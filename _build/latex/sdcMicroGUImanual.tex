%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional
  \DeclareUnicodeCharacter{"00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{"2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{"2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{"2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{"251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{"2572}{\textbackslash}
 \else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{2572}{\textbackslash}
 \fi
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Table of contents}}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{1}



\title{sdcMicro GUI manual Documentation}
\date{May 22, 2019}
\release{}
\author{Thijs Benschop}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}


This is documentation and guidance for \sphinxstyleemphasis{sdcApp}, a user interface for the \sphinxstyleemphasis{sdcMicro} \sphinxstyleemphasis{R}
package, which provides tools for Statistical Disclosure Control (SDC) for microdata,
also known as microdata anonymization.


\chapter{Introduction}
\label{\detokenize{introduction::doc}}\label{\detokenize{introduction:introduction}}\label{\detokenize{introduction:sdcapp-manual}}

\section{What is sdcApp?}
\label{\detokenize{introduction:what-is-sdcapp}}
\sphinxstyleemphasis{sdcApp} is the Graphical User Interface (GUI) for the R package \sphinxstyleemphasis{sdcMicro} (see
\sphinxhref{https://cran.r-project.org/web/packages/sdcMicro/index.html}{here}). The \sphinxstyleemphasis{sdcApp}
opens the functionality of \sphinxstyleemphasis{sdcMicro} to users not familiar with the statistical
programming language \sphinxstyleemphasis{R}. \sphinxstyleemphasis{sdcMicro} is an add-on package for the statistical software \sphinxstyleemphasis{R}
for Statistical Disclosure Control (SDC) of microdata and includes functions for risk measurement,
anonymization and utility measurement for
microdata. All functionality available in the \sphinxstyleemphasis{sdcMicro} package is also available in \sphinxstyleemphasis{sdcApp}.


\section{Statistical Disclosure Control (SDC)}
\label{\detokenize{introduction:statistical-disclosure-control-sdc}}
A large part of the data collected by statistical agencies cannot be published directly
due to privacy and confidentiality concerns. These concerns are both of legal and ethical
nature. SDC seeks to treat and alter the data so that the data can be published or
released without revealing the confidential information it contains, while, at the same time,
limit information loss due to the anonymization of the data. There are two strands of literature
on SDC: 1) for microdata and 2) for tabular data. \sphinxstyleemphasis{sdcMicro} and \sphinxstyleemphasis{sdcApp} only provide the tools
and methodology for protecting microdata.


\section{What is the purpose of the manual?}
\label{\detokenize{introduction:what-is-the-purpose-of-the-manual}}
This manual is designed to provide step-by-step guidance through the process of anonymizing a
dataset with microdata. Both limited background information on methods and measures is
provided as well as instructions on how to complete these steps in sdcApp. As \sphinxstyleemphasis{sdcApp} is a
GUI for the \sphinxstyleemphasis{sdcMicro} package, users familiar with using \sphinxstyleemphasis{R} for statistical analysis
may prefer to carry out the anonymization process using \sphinxstyleemphasis{R} from command-line.
More information and guidance on using \sphinxstyleemphasis{sdcMicro} from command-line
is available in the SDC Practice Guide available \sphinxhref{https://sdcpractice.readthedocs.io/en/latest/}{here}.
A theory guide is available \sphinxhref{https://statistical-disclosure-control-for-microdata-theory.readthedocs.io/en/latest/}{here}
and provides more detailed background information on the SDC process, methods and measures.


\section{Background literature on SDC for microdata}
\label{\detokenize{introduction:background-literature-on-sdc-for-microdata}}
There is a broad scientific literature available on SDC for microdata. The theory guide
contains many references to the appropriate literature. Two books written by practitioners in
NSOs, which give a complete overview are especially worth mentioning:

Hundepool

Templ


\section{Outline of this guide}
\label{\detokenize{introduction:outline-of-this-guide}}
This guide is divided into the following main sections:
\begin{enumerate}
\item {} 
the Section \sphinxhref{installation.html}{Installation and updating} guides the user through the installation process of sdcApp, which includes the installation of R, RStudio as well as the required packages. It also discusses the need and process of regular updates of all software components.

\item {} 
the Section \sphinxhref{introsdcApp.html}{Introduction to sdcApp} covers how to launch and close the application and provides a brief overview of structure of the application.  of the structure of the application

\item {} 
the Section \sphinxhref{loadprepdata.html}{Loading and preparing data} describes how to load microdata into the application. It also discusses the requirements to the

\item {} 
the Section \sphinxhref{setup.html}{Setup anonymization problem}  covers the variable selection and setup of an SDC problem.

\item {} 
the Section \sphinxhref{risk.html}{Risk measurement} covers methods to measure the disclosure risk in the microdata.

\item {} 
the Section \sphinxhref{anon.html}{Anonymization methods} covers anonymization methods for quantitative and qualitative variables.

\item {} 
the Section \sphinxhref{utility.html}{Utility measurement} covers the measurement of information loss resulting from anonymization of the data

\item {} 
the Section \sphinxhref{export.html}{Export data and reports} describes how to export the anonymized dataset and generate reports.

\item {} 
the Section \sphinxhref{reproducibility.html}{Reproducibility} covers functionality that render the anonymization process reproducable.

\item {} 
the Section \sphinxhref{casestudies.html}{Case Studies} presents two case studies illustrating the full SDC process in sdcApp.

\end{enumerate}


\chapter{Installation and updating}
\label{\detokenize{installation::doc}}\label{\detokenize{installation:installation-and-updating}}
This section will guide you through the steps you need to take to install \sphinxstyleemphasis{sdcApp}.
\sphinxstyleemphasis{sdcApp} is a graphical user interface for the sdcMicro package.
The \sphinxstyleemphasis{sdcMicro} package is an add-on package for the statistical software \sphinxstyleemphasis{R}. In order
to start working with \sphinxstyleemphasis{sdcApp}, you need to install \sphinxstyleemphasis{R}, \sphinxstyleemphasis{RStudio} %
\begin{footnote}[1]\sphinxAtStartFootnote
Technically speaking, \sphinxstyleemphasis{RStudio is not required to run *sdcApp}. Nevertheless, we recommend to install \sphinxstyleemphasis{RStudio} for a better user experience.
%
\end{footnote} as well as several
add-on packages for R. All software is available free of charge and open-source.
\sphinxstyleemphasis{R} and \sphinxstyleemphasis{RStudio} run on most platfroms, including Windows, Mac OS X and Linux. To use \sphinxstyleemphasis{sdcApp},
a webbrowser needs to be installed as well %
\begin{footnote}[2]\sphinxAtStartFootnote
\sphinxstyleemphasis{sdcApp} is a \sphinxstyleemphasis{Shiny} web application, which works best in a recent version of a webbrowser. Therefore, it is recommended to ensure that your webbrowser is updated regularly. Some webbrowsers may impede the proper functioning of \sphinxstyleemphasis{sdcApp}. If \sphinxstyleemphasis{sdcApp} doesn’t work properly in your default web browser, please try to install Firefox or Google Chrome.
%
\end{footnote}.

\sphinxstyleemphasis{R}, \sphinxstyleemphasis{RStudio}, the \sphinxstyleemphasis{sdcMicro} package as well as dependencies (other \sphinxstyleemphasis{R} packages
that need to be installed for the \sphinxstyleemphasis{sdcMicro} package to work propoerly) are regularly updated.
Therefore, it is recommended to regularly update to the latest version of the software.
The Section {\hyperref[\detokenize{installation:updating-r-rstudio-and-the-sdcmicro-package}]{\sphinxcrossref{Updating R, RStudio and the sdcMicro package}}} shows how to check for updates
and install updates.


\section{Installing R and RStudio}
\label{\detokenize{installation:installing-r-and-rstudio}}
The first step in the installation of \sphinxstyleemphasis{sdcApp} is the installation of \sphinxstyleemphasis{R} and \sphinxstyleemphasis{RStudio}. The
free open source statistical software R can be downloaded from the \sphinxhref{https://cran.r-project.org}{CRAN website}.
By selecting your OS (cf. \hyperref[\detokenize{installation:fig21}]{Fig.\@ \ref{\detokenize{installation:fig21}}}), the installer will be dowloaded to your computer. In order to install
\sphinxstyleemphasis{R}, open the installer and follow the installation steps.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{installDownloadR}.png}
\caption{Select OS to start downloading R}\label{\detokenize{installation:fig21}}\label{\detokenize{installation:id10}}\end{figure}

Once \sphinxstyleemphasis{R} is successfully installed, we can install \sphinxstyleemphasis{RStudio}. \sphinxstyleemphasis{RStudio} is an IDE
(integrated development environment) for \sphinxstyleemphasis{R}.
\sphinxstyleemphasis{RStudio} makes working with \sphinxstyleemphasis{R} much easier. \sphinxstyleemphasis{RStudio Desktop} and \sphinxstyleemphasis{RStudio Server} can be downloaded
free of charge from the \sphinxhref{https://www.rstudio.com/products/rstudio/download/}{RStudio} website.
On this webpage, scroll down to the overview of different versions as shown in \hyperref[\detokenize{installation:fig22}]{Fig.\@ \ref{\detokenize{installation:fig22}}}
and select the version corresponding to your OS to start downloading the installer.
In order to install \sphinxstyleemphasis{RStudio}, open the installer and follow the installation steps.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{installRStudioVersion}.png}
\caption{Select version to start downloading RStudio}\label{\detokenize{installation:fig22}}\label{\detokenize{installation:id11}}\end{figure}

\begin{sphinxadmonition}{note}{Note:}
We recommend updating to the latest versions of R and RStudio if this software is already
installed on your computer before moving on.
See also the Sections {\hyperref[\detokenize{installation:updating-r}]{\sphinxcrossref{Updating R}}} and {\hyperref[\detokenize{installation:updating-rstudio}]{\sphinxcrossref{Updating RStudio}}} for more information on updating the software.
\end{sphinxadmonition}

Once \sphinxstyleemphasis{R} and \sphinxstyleemphasis{RStudio} are installed on your computer, open \sphinxstyleemphasis{RStudio}. The \sphinxstyleemphasis{RStudio} interface consists
by default of four different panes as shown in \hyperref[\detokenize{installation:fig23}]{Fig.\@ \ref{\detokenize{installation:fig23}}}.
\begin{enumerate}
\item {} 
Script editor (by default left up)

\item {} 
Workspace and history (by default right up)

\item {} 
R console (by default left down)

\item {} 
Plots, files and help (by default right down)

\end{enumerate}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{installRStudio}.png}
\caption{Screenshot RStudio}\label{\detokenize{installation:fig23}}\label{\detokenize{installation:id12}}\end{figure}


\section{Installing sdcMicro package}
\label{\detokenize{installation:installing-sdcmicro-package}}
\sphinxstyleemphasis{sdcApp} is included in the \sphinxstyleemphasis{R} package \sphinxstyleemphasis{sdcMicro}. Once \sphinxstyleemphasis{RStudio} is opened, \sphinxstyleemphasis{sdcMicro} can be
installed by executing commands in the \sphinxstyleemphasis{R} console. \sphinxstyleemphasis{sdcMicro} and a set of other \sphinxstyleemphasis{R} packages
that are required by the \sphinxstyleemphasis{sdcMicro} package are downloaded from the CRAN servers. Therefore,
it is necessary to be connected to the internet during the installation process. %
\begin{footnote}[3]\sphinxAtStartFootnote
It is possible to download \sphinxstyleemphasis{R}, \sphinxstyleemphasis{RStudio} and the packages and transfer the files to the computer with for example a USB drive in case the computer
\sphinxstyleemphasis{sdcMicro} should be installed on cannot be connected to the internet for technical or confidentiality reasons.
%
\end{footnote}

In order to install the latest version of the \sphinxstyleemphasis{sdcMicro} package, type the command
\sphinxcode{\sphinxupquote{install.packages("sdcMicro", dependencies = TRUE)}} in the console and press enter to execute (cf. \hyperref[\detokenize{installation:fig24}]{Fig.\@ \ref{\detokenize{installation:fig24}}}).
The first time you are installing R packages, a prompt will ask you to select a CRAN mirror (server) to install the package from.
Since the packages on all mirrors are identical, you can choose any of the locations.
The sdcMicro package itself uses functionality
from a set of other R packages (e.g., \sphinxstyleemphasis{haven} for reading files in different formats).
By specifying the dependencies argument to TRUE, these dependencies will automatically be installed too.

\def\sphinxLiteralBlockLabel{\label{\detokenize{installation:code01}}}
\sphinxSetupCaptionForVerbatim{Installing sdcMicro package}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} install sdcMicro package}
install.packages\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{sdcMicro\PYGZdq{}}\PYG{p}{,} dependencies \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{installInstallsdcMicro}.png}
\caption{Installing sdcMicro package from \sphinxstyleemphasis{R} console}\label{\detokenize{installation:fig24}}\label{\detokenize{installation:id13}}\end{figure}

\begin{sphinxadmonition}{note}{Note:}
Also dependencies will be installed and the installation may take some time.
Dependencies are other add-on packages, of which the functionality is required to run the sdcMicro package.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
An internet connection is not required while using \sphinxstyleemphasis{sdcMicro} and \sphinxstyleemphasis{sdcApp} and the data
are stored locally on your computer or server. The web browser uses a local host IP,
which is not connected to the internet and the browser is only used to communicate with
the running \sphinxstyleemphasis{R} session.
\end{sphinxadmonition}


\section{Launching \sphinxstyleemphasis{sdcApp}}
\label{\detokenize{installation:launching-sdcapp}}
Once the \sphinxstyleemphasis{sdcMicro} package is successfully installed, the \sphinxstyleemphasis{sdcMicro} package needs to be loaded.
Installing the package is only required once (except for updating), whereas loading the
package is required every time a new \sphinxstyleemphasis{R} session is started.

You can load the \sphinxstyleemphasis{sdcMicro} package by typing \sphinxcode{\sphinxupquote{library(sdcMicro)}}
and launch the application by typing \sphinxcode{\sphinxupquote{sdcApp()}}.

\sphinxstyleemphasis{sdcApp} opens in your system’s default web browser through the local host IP \sphinxcode{\sphinxupquote{127.0.0.1:}}.
\sphinxstyleemphasis{sdcApp} works with recent versions of any webbrowser.
Due to small issues encountered with some browsers, we recommend to use Google Chrome, Mozilla Firefox or Safari for the best performance.
In case your default web browser is not one of the aforementioned browsers, you can simply open an
alternative browser and copy paste the local host IP address in the new browser.
\sphinxstyleemphasis{sdcApp} will open in the new browser.

\begin{sphinxadmonition}{note}{Note:}
After launching \sphinxstyleemphasis{sdcApp} the \sphinxstyleemphasis{R} session is busy and cannot be used for other calculations.
\end{sphinxadmonition}

Furthermore, it’s important that your \sphinxstyleemphasis{R} session is enabled to use the installed webbrowser.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{installRconsoleIP}.png}
\caption{R console with local IP after launching \sphinxstyleemphasis{sdcApp}}\label{\detokenize{installation:fig25}}\label{\detokenize{installation:id14}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{sdcAppStartIP}.png}
\caption{Start screen sdcApp in browser with local IP}\label{\detokenize{installation:fig26}}\label{\detokenize{installation:id15}}\end{figure}

\def\sphinxLiteralBlockLabel{\label{\detokenize{installation:code02}}}
\sphinxSetupCaptionForVerbatim{Loading sdcMicro package and launching \sphinxstyleemphasis{sdcApp}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Load sdcMicro package}
\PYG{k+kn}{library}\PYG{p}{(}sdcMicro\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Launch sdcApp (opens in browser window)}
sdcApp\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

In rare cases, not all dependencies are correctly installed and the following error
message appears in the R console upon loading the sdcMicro package.

Please install the package(s) indicated in the error message manually by using the
command install.packages() with the name of the package(s). In the example error message,
this would be for the packages .


\section{Updating R, RStudio and the sdcMicro package}
\label{\detokenize{installation:updating-r-rstudio-and-the-sdcmicro-package}}
\sphinxstyleemphasis{R}, \sphinxstyleemphasis{RStudio}, the \sphinxstyleemphasis{dcMicro} package as well as dependencies are regularly updated. Updates include
bug fixes as well as additional functionality. Therefore,
it is recommended to regularly update to the latest version of the software.


\subsection{Updating R}
\label{\detokenize{installation:updating-r}}
\sphinxstyleemphasis{RStudio} uses by default the most recent version of \sphinxstyleemphasis{R} available on your system. New
versions of \sphinxstyleemphasis{R} packages, including the \sphinxstyleemphasis{sdcMicro} package, rely on the newest version of \sphinxstyleemphasis{R}. Therefore,
it’s important to regularly check for updates of \sphinxstyleemphasis{R}. The easiest way to do so
is to visit regularly the \sphinxhref{https://cran.r-project.org}{CRAN website}.
If a new version of \sphinxstyleemphasis{R} is available, the same steps as for the installation of \sphinxstyleemphasis{R} need to be followed
as described in the Section {\hyperref[\detokenize{installation:installing-r-and-rstudio}]{\sphinxcrossref{Installing R and RStudio}}}. The version number of the
\sphinxstyleemphasis{R} version installed on your computer appears in the R console upon launching \sphinxstyleemphasis{R} or \sphinxstyleemphasis{RStudio}
(cf. \sphinxcode{\sphinxupquote{fig27}}).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{installRversion}.png}
\caption{R console with version number}\label{\detokenize{installation:fig27}}\label{\detokenize{installation:id16}}\end{figure}


\subsection{Updating RStudio}
\label{\detokenize{installation:updating-rstudio}}
To check for updates in \sphinxstyleemphasis{RStudio}, go to Help -\textgreater{} Check for updates. If an update is available,
the current version number and the newest version number are shown. In order to install
the newer version, you need to visit the
\sphinxhref{https://www.rstudio.com/products/rstudio/download/}{RStudio} website and follow the steps
as described in the Section {\hyperref[\detokenize{installation:installing-r-and-rstudio}]{\sphinxcrossref{Installing R and RStudio}}}.


\subsection{Updating R packages}
\label{\detokenize{installation:updating-r-packages}}
The \sphinxstyleemphasis{sdcMicro} package is regularly updated to fix bugs and add functionality. In order to check
for newer versions, click on the Update button to get an overview of all packages that have
newer versions available. By clicking Select all, these packages are all automatically updated.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{installCheckUpdate}.png}
\caption{Updating R packages in RStudio}\label{\detokenize{installation:id6}}\label{\detokenize{installation:id17}}\end{figure}

\def\sphinxLiteralBlockLabel{\label{\detokenize{installation:code03}}}
\sphinxSetupCaptionForVerbatim{Updating packages}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Update}
install.packages\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Bug reporting on GitHub}
\label{\detokenize{installation:bug-reporting-on-github}}
The sdcMicro package is open source software and the source code can be easily viewed on
the \sphinxhref{https://github.com/sdcTools/sdcMicro}{GitHub} of the \sphinxstyleemphasis{sdcMicro} project. There you can
also report alleged bugs and raise other issues.


\chapter{Introduction to sdcApp}
\label{\detokenize{introsdcApp::doc}}\label{\detokenize{introsdcApp:introduction-to-sdcapp}}
\sphinxstyleemphasis{sdcApp} is a user-friendly application for microdata anonymization
and is built on the \sphinxhref{https://shiny.rstudio.com}{Shiny}
technology. Shiny allows users to
communicate through a GUI that runs in a webbrowser with a local \sphinxstyleemphasis{R} session. The local
\sphinxstyleemphasis{R} session performs the necessary calculations. In the case of \sphinxstyleemphasis{sdcApp}, most functionality
used in \sphinxstyleemphasis{R} is included in the \sphinxhref{https://CRAN.R-project.org/package=sdcMicro}{sdcMicro}
package.

\sphinxstyleemphasis{sdcApp} has a tab structure and consists of seven tabs, which in turn consist of
up to three panels. This structured is further explored below.
The tabs and panels are used to navigate through the app.


\section{Starting sdcApp}
\label{\detokenize{introsdcApp:starting-sdcapp}}
After succcesful installation (see the Section \sphinxhref{installation.html}{Installation and updating}),
\sphinxstyleemphasis{sdcApp} is ready for use. Every single time \sphinxstyleemphasis{sdcApp} is used,
first the applications \sphinxstyleemphasis{R} or \sphinxstyleemphasis{RStudio} need to be opened. We recommend to use \sphinxstyleemphasis{RStudio}
for ease of use. After launching \sphinxstyleemphasis{R} or \sphinxstyleemphasis{RStudio},
the \sphinxstyleemphasis{sdcMicro} package needs to be loaded and \sphinxstyleemphasis{sdcApp} needs to be launched.
To load \sphinxstyleemphasis{sdcMicro} and launch \sphinxstyleemphasis{sdcApp}, enter the code as shown in \hyperref[\detokenize{introsdcApp:code1}]{Listing \ref{\detokenize{introsdcApp:code1}}} in the \sphinxstyleemphasis{R} console.
Press enter after each line to execute the line of code. \hyperref[\detokenize{introsdcApp:fig31}]{Fig.\@ \ref{\detokenize{introsdcApp:fig31}}} shows the
output in the \sphinxstyleemphasis{R} console after successfully launching \sphinxstyleemphasis{sdcApp}.

\def\sphinxLiteralBlockLabel{\label{\detokenize{introsdcApp:code1}}}
\sphinxSetupCaptionForVerbatim{Loading sdcMicro package and launching sdcApp}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Load sdcMicro package}
\PYG{k+kn}{library}\PYG{p}{(}sdcMicro\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Launch sdcApp (opens in browser window)}
sdcApp\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
You can omit the lines starting with a hash tag (\sphinxcode{\sphinxupquote{\#}}) as these are comment lines
and ignored by the \sphinxstyleemphasis{R} interpreter.
\end{sphinxadmonition}

The application opens in a new tab in your default web browser. In case you prefer to use
an alternative web browser, you can simply copy the address of the localhost and paste it into
a different browser on the same machine. The localhost address can be
found in the output in the \sphinxstyleemphasis{R} console. The address starts with \sphinxcode{\sphinxupquote{http://127.0.0.1:}} followed
by a four digit number. In the example in \hyperref[\detokenize{introsdcApp:fig31}]{Fig.\@ \ref{\detokenize{introsdcApp:fig31}}}, the full localhost address is
\sphinxcode{\sphinxupquote{http://127.0.0.1:3256}}. The application opens on the \sphinxstylestrong{About/Help} tab (see \hyperref[\detokenize{introsdcApp:fig32}]{Fig.\@ \ref{\detokenize{introsdcApp:fig32}}}).

\begin{sphinxadmonition}{note}{Note:}
Firewalls and other settings on your computer and browser may prevent \sphinxstyleemphasis{sdcApp} from opening
in your webbrowser. As a first thing you could try to copy paste the localhost address
into your webbrowser. If that is not successful, try changing the settings of your
browser and firewall.
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{introRConsoleLaunch}.png}
\caption{R console after loading the \sphinxstyleemphasis{sdcMicro} package and launching \sphinxstyleemphasis{sdcApp}}\label{\detokenize{introsdcApp:fig31}}\label{\detokenize{introsdcApp:id1}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{introLandingPage}.png}
\caption{\sphinxstylestrong{About/Help} tab in web browser after launching \sphinxstyleemphasis{sdcApp} with localhost address}\label{\detokenize{introsdcApp:fig32}}\label{\detokenize{introsdcApp:id2}}\end{figure}


\section{Tab and panel structure}
\label{\detokenize{introsdcApp:tab-and-panel-structure}}
The sdcApp consists of seven different tabs that serve different parts of the
SDC process. The tabs can be selected in the navigation
bar at the top of the page (cf. the area indicated with 1 in \hyperref[\detokenize{introsdcApp:fig33}]{Fig.\@ \ref{\detokenize{introsdcApp:fig33}}}).
The navigation bar is visible at all times. The content of each tab may change as
function the specified SDC problem and the current state of the SDC process. For example,
anonymization methods for continuous key variables are not shown on the \sphinxstylestrong{Anonymize} tab,
if no continuous key variables are selected.
\begin{itemize}
\item {} \begin{description}
\item[{About/Help}] \leavevmode
Landing page to set storage path, quit and restart \sphinxstyleemphasis{sdcApp} as well as provide feedback to the developers

\end{description}

\item {} \begin{description}
\item[{Microdata}] \leavevmode
Page to load, view, explore and prepare the microdata to be anonymized

\end{description}

\item {} \begin{description}
\item[{Anonymize}] \leavevmode
Page to setup the anonymization problem (select variables, set parameters). Once the
problem is defined, this page shows a summary of the anonymization problem and allows
to apply anonymization methods

\end{description}

\item {} \begin{description}
\item[{Risk/Utility}] \leavevmode
Page to evaluate disclosure risk and information loss (data utility)

\end{description}

\item {} \begin{description}
\item[{Export Data}] \leavevmode
Page to export the anonymized data and reports on the anonymization process

\end{description}

\item {} \begin{description}
\item[{Reproducibility}] \leavevmode
Page with functionality to guarantee the reproducibility of the process by exporting the
\sphinxstyleemphasis{R} script or problem instance

\end{description}

\item {} \begin{description}
\item[{Undo}] \leavevmode
Page to revert one or several steps in the anonymization process

\end{description}

\end{itemize}

Each tab consists of two panels: the left sidebar (cf. the area indicated with 2 in \hyperref[\detokenize{introsdcApp:fig33}]{Fig.\@ \ref{\detokenize{introsdcApp:fig33}}})
and the main panel (cf. the area indicated with 3 in \hyperref[\detokenize{introsdcApp:fig33}]{Fig.\@ \ref{\detokenize{introsdcApp:fig33}}}). The left panel
allows the user to navigate between different function on the same tab, e.g., different
risk measures. Some tabs have an additional right sidebar (cf. the area indicated with 4 in \hyperref[\detokenize{introsdcApp:fig33}]{Fig.\@ \ref{\detokenize{introsdcApp:fig33}}}),
which provide summary information on the current SDC problem.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{appStructure}.png}
\caption{Risk/Utility tab with navigation bar and panel structure}\label{\detokenize{introsdcApp:fig33}}\label{\detokenize{introsdcApp:id3}}\end{figure}


\section{In-app help}
\label{\detokenize{introsdcApp:in-app-help}}
By hovering with the mouse pointer over the \sphinxincludegraphics{{introIicon}.png} icon in \sphinxstyleemphasis{sdcApp}, additional information on
e.g., specific parameters and the interpretation of results is provided. The help information
is mainly intended to provide a brief reminder and is not meant to replace a thorough
study of the SDC literature on risk and utility measurement and anonymization methods.
\hyperref[\detokenize{introsdcApp:fig36}]{Fig.\@ \ref{\detokenize{introsdcApp:fig36}}} shows the help pop-up for the variable selection table.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{introHelp}.png}
\caption{Help pop-up when moving with mouse cursor over \sphinxstyleemphasis{i} icon}\label{\detokenize{introsdcApp:fig36}}\label{\detokenize{introsdcApp:id4}}\end{figure}


\section{Getting started}
\label{\detokenize{introsdcApp:getting-started}}
Use testdata dataset: all examples in this guide are illustrated with the testdata dataset.


\section{Set storage path}
\label{\detokenize{introsdcApp:set-storage-path}}
All output exported from \sphinxstyleemphasis{sdcApp}, such as the anonymized dataset, reports and scripts will be
saved in the directory shown under the header \sphinxstylestrong{Set storage path} on the \sphinxstylestrong{About/Help}
tab (cf. \hyperref[\detokenize{introsdcApp:fig34}]{Fig.\@ \ref{\detokenize{introsdcApp:fig34}}}). Upon launching \sphinxstyleemphasis{sdcApp}, this directory is set to the \sphinxstyleemphasis{R} working
directory. Change the working directory to a the folder in the project directory with the
dataset to be anonymized by typing the path to this folder in the input box (cf. \hyperref[\detokenize{introsdcApp:fig34}]{Fig.\@ \ref{\detokenize{introsdcApp:fig34}}}).
Once a valid path on your computer is entered, click the blue button \sphinxstylestrong{Update the current output
path} to change the path. If the entered path is not a valid path on your system, a red button appears
with the text \sphinxstylestrong{The specified directory does not exist, thus the path can’t be updated}.
It is recommended to create a new folder in the project directory for the \sphinxstyleemphasis{sdcApp} output.
The file names of the output files contain a date and time stamp as well as a brief description,
e.g., exportedData\_sdcMicro\_20181010\_1211.dta for the anonymized microdata in STATA format
on October 10, 2018 at 12:11 and exportedProblem\_sdcMicro\_20180304\_1633.rdata for the
saved problem instance as \sphinxstyleemphasis{R} datafile on March 4, 2018 ar 16:33.

\begin{sphinxadmonition}{note}{Note:}
The storage path to the output folder needs to be specified every time \sphinxstyleemphasis{sdcApp} is
launched.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
If an sdcProblem is saved and reloaded, the storage path is set to the path saved
in the sdcProblem. If the problem is loaded on a different computer than it was saved at,
the storage path may be invalid and needs to be updated in the same way as described above.
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{introSetStoragePath}.png}
\caption{View and set storage path for file export}\label{\detokenize{introsdcApp:fig34}}\label{\detokenize{introsdcApp:id5}}\end{figure}


\section{Quiting sdcApp}
\label{\detokenize{introsdcApp:quiting-sdcapp}}
To quit \sphinxstyleemphasis{sdcApp}, click on \sphinxstylestrong{Stop the GUI} under the header \sphinxstylestrong{Stop the interface} on the
\sphinxstylestrong{About/Help} tab. It is recommended to quit \sphinxstyleemphasis{R} or \sphinxstyleemphasis{RStudio} after quitting \sphinxstyleemphasis{sdcApp}
to ensure that nothing is left in the memory. This especially applies to a restart due
to \sphinxstyleemphasis{sdcApp} not responding.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{introStopGUI}.png}
\caption{Button to quit \sphinxstyleemphasis{sdcApp} on the \sphinxstylestrong{About/Help} tab}\label{\detokenize{introsdcApp:fig35}}\label{\detokenize{introsdcApp:id6}}\end{figure}

Save SDC problem to continue working later. Possible once the SDC problem is defined.
See undo section


\chapter{Loading and Preparing Data}
\label{\detokenize{loadprepdata::doc}}\label{\detokenize{loadprepdata:loading-and-preparing-data}}
This section discusses how to load microdata into \sphinxstyleemphasis{sdcApp} and prepare the data
for the SDC process.

The first step in the SDC process is loading the dataset into \sphinxstyleemphasis{sdcApp}. \sphinxstyleemphasis{sdcApp} supports
most common statistical data formats, such as \sphinxstyleemphasis{R}, \sphinxstyleemphasis{STATA}, \sphinxstyleemphasis{SPSS} and \sphinxstyleemphasis{SAS} files. First time
users may also load one of the two practice datasets, which are included in \sphinxstyleemphasis{sdcApp},
to explore \sphinxstyleemphasis{sdcApp} and methods. Most examples in this guide are illustrated by
using the practice dataset \sphinxstyleemphasis{testdata} and can be reproduced by using this dataset.

After loading the data, the user needs to prepare the data for the SDC process.
Most preparation steps can be carried out in \sphinxstyleemphasis{sdcApp}, although users may find it
more convenient to perform some of these actions in another statistical software
before loading the data in \sphinxstyleemphasis{sdcApp}.


\section{Loading data}
\label{\detokenize{loadprepdata:loading-data}}

\subsection{Testdata}
\label{\detokenize{loadprepdata:testdata}}
\sphinxstyleemphasis{sdcApp} includes two practice datasets: \sphinxstyleemphasis{testdata} and \sphinxstyleemphasis{testdata2}. The dataset
\sphinxstyleemphasis{testdata} is used to illustrate methods and examples in this guide. In order to
replicate these examples, the user needs to load this dataset. In order to load the testdata
dataset, navigate to the \sphinxstylestrong{Microdata tab} and select \sphinxstylestrong{Testdata/Internal data} in the left sidebar.
Select the dataset from the dropdown menu and click the button \sphinxstylestrong{Load data}.
This is illustrated in \hyperref[\detokenize{loadprepdata:fig51}]{Fig.\@ \ref{\detokenize{loadprepdata:fig51}}}.

\begin{sphinxadmonition}{note}{Note:}
Any other datasets loaded in the current \sphinxstyleemphasis{R} session are also shown in the dropdown list
with available datasets and can be loaded.
\sphinxstylestrong{Add screenshot of dropdown menu with mymicrodata}
\end{sphinxadmonition}

After loading the dataset, the data is displayed in the \sphinxstylestrong{Microdata} tab. The \sphinxstylestrong{Microdata}
tab changes and the functionality for loading microdata is replaced with
functionality to explore and prepare the dataset (cf. \hyperref[\detokenize{loadprepdata:fig52}]{Fig.\@ \ref{\detokenize{loadprepdata:fig52}}}). The
left sidebar shows different options to explore and prepare the data for the anonymization process,
as discussed in the next sections.

After loading the testdata dataset, the loaded
dataset is displayed (cf. \hyperref[\detokenize{loadprepdata:fig52}]{Fig.\@ \ref{\detokenize{loadprepdata:fig52}}}). By default the first 20 records are displayed.
With the dropdown menu in the topleft corner it is possible to display 20, 50, 100 or all
records per page. It is not recommended to select \sphinxstyleemphasis{all} in case of larger datasets
\sphinxstyleemphasis{sdcApp} will run very slow. In the right bottom it is possible to navigate to different pages,
either by clicking \sphinxstyleemphasis{Next} or by clicking on a page number. The table
with the data is both horizontally and vertically scrollable with the scrollbars on the
right side and bottom of the table. To sort the data by a variable, click on the symbol
with two arrows (\sphinxincludegraphics{{prepLoadSort}.png} or \sphinxincludegraphics{{prepLoadSort2}.png}) next to the variable name in the header of the table.
The data is searchable by using the search bar on the right top of the table. Only records
with matches are displayed. The search is performed simultaneously on all variables.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{prepLoadTestdata}.png}
\caption{Load testdata on \sphinxstylestrong{Microdata} tab}\label{\detokenize{loadprepdata:fig51}}\label{\detokenize{loadprepdata:id1}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{prepLoadedData}.png}
\caption{Loaded dataset}\label{\detokenize{loadprepdata:fig52}}\label{\detokenize{loadprepdata:id2}}\end{figure}


\subsection{Other microdata}
\label{\detokenize{loadprepdata:other-microdata}}
\sphinxstyleemphasis{sdcApp} supports datasets in several foreign data formats (cf. \hyperref[\detokenize{loadprepdata:tab51}]{Table \ref{\detokenize{loadprepdata:tab51}}}).
If the microdata is not in one of these data formats, another software can be used
to convert the data, such as \sphinxstyleemphasis{Stat/Transfer}. Also some statistical software allow to export
the data in another data format.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Data formats compatible with sdcApp}\label{\detokenize{loadprepdata:tab51}}\label{\detokenize{loadprepdata:id3}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Software
&\sphinxstyletheadfamily 
File extension
\\
\hline
R/RStudio
&
.rdata
\\
\hline
SPSS
&
.sav
\\
\hline
SAS
&
.sas7bdat
\\
\hline
CSV
&
.csv, .txt
\\
\hline
STATA
&
.dta
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

In order to load a dataset, select the corresponding data format
from the left sidebar of the \sphinxstylestrong{Microdata} tab. For all formats the user can set two options:
\begin{enumerate}
\item {} \begin{description}
\item[{Convert string variables (character vectors) to factor variables?}] \leavevmode
If \sphinxcode{\sphinxupquote{TRUE}} (default), variables of type string are automatically converted to categorical variables
(type factor in \sphinxstyleemphasis{R}). Categorical variables need to be of type factor in \sphinxstyleemphasis{sdcApp}.
Remove any textual variables, such as ‘Specify other:’ variables before loading the
data. These variables are oftentimes not suitable for release and require long
computation times to be transformed to factor. If \sphinxcode{\sphinxupquote{FALSE}},

\end{description}

\item {} \begin{description}
\item[{Drop variables with only missing values (NA)?}] \leavevmode
If \sphinxcode{\sphinxupquote{TRUE}} (default), variables that contain only missing values (\sphinxcode{\sphinxupquote{NA}} in \sphinxstyleemphasis{R})
are removed upon loading the data. This does not cause any loss of information,
as these variabels do not contain information. However, variables with only
missing values can cause issues in \sphinxstyleemphasis{sdcApp}. If \sphinxcode{\sphinxupquote{FALSE}}, no variables are deleted.

\end{description}

\end{enumerate}

If the selected data format is a CSV-file, two additional options need to be specified:
\begin{enumerate}
\item {} \begin{description}
\item[{Does the first row contain the variable names?}] \leavevmode
If \sphinxcode{\sphinxupquote{TRUE}}, the values in the first row are used as variable names. If
\sphinxcode{\sphinxupquote{FALSE}}, the variables names are set to V1, V2, V3, … in the order of
appearance in the dataset.

\end{description}

\item {} \begin{description}
\item[{Field separator}] \leavevmode
The field separator in the csv file needs to be specified. Options are comma (,),
semicolon (;) and tab.

\end{description}

\end{enumerate}

After setting the options for the data upload, click on the button \sphinxstylestrong{Browse} to access
the file system in your computer and select the microdata file. The file is upload
immediately after selection. After loading the file, which may

\begin{sphinxadmonition}{note}{Note:}
Set the additional options before selecting the datafile from your file system.
Upon selection after clicking \sphinxstylestrong{Browse}, the file is immediately loaded and settings
can no longer be changed. If the file was accidentally loaded before setting all
parameters, the file needs to be reloaded after first restting the microdata by
clicking \sphinxstylestrong{Reset microdata} in the left sidebar.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
The default maximum file size in \sphinxstyleemphasis{sdcApp} is 50 MB. In order to upload larger files,
the maximum file size in MB needs to be specified upon launching \sphinxstyleemphasis{sdcApp}. This can
be achieved by specifying the argument \sphinxcode{\sphinxupquote{maxRequestSize}}:

\def\sphinxLiteralBlockLabel{\label{\detokenize{loadprepdata:id4}}}
\sphinxSetupCaptionForVerbatim{Launching \sphinxstyleemphasis{sdcApp} to load larger files}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Launch sdcApp with increased max. file size (200MB)}
sdcApp\PYG{p}{(}maxRequestSize \PYG{o}{=} \PYG{l+m}{200}\PYG{p}{)}
\end{sphinxVerbatim}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{prepLoadData}.png}
\caption{Load data on Microdata tab - example STATA dataset}\label{\detokenize{loadprepdata:fig53}}\label{\detokenize{loadprepdata:id5}}\end{figure}

After loading the testdata dataset, the loaded
dataset is displayed (cf. \hyperref[\detokenize{loadprepdata:fig52}]{Fig.\@ \ref{\detokenize{loadprepdata:fig52}}}). By default the first 20 records are displayed.
With the dropdown menu in the topleft corner it is possible to display 20, 50, 100 or all
records per page. It is not recommended to select \sphinxstyleemphasis{all} in case of larger datasets
\sphinxstyleemphasis{sdcApp} will run very slow. In the right bottom it is possible to navigate to different pages,
either by clicking \sphinxstyleemphasis{Next} or by clicking on a page number. The table
with the data is both horizontally and vertically scrollable with the scrollbars on the
right side and bottom of the table. To sort the data by a variable, click on the symbol
with two arrows next to the variable name in the header of the table.

After loading the dataset, the data is shown in the \sphinxstylestrong{Microdata} tab. The \sphinxstylestrong{Microdata}
tab changes and the functionality for loading microdata is replaced with
functionality to explore and prepare the dataset (cf. \hyperref[\detokenize{loadprepdata:fig511}]{Fig.\@ \ref{\detokenize{loadprepdata:fig511}}}). The
left sidebar shows different options to explore and prepare the data for the anonymization process,
as discussed in the next sections.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{prepLoadAfterLoad}.png}
\caption{Microdata tab after loading dataset}\label{\detokenize{loadprepdata:fig511}}\label{\detokenize{loadprepdata:id6}}\end{figure}

maxrequestsize option for loading larger files


\section{Inspect and explore data}
\label{\detokenize{loadprepdata:inspect-and-explore-data}}
After loading the dataset into \sphinxstyleemphasis{sdcApp}, the data is shown on the Microdata tab. At the top of
the data viewer, the number of observations and variables is shown as well as the number
of variables that were deleted as a result all missing values (cf. \hyperref[\detokenize{loadprepdata:fig511}]{Fig.\@ \ref{\detokenize{loadprepdata:fig511}}}).

\begin{sphinxadmonition}{note}{Note:}
If \sphinxstyleemphasis{Drop variables with only missing values (NA)?} is set to TRUE, the number of variables
shown may be lower than the number of variables in the loaded dataset.
\end{sphinxadmonition}

It is important to check whether the data was imported completely and correctly by browsing
the dataset in \sphinxstyleemphasis{sdcApp}. If, for example, records are missing or labels are corrupted,
then these issues need to be fixed outside of \sphinxstyleemphasis{sdcApp} and the data need to be reimported.

By clicking \sphinxstylestrong{Explore variables} in the left sidebar, univariate and bivariate summary
statistics appropriate for the variable type can displayed. If one variable is selected,
univariate summary statistics are shown.

\begin{sphinxadmonition}{note}{Note:}
The choice of summary statistics is based on the variable type specified in \sphinxstyleemphasis{R} (shown in
brackets after the variable name, e.g., urbrur (integer)). Therefore,
the representation may not be correct, if the variable type does not correspond
with the variable content. By converting the variable (see {\hyperref[\detokenize{loadprepdata:convert-variable-type}]{\sphinxcrossref{Convert variable type}}}),
the correct summary statistics will be displayed.
\end{sphinxadmonition}


\section{Preparing data}
\label{\detokenize{loadprepdata:preparing-data}}
Most datasets need to be prepared before the start of the anonymization process. Examples
of data preparation are removing variables that are not suitable for release, etc. It is
recommended to carry out the data preparation in a statistical software of choice, before
loading the data in sdcApp. Data preparation includes

After loading the data in sdcApp, still some steps may need to be carried, which are
specific to the needs of the sdcApp. These steps are discussed in the following subsections.


\subsection{Convert variable type}
\label{\detokenize{loadprepdata:convert-variable-type}}
numeric to factor

to numeric


\subsection{Set specific values to NA}
\label{\detokenize{loadprepdata:set-specific-values-to-na}}
Missing values play an important role in anonymization of microdata. In particular when
measuring disclosure risk of categorical key variables (see {\color{red}\bfseries{}{}`Risk{}`\_\_}). sdcApp only considers
the R missing value \sphinxcode{\sphinxupquote{NA}} as missing. Therefore, it is important to recode other missing values,
such as 9, 99, 998 or 999, “Missing”, “Not applicable” after loading the
data to the R missing value \sphinxcode{\sphinxupquote{NA}}, if appropriate. Many standard missing value codes
in the data, such as \sphinxcode{\sphinxupquote{.}} in STATA are automatically converted to NA upon loading
the data into \sphinxstyleemphasis{sdcApp}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{prepareMissingToNA}.png}
\caption{Screen to set specific value in a variable to NA}\label{\detokenize{loadprepdata:fig57}}\label{\detokenize{loadprepdata:id7}}\end{figure}


\subsection{Modify factor variable}
\label{\detokenize{loadprepdata:modify-factor-variable}}
Recoding (see Recoding)

\begin{sphinxadmonition}{note}{Note:}
(this note may come in other places as well) \sphinxstyleemphasis{sdcApp} is an aid for completing the
microdata anonymization process. However, sometimes it may be easier and quicker to
use other statistical software packages for performing data preparation steps, such as
recoding.
\end{sphinxadmonition}


\subsection{Create stratification variable}
\label{\detokenize{loadprepdata:create-stratification-variable}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{prepStrataVariable}.png}
\caption{Screen to create new stratification variable}\label{\detokenize{loadprepdata:fig58}}\label{\detokenize{loadprepdata:id8}}\end{figure}


\subsection{Reset variables}
\label{\detokenize{loadprepdata:reset-variables}}

\subsection{Hierarchical data}
\label{\detokenize{loadprepdata:hierarchical-data}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{prepHierarchical1}.png}
\caption{Screen to create household level dataset}\label{\detokenize{loadprepdata:fig59}}\label{\detokenize{loadprepdata:id9}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{prepHierarchical2}.png}
\caption{Screen merge anonymized household level dataset with individual level dataset}\label{\detokenize{loadprepdata:fig510}}\label{\detokenize{loadprepdata:id10}}\end{figure}


\subsection{Use subset of microdata}
\label{\detokenize{loadprepdata:use-subset-of-microdata}}

\chapter{Setup anonymization problem}
\label{\detokenize{setup::doc}}\label{\detokenize{setup:setup-anonymization-problem}}
Based on the analysis of the disclosure scenarios (see ), the user needs can make the variable
selection in \sphinxstyleemphasis{sdcApp} and set some other parameters in order to define the
so-called SDC problem. Once the data is loaded and prepared,
the tab \sphinxstyleemphasis{Anonymize} shows a variable selection matrix in the main panel. The right sidebar
shows several parameter settings and allows to have a quick summary view of each of the variables
in the loaded dataset.


\section{Variable selection}
\label{\detokenize{setup:variable-selection}}
In order to setup an SDC problem the user needs to make a variable selection. The variable
selection itself is the result of the analysis of diclosure scenarios and is beyond the scope
of this manual. We refer to Chapter in for a thorough discussion of disclosure scenarios.

The matrix shown in \hyperref[\detokenize{setup:fig11}]{Fig.\@ \ref{\detokenize{setup:fig11}}} contain one row for each variable in the loaded dataset
and nine different columns as described in \hyperref[\detokenize{setup:tabsetup1}]{Table \ref{\detokenize{setup:tabsetup1}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{setupTable}.png}
\caption{Table on Anonymize tab for variable selection}\label{\detokenize{setup:fig11}}\label{\detokenize{setup:id1}}\end{figure}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Columns in setup table}\label{\detokenize{setup:tabsetup1}}\label{\detokenize{setup:id2}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Column header
&\sphinxstyletheadfamily 
Description
\\
\hline
Variable name
&
Name of variable in original dataset
\\
\hline
Type
&
Variable type in \sphinxstyleemphasis{R} (factor, integer, numeric, character)
\\
\hline
Key variables
&
Radio buttons to select variable as categorical or continuous key variable
\\
\hline
Weight
&
Column to select variable as weight variable
\\
\hline
Hierarchical identifier
&
Column to select variable as hierarchical identifier
\\
\hline
PRAM
&
Column to select variable for PRAM method
\\
\hline
Delete
&
Column to select variable to be deleted from released dataset
\\
\hline
Number of levels
&
Number of different values (including NA/missing) in a categorical (type factor) variable
\\
\hline
Number of missing
&
Number of records with missing value for this particular variable
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The user can select for each
variable the function it has in the SDC problem. No selection needs to
be made for variables that are not relevant to the
anonymization process and can be released without further treatment. Each of the
columns is described in more detail:
\begin{enumerate}
\item {} \begin{description}
\item[{\sphinxstylestrong{Variable name}}] \leavevmode
This column specifies the variable name as provided in the original dataset.
Variable names cannot be changed in \sphinxstyleemphasis{sdcApp}, as they are unique identifiers. If
the anonymization process renders a variable name no longer appropriate, the variable
must be renamed after exporting the dataset in a software of choice.

\end{description}

\item {} \begin{description}
\item[{\sphinxstylestrong{Type}}] \leavevmode
Each variable has a internal variable type in \sphinxstyleemphasis{R}. The different types include
numeric, integer, factor and string. Each of the different functions in the
SDC process requires a specific variable type, e.g., the weight needs to be numeric.
If a variable is not of the appropriate type, the type of the variable needs to be changed
before a selection is made (see the Section \sphinxhref{loadprepdata.html}{Convert variable type}).

\end{description}

\item {} \begin{description}
\item[{\sphinxstylestrong{Key variables}}] \leavevmode
Variables that are determined as key variables in the disclosure
scenario need to be selected with the radiobutton.
Key variables can be either categorical (select \sphinxstyleemphasis{cat.}) or numeric(select \sphinxstyleemphasis{cont.}).
The sets of categorical key variables and numeric key variables are treated independently
in \sphinxstyleemphasis{sdcApp}. Categorical key variables can be of type integer or factor. Numeric key variables
can be of type integer or numeric. If a variable is not a key variable, the default
value \sphinxstyleemphasis{No} should be selected.
At least one variable needs to be selected as
categorcial key variable in order to create an SDC problem.

\end{description}

\item {} \begin{description}
\item[{\sphinxstylestrong{Weight}}] \leavevmode
The sampling weight is used to measure the disclosure risk. The weight
variable needs to be of type numeric.

\end{description}

\item {} \begin{description}
\item[{\sphinxstylestrong{Hierarchical identifier}}] \leavevmode
If the data has a hierarchical structure, e.g., individuals
in households, the variable that defines this hierarchy needs to be selected as
hierarchical identifier (see also the Section \sphinxtitleref{Risk}). This could be for instance a household ID. The hierarchical
identifier needs to be unique for each hierarchical unit (e.g., household)
in the complete dataset and the same for each
member of the hierarchical unit (e.g., household member).
The hierarchical identifier can be of any type, but it is recommended not to use a string
variable. Only one variable can be selected as hierarchical identifier.
If the unique hierachical indentifier is
composed of several variabels, e.g., a geographical identifier, such as region, and
a household ID which is unique within regions but not across, a unique hierarchical
identifier needs to generated before importing the data into \sphinxstyleemphasis{sdcApp}. This can be done in
a software of choice by concatenating the different components.

\end{description}

\item {} \begin{description}
\item[{\sphinxstylestrong{PRAM}}] \leavevmode
If some variables are considered for application of the PRAM method (see \sphinxhref{anon.html\#PRAM}{PRAM}),
they need to be specified at this stage. PRAM variables must be of type factor.

\end{description}

\item {} \begin{description}
\item[{\sphinxstylestrong{Delete}}] \leavevmode
Variables that need to be deleted from the dataset for release, such as
direct identifiers, need to be selected here. Variables to be deleted can be of any type.

\end{description}

\item {} \begin{description}
\item[{\sphinxstylestrong{Number of levels}}] \leavevmode
This column shows the number of unique values in each variable. For instance a gender
variable has typically two different levels. Note that if a variable contains missing
values, this is also considered as a distinct value.

\end{description}

\item {} \begin{description}
\item[{\sphinxstylestrong{Number of missing}}] \leavevmode
This column indicates the number of missing values in each variable.
If values were set to NA, the missing value code in R, these are counted here. Other
missing value codes, such as 9, 99, 998 need to be set to NA
(see also the Section \sphinxhref{loadprepdata.html}{Set missing values to NA}).

\end{description}

\end{enumerate}

\begin{sphinxadmonition}{note}{Note:}
All variables need to be of the appropriate variable type. If the variable type of a
variable is not suitable for the selected variable function, a popup window with an error
message will appear. If necessary, the variable type needs to be changed before setting up the SDC
problem.
\end{sphinxadmonition}

Once a valid variable selection is made, a blue button will appear at the bottom of the
setup table:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{setupButton}.png}
\caption{Blue setup button appears below the setup table if the variable selection is valid}\label{\detokenize{setup:fig12}}\label{\detokenize{setup:id3}}\end{figure}

If a variable selection is invalid, the setup button will disappear and only reappears once
all invalid choices are corrected. Popup windows as shown in \hyperref[\detokenize{setup:fig13}]{Fig.\@ \ref{\detokenize{setup:fig13}}},
will guide the user through the variables
that need to be fixed. The most common invalid choices are the selection of more
than one function for a variable and the selection of a function that does not correspond
with the variable type.

Before clicking the blue button to setup the SDC problem, several parameters have to be set,
as outlined in the next section.

\begin{sphinxadmonition}{note}{Note:}
If an invalid variable choice is made, such as an invalid variable type
or a variable is selected for more than one choice, a pop-up window with an informative
error message is shown. An example is shown in \hyperref[\detokenize{setup:fig13}]{Fig.\@ \ref{\detokenize{setup:fig13}}}. The error
message can be closed by clicking \sphinxstyleemphasis{Continue}.
It is important to undo the invalid selection after clicking away
the error message, as this doesn’t happen automatically.
Not correcting the selection will
make it later difficult to trace back the invalid selections.
The blue setup button disappears and reappears once the problem is fixed.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
The variable selection cannot be saved before setting up the SDC problem. If, for instance,
a variable is not of the appropriate variable type for its use in the SDC problem,
the variable type needs to be changed on the \sphinxstyleemphasis{Microdata} tab. By returning to the
\sphinxstyleemphasis{Microdata} tab, all selections made on the \sphinxstyleemphasis{Anonymize} tab are lost and need to be reselected.
Therefore, it is recommended to first check all variable types before starting the
variable selection.
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{setupErrorMessage}.png}
\caption{Example of a popup window with an error message after an invalid variable choice}\label{\detokenize{setup:fig13}}\label{\detokenize{setup:id4}}\end{figure}


\section{Settings}
\label{\detokenize{setup:settings}}
Besides the variable selection, there are two more parameters to be set before creating
the SDC problem: alpha and seed. Both parameters can be set with sliders
in the right sidepanel (see \hyperref[\detokenize{setup:fig14}]{Fig.\@ \ref{\detokenize{setup:fig14}}}).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{setupAdditionalParameters}.png}
\caption{Sliders to set additional parameters for the SDC problem}\label{\detokenize{setup:fig14}}\label{\detokenize{setup:id5}}\end{figure}


\subsection{Alpha}
\label{\detokenize{setup:alpha}}
The parameter alpha is used to compute the frequencies of keys, which is used to compute risk
measures for categorical key variables. Alpha is the weight with which a key that coincides
based on a missing value (NA) contributes to these frequencies. The default value of the
parameter alpha is 1, which means that two records that have the same key (combination
of values in key variables), are considered to coincide completely.


\subsection{Seed}
\label{\detokenize{setup:seed}}
Every time a probabilistic method is used, a different outcome is generated. For these
methods it is often recommended that a seed be set for the random number generator
if you want to produce replicable results. The seed is used to initialize the
random number generator used for probabilistic methods. In \sphinxstyleemphasis{sdcApp}, the seed can
be set to any integer value from 0 to 500. To select a value, you can click with
the mouse pointer on the slider and use the arrow keys (left and right or up and down)
to select an exact value. In \hyperref[\detokenize{setup:fig14}]{Fig.\@ \ref{\detokenize{setup:fig14}}} the seed is set at 388.

\begin{sphinxadmonition}{note}{Note:}
In order to replicate exact results when using probabilistic methods, the order in
which the methods are carried out influences the results. Therefore, besides the seed,
also the order of the operations needs to be the same. The seed changes when used in
the random number generator. When the undo button is used (see ), the seed is not
reset to the value prior to the reverted step.
\end{sphinxadmonition}


\section{Summary view}
\label{\detokenize{setup:summary-view}}
After setting up the SDC problem, the application jumps automatically to the summary
view of the \sphinxstyleemphasis{Anonymize} tab. When an SDC problem is available, the \sphinxstyleemphasis{Anonymize} tab
provides a summary of the SDC problem and allows to apply anonymization methods.

This tab first shows a Summary overview of the problem. The content of the summary page varies with
the SDC problem. For example, if no numerical key variables were selected, the information on
numeric key variables is omitted. Fig shows the summary page.

\begin{sphinxadmonition}{note}{Note:}
Once the SDC problem is set up, it is possible and highly recommended to save
the SDC problem. By saving the SDC problem, you can reload the problem including
the preparation steps and variable selection in case of issues with sdcApp or
to revert to this ‘clean’ state without any methods applied in order to compare several
methods.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Note:}
If you would like to change the variable selection after setting up the SDC problem,
click the red button {[}add png{]}. By doing so, you need to respecify the full variable selection.
\end{sphinxadmonition}


\chapter{Risk measurement}
\label{\detokenize{risk::doc}}\label{\detokenize{risk:risk-measurement}}

\section{Summary view}
\label{\detokenize{risk:summary-view}}

\subsection{Global risk measure}
\label{\detokenize{risk:global-risk-measure}}
For categorical variables


\subsection{\protect\(k\protect\)-anonymity}
\label{\detokenize{risk:anonymity}}
The risk measure \(k\)-anonymity is based on the principle that, in a safe
dataset, the number of individuals sharing the same combination of
values (keys) of categorical quasi-identifiers should be higher than a
specified threshold \(k\). \(k\)-anonymity is a risk
measure based on the microdata to be released, since it only takes the
sample into account. An individual violates \(k\)-anonymity if the
sample frequency count \(f_{k}\) for the key \(k\) is smaller
than the specified threshold \(k\). For example, if an
individual has the same combination of quasi-identifiers as two other
individuals in the sample, these individuals satisfy 3-anonymity but
violate 4-anonymity. In the dataset, six individuals
satisfy 2-anonymity and four violate 2-anonymity. The individuals that
violate 2-anonymity are sample uniques. The risk measure is the number
of observations that violates k-anonymity for a certain value of \sphinxstyleemphasis{k},
which is
\begin{equation*}
\begin{split}\sum_{i}^{}{I(f_{k} < k)},\end{split}
\end{equation*}
where \(I\) is the indicator function and \(i\) refers to the
\(i\)$^{\text{th}}$ record. This is simply a count of the number of
individuals with a sample frequency of their key lower than \(k\).
The count is higher for larger \(k\), since if a record satisfies
\(k\)-anonimity, it also satisfies \((k + 1)\)-anonimity. The
risk measure \(k\)-anonymity does not consider the sample weights,
but it is important to consider the sample weights when determining the
required level of \(k\)-anonymity. If the sample weights are large,
one individual in the dataset represents more individuals in the target
population, the probability of a correct match is smaller, and hence the
required threshold can be lower. Large sample weights go together with
smaller datasets. In a smaller dataset, the probability to find another
record with the same key is smaller than in a larger dataset. This
probability is related to the number of records in the population with a
particular key through the sample weights.

In the summary view

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{summary_k_anon}.png}
\caption{Information on \(k\)-anonymity violators in summary view}\label{\detokenize{risk:fig71}}\label{\detokenize{risk:id2}}\end{figure}


\subsection{Risk measures for numerical key variables}
\label{\detokenize{risk:risk-measures-for-numerical-key-variables}}

\subsection{Household risk}
\label{\detokenize{risk:household-risk}}
If household identifier is selected, household risk will automatically be displayed.


\section{Detailed view}
\label{\detokenize{risk:detailed-view}}
The Risk/Utility tab provides more detailed information on risk measures and records at
(high) risk.


\subsection{Risky observations}
\label{\detokenize{risk:risky-observations}}

\subsection{SUDA}
\label{\detokenize{risk:suda}}
The SUDA algorithm identifies all the MSUs in the sample, which in turn
are used to assign a SUDA score to each record. This score indicates how
“risky” a record is. The potential risk of the records is determined
based on two observations:
\begin{itemize}
\item {} 
The smaller the size of the MSU within a record (i.e., the fewer
variables are needed to reach uniqueness), the greater the risk of
the record

\item {} 
The larger the number of MSUs possessed by a record, the greater the
risk of the record

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{risk_suda_setup}.png}
\caption{Compute SUDA scores}\label{\detokenize{risk:id1}}\label{\detokenize{risk:id3}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{risk_suda_result}.png}
\caption{Result of SUDA calculation}\label{\detokenize{risk:fig72}}\label{\detokenize{risk:id4}}\end{figure}


\subsection{l-diversity}
\label{\detokenize{risk:l-diversity}}
A dataset
satisfies \(l\)-diversity if for every key \(k\) there are at least
\(l\) different values for each of the sensitive variables. In the
example, the first two individuals satisfy only 1-diversity, individuals
4 and 6 satisfy 2-diversity. The required level of \(l\)-diversity
depends on the number of possible values the sensitive variable can
take. If the sensitive variable is a binary variable, the highest level
if \(l\)-diversity that can be achieved is 2. A sample unique will
always only satisfy 1-diversity.

To compute \(l\)-diversity for sensitive variables in sdcApp


\subsection{k-anonymity}
\label{\detokenize{risk:k-anonymity}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{summary_k_anon}.png}
\caption{Information on \(k\)-anonymity violators for any level of \(k\)}\label{\detokenize{risk:fig73}}\label{\detokenize{risk:id5}}\end{figure}


\chapter{Anonymization methods}
\label{\detokenize{anon::doc}}\label{\detokenize{anon:anonymization-methods}}
Once the disclosure risk is evaluated and is too high for release, SDC methods need
to be applied to the variables to reduce the risk. This process is iterative, i.e.,
after applying a certain method with a set of parameters, the disclosure risk
needs to be reassessed and the information loss needs to be evaluated. If the result is not
satisfactory, other methods can be applied to other variables. It is also possible to
undo the method (see \sphinxhref{undo.html}{Undo}) and reapply the same method with a different set of parameters.

In this section, we provide a brief description of common SDC methods for microdata and
show how to use these in \sphinxstyleemphasis{sdcApp}. For more information on the choice of the
appropriate method and more detailed information on the methods themselves, we refer to
the respective section in the SDC theory guide (link).


\section{Recoding}
\label{\detokenize{anon:recoding}}

\subsection{Global recoding}
\label{\detokenize{anon:global-recoding}}
Global recoding combines several categories (levels) of a categorical variable or constructs
intervals for continuous variables. This reduces the number of categories available
in the data and potentially the disclosure risk, especially for categories with few
observations, but also, importantly, it reduces the level of detail of information
available to the analyst.

In order to perform global recoding in \sphinxstyleemphasis{sdcApp}, navigate to on the \sphinxstylestrong{Anonymize} tab and
select \sphinxstylestrong{Recoding} from the left sidebar. First select the variable to be recoded. In the
example in \hyperref[\detokenize{anon:fig81}]{Fig.\@ \ref{\detokenize{anon:fig81}}} the semi-continuous variable age is selected. Only
variables selected as categorical key variables in the problem setup can be recoded here.

add: distribution is shown to determine breaks: refer to theory guide, also add in screenshot

Next select all the existing levels in the variable to be combined. In the example, we
select all values of age equal or larger to 85. Behind each value the number of observations
in the dataset with this value is displayed. The label of the variable to be created
is by default the concatenation of the labels of all combined values (85\_88\_90\_95), but can
be changed to any string. In the example the new label is 85+.

In case the system missing value (:code:NA) should be included in the newly created level,
set the option Add missing values to new factor level? to Yes. This could be for example
useful if a new group is created combining other and not applicable.
The default of this option is No.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{anonGlobalRecodeSettings}.png}
\caption{Settings for global recoding to recode the variable age}\label{\detokenize{anon:fig81}}\label{\detokenize{anon:id1}}\end{figure}

After selecting the variable, levels and specifying a new label the variable is recoded
by clicking Recode key variable. The risk measures are immediately updated once the method
is applied.

\begin{sphinxadmonition}{note}{Note:}
When exploring the recoded variable, the old levels still appear in the
frequency table. They stay in the variable with 0 observations.
\end{sphinxadmonition}

For each group (new level), this process needs to be repeated. If, for example, age should
be recoded in 5-year age bands, these steps need to be carried out for each 5-year
age group separately.

\begin{sphinxadmonition}{tip}{Tip:}
Global recoding for a variable with many different levels, such as age, can be a
daunting task in \sphinxstyleemphasis{sdcApp}, as it involves many clicks and is prone to making mistakes.
As an alternative, one could perform the recoding in another statistical software
before loading the data in \sphinxstyleemphasis{sdcApp}. This would influence the initial risk levels.
\end{sphinxadmonition}

add: Variables can already be recoded before on data tab


\subsection{Top and bottom coding}
\label{\detokenize{anon:top-and-bottom-coding}}
Top and bottom coding are similar to global recoding, but instead of recoding all values,
only the top and/or bottom values of the distribution or categories are recoded. This can
be applied only to ordinal categorical variables and (semi-)continuous variables, since
the values have to be at least ordered. Top and bottom coding is especially useful if
the bulk of the values lies in the center of the distribution with the peripheral
categories having only few observations (outliers). Examples are age and income; for
these variables, there will often be only a few observations above certain thresholds,
typically at the tails of the distribution. The fewer the observations within a category,
the higher the identification risk. One solution could be grouping the values at the tails
of the distribution into one category. This reduces the risk for those observations, and,
importantly, does so without reducing the data utility for the other observations in the
distribution.

In order to perform top or bottom coding in \sphinxstyleemphasis{sdcApp}, navigate to on the \sphinxstylestrong{Anonymize}
tab and select \sphinxstylestrong{Top/bottom coding} from the left sidebar. First select the variable
to be recoded. In the example in \hyperref[\detokenize{anon:fig82}]{Fig.\@ \ref{\detokenize{anon:fig82}}} the continuous variable income
is selected. Only variables of type numeric can be top or bottom coded.

add: boxplot to check distribution

\begin{sphinxadmonition}{note}{Note:}
Top and bottom coding ca only be applied to numeric variables. If age, as in our example,
is converted to factor, the global recoding method needs to be used, in order to
topcode age by grouping all values above the threshold.
\end{sphinxadmonition}

Next select top or bottom coding. In case of top coding all values above the set threshold
are replaced, in case of bottom coding all values below the set threshold are replaced.
Set the threshold value and replacement value by entering these in the numeric fields.
After entering the threshold and replacement values, the number of records with values
below/above the threshold that are replaced is shown.

\begin{sphinxadmonition}{note}{Note:}
It is advised to use a replacement value different than the threshold value,
such as the weighted mean or median to reduce information loss. The replacement
value needs to be computed in a different software and manually inserted in \sphinxstyleemphasis{sdcApp}.
\end{sphinxadmonition}

After selecting the variable, type and specifying the threshold and replacement values,
the variable is topcoded by clicking Apply Top/Bottom-Coding. The risk measures are
automatically updated after the method is applied.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{anonTopcodingSettings}.png}
\caption{Settings for topcoding the variable income at 8 million}\label{\detokenize{anon:fig82}}\label{\detokenize{anon:id2}}\end{figure}


\section{k-Anonymity / local suppression}
\label{\detokenize{anon:k-anonymity-local-suppression}}
It is common in surveys to encounter values for certain variables or combinations
of quasi-identifiers (keys) that are shared by very few individuals. When this occurs,
the risk of re-identification for those respondents is higher than the rest of the
respondents. Often local suppression is used after
reducing the number of keys in the data by recoding the appropriate variables.
Recoding reduces the number of necessary suppressions as well as the computation
time needed for computing the suppression pattern. Suppression of values means that values of a variable
are replaced by a missing value (NA in R). The the Section k-anonymity discusses how
missing values influence frequency counts and k-anonymity.

In order to perform local suppression to achieve k-anonymity in \sphinxstyleemphasis{sdcApp},
navigate to on the \sphinxstylestrong{Anonymize} tab and select \sphinxstylestrong{k-Anonimity} from the left sidebar.
Local suppression is always performed on the complete set off selected categorical
key variables.

In order to apply the default local suppression algorithm, the user only needs to set the
level of k to be achieved.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{anonLocSupSettings}.png}
\caption{Settings for local suppression to achieve 3-anonimity}\label{\detokenize{anon:fig83}}\label{\detokenize{anon:id3}}\end{figure}

add: overview of suppressions /suppression patterns


\subsection{Importance}
\label{\detokenize{anon:importance}}
By default the algorithm considers variables with many different levels first. Therefore,
it is more likely that these variables will contain suppressed values. Sometimes variables
with many different levels are important for the

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{anonLocSupSettingsImportance}.png}
\caption{Importance settings for local suppression}\label{\detokenize{anon:fig84}}\label{\detokenize{anon:id4}}\end{figure}


\subsection{Subsets}
\label{\detokenize{anon:subsets}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{anonLocSupSettingsSubset}.png}
\caption{Subset settings for local suppression}\label{\detokenize{anon:fig85}}\label{\detokenize{anon:id5}}\end{figure}


\bigskip\hrule\bigskip



\section{PRAM}
\label{\detokenize{anon:pram}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{anonPRAMsettings}.png}
\caption{Settings for PRAM}\label{\detokenize{anon:fig86}}\label{\detokenize{anon:id6}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{anonPRAMsettingsMatrix}.png}
\caption{Settings for PRAM with customized transition matrix}\label{\detokenize{anon:fig87}}\label{\detokenize{anon:id7}}\end{figure}


\section{Suppress values with high risk}
\label{\detokenize{anon:suppress-values-with-high-risk}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{anonSuppressSettings}.png}
\caption{Settings for suppressing values in records with high risk}\label{\detokenize{anon:fig88}}\label{\detokenize{anon:id8}}\end{figure}


\section{Top/Bottom coding}
\label{\detokenize{anon:top-bottom-coding}}

\section{Microaggregation}
\label{\detokenize{anon:microaggregation}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{anonMicroaggregationSettingsCluster}.png}
\caption{Settings for microaggregation}\label{\detokenize{anon:fig89}}\label{\detokenize{anon:id9}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{anonMicroaggregationSettingsAdditional}.png}
\caption{Additional settings for microaggregation}\label{\detokenize{anon:fig810}}\label{\detokenize{anon:id10}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{anonMicroaggregationSettingsCluster}.png}
\caption{Cluster settings for microaggregation}\label{\detokenize{anon:fig811}}\label{\detokenize{anon:id11}}\end{figure}


\section{Adding noise}
\label{\detokenize{anon:adding-noise}}

\section{Rank swapping}
\label{\detokenize{anon:rank-swapping}}

\section{Undo}
\label{\detokenize{anon:undo}}
Finding an anonymization strategy for a microdata dataset is a trial-and-error process.
The effect on risk and utility of different methods with different parameter settings can
only be assessed by executing the methods on the actual dataset. Therefore, it is unlikely
to find a satisfactory anonymization strategy at the first attempt. Before another method
is applied, the previous method needs to be canceled. In \sphinxstyleemphasis{sdcApp} it is possible
to undo the last method applied with one click. To test the effect of a combination
of several methods, which is recommended, it is necessary to cancel several steps.
To do so, the state of the SDC problem before applying the methods is saved to disk and can
be reloaded afterwards. This is the same as canceling several steps. Both methods are
described below.


\subsection{Undo one step}
\label{\detokenize{anon:undo-one-step}}
In order to undo one step,

risk measures etc are also reset, script not, random seed not


\subsection{Undo several steps}
\label{\detokenize{anon:undo-several-steps}}
Recommended to

Save and reload


\chapter{Utility measurement}
\label{\detokenize{utility:utility-measurement}}\label{\detokenize{utility::doc}}

\section{General utility measures in \sphinxstyleemphasis{sdcApp}}
\label{\detokenize{utility:general-utility-measures-in-sdcapp}}

\subsection{Compare summary statistics}
\label{\detokenize{utility:compare-summary-statistics}}

\subsubsection{Categorical variables}
\label{\detokenize{utility:categorical-variables}}

\subsubsection{Continuous variables}
\label{\detokenize{utility:continuous-variables}}

\subsection{IL1s measure}
\label{\detokenize{utility:il1s-measure}}

\section{Customized utility measures}
\label{\detokenize{utility:customized-utility-measures}}
As the statistical analyses based on the microdata depend, amongst others,
on to the topic of the survey, the country and the definition of the variables,
it is not feasible to include all these measures in \sphinxstyleemphasis{sdcApp}. Instead, it is recommended
to compute the statistics and indicators and perform statistical an econometric
analyses on the original and anonymized datasets and evaluate the differences in the results.
If a publication based on the microdata is already published, it is recommended
to recompute the statistics in these publications from the anonymized dataset.

The approach is to compare the indicators calculated on the untreated data and the
data after anonymization with different methods. If the differences between the
indicators are not too large, the anonymized dataset can be released for use by
researchers. It should be taken into account that indicators calculated on samples
are estimates with a certain variance and confidence interval. Therefore, for sample
data, it is more informative to compare the overlap of confidence intervals and/or
to evaluate whether the point estimate calculated after anonymization is contained
within the confidence interval of the original estimate.

\begin{sphinxadmonition}{note}{Note:}
Some analyses may no longer be possible or not possible in exactly the same way.
E.g. regression on age if age is recoded in 5-year intervals.
\end{sphinxadmonition}

In order to do so, it is posible to export the dataset at any point in \sphinxstyleemphasis{sdcApp}.
See Export dataset. Several datasets can be exported after applying different methods
with different parameters settings to compare the information loss resulting from
the anonymization. This information can be used to select the anonymization methods
as well as to inform the user about the implications of the anonymization on
the validity of the dataset for analysis.


\chapter{Export data and reports}
\label{\detokenize{export::doc}}\label{\detokenize{export:export-data-and-reports}}

\section{Export anonymized dataset}
\label{\detokenize{export:export-anonymized-dataset}}
\sphinxstyleemphasis{sdcApp} supports datasets in several foreign data formats. The file formats that are
supported for loading microdata are also supported for export (cf. \hyperref[\detokenize{export:tab101}]{Table \ref{\detokenize{export:tab101}}}).

In order to export the file, click on  \sphinxstylestrong{Anonymized Data} in the left sidebar on the
\sphinxstylestrong{Export Data} tab. The dataset shown is the file as it will be exported. Select the
appropriate file format with the radiobuttons underneath the data.

In case the microdata is exported as csv or STATA file, additional options need to
be specified. For a csv file, whether first row should include column names,
the field separator as well as the decimal separator. For STATA files, the version of STATA
needs to be specified. STATA cannot STATA files saved for a higher version.

Option to randomize the order of the records. Order may reveal values, e.g.
ordered by region with suppressed region value Need to replace existing ID

In order to export the dataset, click on blue button \sphinxstylestrong{Save dataset}. The dataset is saved
to the

By clicking on the blue button Save script to file at the top of the page, the script is
saved as R script (extension .R) on disk to the selected storage path on the
About/Help tab (see Introduction to sdcApp). The filename of the exported script
starts with ‘exportedScript\_sdcMicro’ followed by a date and time stamp, e.g.,
‘exportedScript\_sdcMicro\_20181010\_1212.R’.
, exported two with file name… Exported to

the microdata, select


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Data formats compatible with sdcApp}\label{\detokenize{export:tab101}}\label{\detokenize{export:id1}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Software
&\sphinxstyletheadfamily 
File extension
\\
\hline
R/RStudio
&
.rdata
\\
\hline
SPSS
&
.sav
\\
\hline
SAS
&
.sas7bdat
\\
\hline
CSV
&
.csv, .txt
\\
\hline
STATA
&
.dta
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Also for intermediate export
\begin{description}
\item[{..NOTE::}] \leavevmode
Categorical variables (type factor in \sphinxstyleemphasis{sdcApp}) that were had a value and a
label in the input dataset are

labels (variable, value), coding 0,1 to 1,2 etc.

\end{description}

Extra for STATA input files: change variable labels for STATA files


\section{Exporting reports}
\label{\detokenize{export:exporting-reports}}
It is extremely important to document the SDC process of microdata both for internal
use as well as for external use. The internal report should contain detailed descriptions
of all steps carried out as well as reasoning for

Generic drafts of both an


\subsection{Internal report}
\label{\detokenize{export:internal-report}}
An important step in the SDC process is reporting, both internal and external.
Internal reporting contains the exact description of anonymization methods used,
parameters but also the risk measures before and after anonymization. This allows
replication of the anonymized dataset and is important for supervisory authorities/bodies
to ensure the anonymization process is sufficient to guarantee anonymity according
to the applicable legislation.

Report is just technical overview, not complete

file path, name of file

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{exportReportInternal}.png}
\caption{Exporting an internal report}\label{\detokenize{export:fig103}}\label{\detokenize{export:id2}}\end{figure}


\subsection{External report}
\label{\detokenize{export:external-report}}
The external report informs the user that the data has been anonymized,
provides information for valid analysis on the data and explains the limitations to
the data as a result of the anonymization. A brief description of the methods used
can be included. The release of anonymized microdata should be accompanied by the
usual metadata of the survey (survey weight, strata, survey methodology) as well as
information on the anonymization methods that allow researchers to do valid analysis
(e.g., amount of noise added, transition matrix for PRAM).

file path, name of file

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{exportReportExternal}.png}
\caption{Exporting an external report}\label{\detokenize{export:fig104}}\label{\detokenize{export:id3}}\end{figure}


\chapter{Reproducibility}
\label{\detokenize{reproducibility::doc}}\label{\detokenize{reproducibility:reproducibility}}
Reproducibility is key to the SDC process, as …


\section{Exporting \sphinxstyleemphasis{R} script}
\label{\detokenize{reproducibility:exporting-r-script}}
\sphinxstyleemphasis{sdcApp} is a GUI for the \sphinxstyleemphasis{R} package \sphinxstyleemphasis{sdcMicro}. All steps executed in \sphinxstyleemphasis{sdcApp} are translated
into \sphinxstyleemphasis{R} commands. Therefore, the full anonymization can also be performed from command-line
in \sphinxstyleemphasis{R}. While carrying out the anonymization process, the code to perform the same action
from command-line is generated. The code can be viewed and exported on the \sphinxstylestrong{Reproducibility}
tab by selecting \sphinxstylestrong{View the current script} from the left sidebar (cf. \hyperref[\detokenize{reproducibility:fig111}]{Fig.\@ \ref{\detokenize{reproducibility:fig111}}}).
The script also contains comments, which are the lines starting with the hash tag (\sphinxcode{\sphinxupquote{\#}}).
These comments are meant to help with the interpretation of the code blocks.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{reproScript}.png}
\caption{\sphinxstyleemphasis{R} script to reproduce anonymization process after setting up SDC problem}\label{\detokenize{reproducibility:fig111}}\label{\detokenize{reproducibility:id5}}\end{figure}

The goal of the \sphinxstyleemphasis{R} script is threefold:
1) To reproduce the steps taken in the anonymization process. This guarantees
the reproducibility, since the all variabele selections and parameters are contained in the
code and the order of the application of different methods is preserved in the code.
2) As a starting point to learn \sphinxstyleemphasis{R} and use \sphinxstyleemphasis{sdcMicro} from \sphinxstyleemphasis{R} command-line. Especially for
users with some degree of familiarity with \sphinxstyleemphasis{R}, the script
3) To rerun the same methods with different parameter settings without the need to make
all selections by mouseclick in the GUI. It’s relatively easy to change the parameter settings
in the \sphinxstyleemphasis{R} code and rerun the code. However, the code does not include commands to shw
the results.

By clicking on the blue button \sphinxstylestrong{Save script to file} at the top of the page, the script
is saved as \sphinxstyleemphasis{R} script (extension .R) on disk to the selected storage path on the
\sphinxstylestrong{About/Help} tab (see \sphinxhref{introsdcApp.html}{Introduction to sdcApp}).
The filename of the exported script starts with ‘exportedScript\_sdcMicro’ followed
by a date and time stamp, e.g., ‘exportedScript\_sdcMicro\_20181010\_1212.R’.

In order to run the script in \sphinxstyleemphasis{R}, open the saved script in \sphinxstyleemphasis{RStudio}. The only
thing to do is to change the path of the input file to the actual file path on your computer.
In the second line of the \sphinxstyleemphasis{R} script,

\begin{sphinxadmonition}{note}{Note:}
In case a method was applied in \sphinxstyleemphasis{sdcApp} and subsequently reverted by using the \sphinxstylestrong{Undo}
button, the method is not erased from the script, but rather the undo command is added.
For example, if local suppression was applied and reverted, this appears as follows in
the script:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Local suppression to obtain k\PYGZhy{}anonymity}
sdcObj \PYG{o}{\PYGZlt{}\PYGZhy{}} kAnon\PYG{p}{(}sdcObj\PYG{p}{,} importance\PYG{o}{=}\PYG{k+kt}{c}\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{)}\PYG{p}{,} combs\PYG{o}{=}\PYG{k+kc}{NULL}\PYG{p}{,} k\PYG{o}{=}\PYG{k+kt}{c}\PYG{p}{(}\PYG{l+m}{3}\PYG{p}{)}\PYG{p}{)}
sdcObj \PYG{o}{\PYGZlt{}\PYGZhy{}} undolast\PYG{p}{(}sdcObj\PYG{p}{)}
\end{sphinxVerbatim}

This code preceding the :code:{\color{red}\bfseries{}{}`}undoLast{}`command and the :code:{\color{red}\bfseries{}{}`}undoLast{}`command
can be deleted without changing the results.
\end{sphinxadmonition}


\chapter{Undo}
\label{\detokenize{undo:undo}}\label{\detokenize{undo::doc}}
Microdata anonymization is a trial-and-error process. It is necessary to several
methods, each with different parameter settings, to find optimal set of
anonymization measures that minimize the information loss, while reducing the risk of
disclosure to an acceptable level. Before applying an alternative method to the same
variable or set of variables, it is important to undo the previously applied methods.
Only in this way, it is possible to compare the effect on risk and information
loss of a particular method or parameter setting. For instance to compare the
effect of recoding the age variable in 5 or 10 year intervals, it is necessary to first
undo the recoding in 5-year intervals before recoding in 10 year intervals.

In \sphinxstyleemphasis{sdcApp} it is possible to undo the last anonymization step. In order to undo several
steps, it is required to save and reload the SDC problem. Both ways are explained below.


\section{Undo one step}
\label{\detokenize{undo:undo-one-step}}
In order to undo one step, go to the \sphinxstylestrong{Undo} tab.
The screen shows

risk measures etc are also reset, script not (completely), random seed not


\section{Undo several steps}
\label{\detokenize{undo:undo-several-steps}}
Save and reload

Recommended to save the SDC problem after each method to be able to reload. This is also
practical if \sphinxstyleemphasis{sdcApp} or \sphinxstyleemphasis{R} crash. Also useful to continue working at a later point of
transfer a problem to a different computer


\subsection{Save a previously saved problem}
\label{\detokenize{undo:save-a-previously-saved-problem}}

\subsection{Load a previously saved problem}
\label{\detokenize{undo:load-a-previously-saved-problem}}
\begin{sphinxadmonition}{note}{Note:}
sdcApp exports four different file types
Different file names for different files (data, sdcProblem)
\end{sphinxadmonition}


\chapter{Case Studies (Illustrating the SDC Process)}
\label{\detokenize{casestudies::doc}}\label{\detokenize{casestudies:case-studies-illustrating-the-sdc-process}}
In order to evaluate the use of different SDC methods on different types
of survey datasets, we compared the results of the different methods
applied to 75 datasets from 52 countries representing six geographic
regions: Latin America and the Caribbean (LAC), Sub-Saharan Africa
(AFR), South Asia (SA), Europe and Central Asia (ECA), Middle East and
North Africa (MENA) as well as East Asia and the Pacific (EAP). The
datasets chosen were from a mix of datasets that are already publically
available, as well as data made available to the World Bank.
The surveys used included, amongst others, household,
demographic, and health surveys. The variables from these surveys used
for the experiments were selected based on their relevance for users
(e.g., for indicators, MDGs), their sensitivity, and their classification
with respect to the SDC process.

The following case studies draw from knowledge gained from these
experiments and try to incorporate the lessons learned. The case studies
use synthetic data that mimic the structure of the survey types we used
in our experiments and present the anonymization of a dataset similar to
many surveys designed to measure household income and consumption, labor
force participation and general demographic characteristics. The first
case study creates a SUF, whereas in the second case study we take this
SUF and treat it further to create a PUF.


\section{Case study 1- SUF}
\label{\detokenize{casestudies:case-study-1-suf}}
This case study shows an example of how the anonymization process might
be approached, particularly for a dataset with many continuous
variables. We also show how this can be achieved using \sphinxstyleemphasis{sdcApp}, the GUI for
the open source and free \sphinxstyleemphasis{sdcMicro} \sphinxstyleemphasis{R} package.

\begin{sphinxadmonition}{note}{Note:}
The choices of methods and parameters in
this case study are based on this particular dataset and the results and
choices might be different for other datasets.
\end{sphinxadmonition}

The aim is to show the process, not to compare methods per se.

This example uses a dataset with a similar structure to that of a
typical social survey with a focus on demographics, labor force
participation and income and expenditure patterns. The dataset has been
compiled using observations from several datasets from different
countries. They are considered synthetic data and as such are used only
for illustrative purposes. The source datasets were already treated for
disclosure control by their producers. This does not matter, as our
concern is to illustrate the process only. The data from which we
compiled our case study file was from surveys that contain many
variables, but pay particular attention to labor force variables as well
as household income and household expenditure variables. The variables
in the demo dataset have already been pre-selected from the total set of
variables available in the datasets. See
\sphinxhref{appendices.html\#AppendixA:OverviewofCaseStudyVariables}{Appendix A}
for the complete overview of all variables.

This case study follows the steps of the SDC process outlined in the Section
\sphinxhref{process.html}{The SDC Process}.


\subsection{Step 1: Need for disclosure control}
\label{\detokenize{casestudies:step-1-need-for-disclosure-control}}
The statistical units in this dataset are individuals and households.
The household structure provides a hierarchical structure in the data,
which should be taken into account when measuring risk and selecting
anonymization methods.

The data contains variables with demographic information, income,
expenditures, education variables and variables relating to the labor
status of the individual. These variables include sensitive and
confidential variables. The dataset is an example of a social survey
and, due to the nature of the statistical units and the variables,
disclosure control is needed before release of the microdata. This is
the case regardless of the legal framework, which is not specified here,
as this is a hypothetical dataset.


\subsection{Step 2: Data preparation and exploring data characteristics}
\label{\detokenize{casestudies:step-2-data-preparation-and-exploring-data-characteristics}}
The first step is to explore the data. First launch \sphinxstyleemphasis{sdcApp} and specify the
output directory (see the Section
{\color{red}\bfseries{}{}`Starting sdcApp \textless{}introsdcApp.html\#Starting sdcApp{}`\_\_}). To analyze the data in \sphinxstyleemphasis{sdcApp} we
first have to load the dataset.
In our case, the data is saved as a \sphinxstyleemphasis{STATA} file (.dta file). (see the Section
\sphinxhref{loadprepdata.html\#Loadingdata}{Loading data}
on importing data in \sphinxstyleemphasis{sdcApp}). Load the dataset case\_1\_data.dta with the default
options for string conversion and dropping variables with only missing values.
After loading the dataset, the dataset is shown in the Microdata tab.

On top of the table we can check the name of the loaded dataset,
the number of variables and the number of
observation, as shown in \hyperref[\detokenize{casestudies:fig131}]{Fig.\@ \ref{\detokenize{casestudies:fig131}}}. Note that the variables ETHNICITY and
LANGUAGE were dropped due to all missing values in these variables. The loaded
dataset contains 10,574 observations and 66 variables.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{case1LoadedData}.png}
\caption{Microdata tab after loading case study dataset}\label{\detokenize{casestudies:fig131}}\label{\detokenize{casestudies:id17}}\end{figure}

The dataset has 10,574 individuals in 2,000 households and contains 68
variables. The survey corresponds to a population of about 4.3 million
individuals, which means that the sample is relatively small and the
sample weights are high. This has an impact on the disclosure risk, as
we will see in Steps 6a and 6b.

To get an overview of the values of the variables, we use tabulations
and cross-tabulations for categorical variables and summary statistics
for continuous variables. To include the number of missing values (NA or
other), we use the option useNA = “ifany” in the table() function (see \sphinxcode{\sphinxupquote{code94}}).

In \hyperref[\detokenize{casestudies:tab91}]{Table \ref{\detokenize{casestudies:tab91}}} the variables in the dataset are listed along with concise
descriptions of the variables, the level at which they are collected
(individual (IND), household (HH)), the measurement type (continuous,
semi-continuous, categorical) and value ranges. Note that the dataset
contains a selection of 68 variables (cf. \sphinxhref{appendices.html\#AppendixA:OverviewofCaseStudyVariables}{Appendix A}) of a total of 112
variables in the survey dataset. The variables have been preselected
based on their relevance for data users. This allows to reduce the total
numbers of variables to consider in the anonymization process and makes
the process easier. The numerical values for many of the categorical
variables are codes that refer to values, e.g., in the variable URBRUR,
1 stands for rural and 2 for urban. More information on the meanings of
coded values of the categorical variables is available in the \sphinxstyleemphasis{R} code
for this case study.

We identified the following sensitive variables in the data: ETHNICITY,
RELIGION, variables related to the labor force status of the individual
and the variables containing information on income and expenditures of
the household. Whether variables can be identified as sensitive may vary
across countries and datasets.

The case study dataset does not have any direct identifiers that, if
they were present, would need to be removed at this stage. Examples of
direct identifiers would be names, telephone numbers, geographical
location coordinates, etc.

Before exploring the data, the variable type of all variables needs to be checked and,
if necessary, be adapted. Categorical key variables need to be of type \sphinxstyleemphasis{factor} and
continuous key variables need to be of type \sphinxstyleemphasis{numeric}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{case1ExploreVarType}.png}
\caption{Check variable type}\label{\detokenize{casestudies:fig132}}\label{\detokenize{casestudies:id18}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{case1ExploreCat}.png}
\caption{Summary statistics for categorical variable, example  variable ‘gender’}\label{\detokenize{casestudies:id1}}\label{\detokenize{casestudies:id19}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{case1ExploreCont}.png}
\caption{Summary statistics for continuous variable, example variable ‘total annual expenditures’}\label{\detokenize{casestudies:id2}}\label{\detokenize{casestudies:id20}}\end{figure}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{|l|l|l|l|l|l|}
\caption{Overview of variables in dataset\strut}\label{\detokenize{casestudies:tab91}}\label{\detokenize{casestudies:id21}}\\*[\sphinxlongtablecapskipadjust]
\hline
\sphinxstyletheadfamily 
No.
&\sphinxstyletheadfamily 
Variable name
&\sphinxstyletheadfamily 
Description
&\sphinxstyletheadfamily 
Level
&\sphinxstyletheadfamily 
Measurement
&\sphinxstyletheadfamily 
Values
\\
\hline
\endfirsthead

\multicolumn{6}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} -- continued from previous page}}}\\
\hline
\sphinxstyletheadfamily 
No.
&\sphinxstyletheadfamily 
Variable name
&\sphinxstyletheadfamily 
Description
&\sphinxstyletheadfamily 
Level
&\sphinxstyletheadfamily 
Measurement
&\sphinxstyletheadfamily 
Values
\\
\hline
\endhead

\hline
\multicolumn{6}{r}{\makebox[0pt][r]{\sphinxtablecontinued{Continued on next page}}}\\
\endfoot

\endlastfoot

1
&
IDH
&
Household ID
&
HH
&
.
&
1-2,000
\\
\hline
2
&
IDP
&
Individual ID
&
IND
&
.
&
1-33
\\
\hline
3
&
REGION
&
Region
&
HH
&
categorical
&
1-6
\\
\hline
4
&
DIST
&
District
&
HH
&
categorical
&
101-1105
\\
\hline
5
&
URBRUR
&
Area of residence
&
HH
&
categorical
&
1, 2
\\
\hline
6
&
WGTHH
&
Individual weighting coefficient
&
HH
&
weight
&
31.2-8495
\\
\hline
7
&
WGTPOP
&
Population weighting coefficient
&
IND
&
weight
&
45.8-93452.2
\\
\hline
8
&
HHSIZE
&
Household size
&
HH
&
semi-cont
&
1-33
\\
\hline
9
&
GENDER
&
Gender
&
IND
&
categorical
&
0, 1
\\
\hline
10
&
REL
&
Relationship to household head
&
IND
&
categorical
&
1-9
\\
\hline
11
&
MARITAL
&
Marital status
&
IND
&
categorical
&
1-6
\\
\hline
12
&
AGEYRS
&
Age in completed years
&
IND
&
semi-continuous
&
0-95 (under 1, 1/12 year increments)
\\
\hline
13
&
AGEMTH
&
Age of child in completed years
&
IND
&
semi-continuous
&
1-1140
\\
\hline
14
&
RELIG
&
Religion of household head
&
HH
&
categorical
&
1, 5-7, 9
\\
\hline
15
&
ETHNICITY
&
Ethnicity of household head
&
HH
&
categorical
&
all missing values
\\
\hline
16
&
LANGUAGE
&
Language of household head
&
HH
&
categorical
&
all missing values
\\
\hline
17
&
MORBID
&
Morbidity last x weeks
&
IND
&
categorical
&
0, 1
\\
\hline
18
&
MEASLES
&
Child immunized against measles
&
IND
&
categorical
&
0, 1, 9
\\
\hline
19
&
MEDATT
&
Sought medical attention
&
IND
&
categorical
&
0, 1
\\
\hline
20
&
CHWEIGHTKG
&
Weight of child (Kg)
&
IND
&
continuous
&
2 \textendash{} 26.5
\\
\hline
21
&
CHHEIGHTCM
&
Height of child (cms)
&
IND
&
continuous
&
7 - 140
\\
\hline
22
&
ATSCHOOL
&
Currently enrolled in school
&
IND
&
categorical
&
0, 1
\\
\hline
23
&
EDUCY
&
Highest
level of education attended
&
IND
&
categorical
&
1-6
\\
\hline
24
&
EDYRS
&
Years of education
&
IND
&
semi-continuous
&
0-18
\\
\hline
25
&
EDYRSCURRAT
&
Years of education
for currently enrolled
&
IND
&
semi-continuous
&
1-18
\\
\hline
26
&
SCHTYP
&
Type of
school attending
&
IND
&
categorical
&
1-3, 9
\\
\hline
27
&
LITERACY
&
Literacy
&
IND
&
categorical
&
1-3
\\
\hline
28
&
EMPTYP1
&
Type of employment
&
IND
&
categorical
&
1-9
\\
\hline
29
&
UNEMP1
&
Unemployed
&
IND
&
categorical
&
0, 1
\\
\hline
30
&
INDUSTRY1
&
Industry
classification (1-digit)
&
IND
&
categorical
&
1-10
\\
\hline
31
&
EMPCAT1
&
Employment categories
&
IND
&
categorical
&
11, 12, 13, 14, 21, 22
\\
\hline
32
&
WHOURSWEEK1
&
Hours worked last week
&
IND
&
continuous
&
0-154
\\
\hline
33
&
OWNHOUSE
&
Ownership of dwelling
&
HH
&
categorical
&
0, 1
\\
\hline
34
&
ROOF
&
Main material used for roof
&
IND
&
categorical
&
1-5, 9
\\
\hline
35
&
TOILET
&
Main toilet facility
&
HH
&
categorical
&
1-4, 9
\\
\hline
36
&
ELECTCON
&
Electricity
&
HH
&
categorical
&
0-3
\\
\hline
37
&
FUELCOOK
&
Main cooking fuel
&
HH
&
categorical
&
1-5, 9
\\
\hline
38
&
WATER
&
Main source of water
&
HH
&
categorical
&
1-9
\\
\hline
39
&
OWNAGLAND
&
Ownership of agricultural land
&
HH
&
categorical
&
1-3
\\
\hline
40
&
LANDSIZEHA
&
Land size owned by household
(ha) (agric and non agric)
&
HH
&
continuous
&
0-1214
\\
\hline
41
&
OWNMOTORCYCLE
&
Ownership of motorcycle
&
HH
&
categorical
&
0, 1
\\
\hline
42
&
CAR
&
Ownership of car
&
HH
&
categorical
&
0, 1
\\
\hline
43
&
TV
&
Ownership of television
&
HH
&
categorical
&
0, 1
\\
\hline
44
&
LIVESTOCK
&
Number of
large-sized livestock owned
&
HH
&
semi-continuous
&
0-25
\\
\hline
45
&
INCRMT
&
Income \textendash{} Remittances
&
HH
&
continuous
&\\
\hline
46
&
INCWAGE
&
Income - Wages and salaries
&
HH
&
continuous
&\\
\hline
47
&
INCBONSOCAL
&
Income - Bonuses and social
allowances derived from wage jobs
&
HH
&
continuous
&\\
\hline
48
&
INCFARMBSN
&
Income - Gross income
from household farm businesses
&
HH
&
continuous
&\\
\hline
49
&
INCNFARMBSN
&
Income - Gross income from
household nonfarm businesses
&
HH
&
continuous
&\\
\hline
50
&
INCRENT
&
Income - Rent
&
HH
&
continuous
&\\
\hline
51
&
INCFIN
&
Income - Financial
&
HH
&
continuous
&\\
\hline
52
&
INCPENSN
&
Income - Pensions/social assistance
&
HH
&
continuous
&\\
\hline
53
&
INCOTHER
&
Income - Other
&
HH
&
continuous
&\\
\hline
54
&
INCTOTGROSSHH
&
Income - Total
&
HH
&
continuous
&\\
\hline
55
&
FARMEMP
&&&&\\
\hline
56
&
TFOODEXP
&
Total expenditure on food
&
HH
&
continuous
&\\
\hline
57
&
TALCHEXP
&
Total expenditure on alcoholic
beverages, tobacco and narcotics
&
HH
&
continuous
&\\
\hline
58
&
TCLTHEXP
&
Total expenditure on clothing
&
HH
&
continuous
&\\
\hline
59
&
THOUSEXP
&
Total expenditure on housing
&
HH
&
continuous
&\\
\hline
60
&
TFURNEXP
&
Total expenditure on furnishing
&
HH
&
continuous
&\\
\hline
61
&
THLTHEXP
&
Total expenditure on health
&
HH
&
continuous
&\\
\hline
62
&
TTRANSEXP
&
Total expenditure on transport
&
HH
&
continuous
&\\
\hline
63
&
TCOMMEXP
&
Total expenditure on communication
&
HH
&
continuous
&\\
\hline
64
&
TRECEXP
&
Total expenditure on recreation
&
HH
&
continuous
&\\
\hline
65
&
TEDUEXP
&
Total expenditure on education
&
HH
&
continuous
&\\
\hline
66
&
TRESHOTEXP
&
Total expenditure on restaurants
and hotels
&
HH
&
continuous
&\\
\hline
67
&
TMISCEXP
&
Total expenditure on
miscellaneous spending
&
HH
&
continuous
&\\
\hline
68
&
TANHHEXP
&
Total annual nominal household
expenditures
&
HH
&
continuous
&\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}

It is always important to ensure that the relationships between
variables in the data are preserved during the anonymization process and
to explore and take note of these relationships before beginning the
anonymization. In the final step in the anonymization process, an audit
should be conducted, using these initial results, to check that these
relationships are maintained in the anonymized dataset.

In our demo dataset, we identify several relationships between variables
that need to be preserved during the anonymization process. The
variables TANHHEXP and INCTOTGROSSHH represent the total annual nominal
household expenditure and the total gross annual household income,
respectively, and these variables are aggregations of existing income
and expenditure components in the dataset.

The variables related to education are available only for individuals in
the appropriate age groups and missing for other individuals. We make a
similar observation for variables relating to children, such as height,
weight and age in months. In addition, the household-level variables
(cf. fourth column of \hyperref[\detokenize{casestudies:tab91}]{Table \ref{\detokenize{casestudies:tab91}}}) have the same values for all members in
any particular household. The value of household size corresponds to the
actual number of individuals belonging to that household in the dataset.
As we proceed, we have to take care that these relationships and
structures are preserved in the anonymization process.

When tabulating the variables, we notice that the variables RELIG,
EMPTYP1 and LIVESTOCK have missing value codes different from the \sphinxstyleemphasis{R}
standard missing value code NA. Before proceeding, we need to recode
these to NA so \sphinxstyleemphasis{R} interprets them correctly. The missing value codes
are resp. 99999, 99 and 9999 for these three variables. These are
genuine missing value codes and not caused by the variables being not
applicable to the individual. \hyperref[\detokenize{casestudies:code95}]{Listing \ref{\detokenize{casestudies:code95}}} shows how to make these
changes.

\begin{sphinxadmonition}{note}{Note:}
At the end of the anonymization process, and if desired
for users, it is relatively easy to change these values back to their
original missing value code.
\end{sphinxadmonition}

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code95}}}
\sphinxSetupCaptionForVerbatim{Recoding missing value codes}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Set different NA codes to R missing value NA}
\PYG{k+kp}{file}\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{RELIG\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{k+kp}{file}\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{RELIG\PYGZsq{}}\PYG{p}{]} \PYG{o}{==} \PYG{l+m}{99999}\PYG{p}{]}        \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kc}{NA}
\PYG{k+kp}{file}\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{EMPTYP1\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{k+kp}{file}\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{EMPTYP1\PYGZsq{}}\PYG{p}{]} \PYG{o}{==} \PYG{l+m}{99}\PYG{p}{]}       \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kc}{NA}
\PYG{k+kp}{file}\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{LIVESTOCK\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{k+kp}{file}\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{LIVESTOCK\PYGZsq{}}\PYG{p}{]} \PYG{o}{==} \PYG{l+m}{9999}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kc}{NA}
\end{sphinxVerbatim}

We also take note that the variables LANGUAGE and ETHNICITY have only
missing values. Variables that contain only missing values should be
removed from the dataset at this stage and excluded from the
anonymization process. Removing these variables does not mean loss of
data or reduction of the data utility, since these variables did not
contain any information. It is, however, necessary to remove them,
because keeping them can lead to errors in some of the anonymization
methods in \sphinxstyleemphasis{R}. It is always possible to add these variables back into
the dataset to be released at the end of the anonymization process. It
is useful to reduce the dataset to those variables and records relevant
for the anonymization process. This guarantees the best results in \sphinxstyleemphasis{R}
and fewer errors. In \hyperref[\detokenize{casestudies:code96}]{Listing \ref{\detokenize{casestudies:code96}}} we drop the variables that contain all
missing values.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code96}}}
\sphinxSetupCaptionForVerbatim{Dropping variables with only missing values}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Drop variables containing only missings}
file \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{file}\PYG{p}{[}\PYG{p}{,}\PYG{o}{!}\PYG{k+kp}{names}\PYG{p}{(}\PYG{k+kp}{file}\PYG{p}{)} \PYG{o}{\PYGZpc{}in\PYGZpc{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{LANGUAGE\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{ETHNICITY\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\end{sphinxVerbatim}

We assume that the data are collected in a survey that uses simple
sampling of households. The data contains two weight coefficients: WGTHH
and WGTPOP. The relationship between the weights is WGTPOP = WGTHH *
HHSIZE. WGTPOP is the sampling weight for the households and WGTHH is
the sampling weight for the individuals to be used for disclosure risk
calculations. WGTHH is used for computing individual-level indicators
(such as education) and WGTPOP is used for population level indicators
(such as income indicators). There are no strata variables available in
the data. We will use WGTPOP for the anonymization of the household
variables and WGTHH for the anonymization of the individual-level
variables.


\subsection{Step 3: Type of release}
\label{\detokenize{casestudies:step-3-type-of-release}}
In this case study, we assume that data will be released as a SUF, which
will be only available under license to accredited researchers with
approved research proposals (see the Section
\sphinxhref{release\_types.html\#ConditionsforSUFs}{Conditions for SUFs}
for more information of the
release of a SUF). Therefore, the accepted risk level is higher and a
broader set of variables can be released than would be the case when
releasing a PUF. Since we do not have an overview of the requirements of
all users, we restrict the utility measures to a selected number of data
uses (see Step 5).


\subsection{Step 4: Intruder scenarios and choice of key variables}
\label{\detokenize{casestudies:step-4-intruder-scenarios-and-choice-of-key-variables}}
Next, we analyze possible intruder scenarios and select
quasi-identifiers or key variables based on these scenarios. Since the
dataset used in this case study is a demo dataset that does not stem
from an existing country (and hence we do not have information on
external data sources available to possible intruders) and the original
data has already been anonymized, it is not possible to define exact
disclosure scenarios. Instead, we draft intruder scenarios for this demo
dataset based on some hypothetical assumptions about availability of
external data sources. We consider two types of disclosure scenarios: 1)
matching to other publicly available datasets and 2) spontaneous
recognition. The license under which the dataset will be distributed
(SUF) prohibits matching to external resources. Still this can happen.
However, the more important scenario is the one of spontaneous
recognition. We describe both scenarios in the following two paragraphs.

For the sake of illustration, we assume that population registers are
available with the demographic variables gender, age, place of residence
(region, urban/rural), religion and other variables such as marital
status and variables relating to education and professional status that
are also present in our dataset. In addition, we assume that there is a
publically available cadastral register on land ownership. Based on this
analysis of available data sources, we select the variables REGION,
URBRUR, HHSIZE, OWNAGLAND, RELIG, GENDER, REL (relationship to household
head), MARITAL (marital status), AGEYRS, INDUSTRY1 and two variables
relating to school attendance as categorical quasi-identifiers, the
expenditure and income variables as well as LANDSIZEHA as continuous
quasi-identifiers. According to our assessment, these variables might
enable an intruder to re-identify an individual or household in the
dataset by matching with other available datasets.

\hyperref[\detokenize{casestudies:tab92}]{Table \ref{\detokenize{casestudies:tab92}}} gives an overview of the selected quasi-identifiers and their
levels of measurement.

The decision to release the dataset as a SUF means the level of
anonymization will be relatively low and consequently, the variables are
more detailed and a scenario of spontaneous recognition is our main
concern. Therefore, we should check for rare combinations or unusual
patterns in the variables. Variables that may lead to spontaneous
recognition in our sample are amongst others HHSIZE (household size),
LANDSIZEHA as well as income and expenditure variables. Large households
and large land ownership are easily identifiable. The same holds for
extreme outliers in wealth and expenditure variables, especially when
combined with other identifying variables such as region. There might be
only one or a few households in a certain region with a high income,
such as the local doctor. Variables that are easily observable and known
by neighbors such as ROOF, TOILET, WATER, ELECTCON, FUELCOOK,
OWNMOTORCYCLE, CAR, TV and LIVESTOCK may also need protection depending
on what stands out in the community, since a researcher might be able to
identify persons (s)he knows. This is called the nosy-neighbor scenario.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{List of selected quasi-identifiers}\label{\detokenize{casestudies:tab92}}\label{\detokenize{casestudies:id22}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Name
&\sphinxstyletheadfamily 
Measurement
\\
\hline
REGION (region)
&
Household, categorical
\\
\hline
URBRUR (area of residence)
&
Household, categorical
\\
\hline
HHSIZE (household size)
&
Household, categorical
\\
\hline
OWNAGLAND (agricultural land ownership)
&
Household, categorical
\\
\hline
RELIG (religion of household  head)
&
Household, categorical
\\
\hline
LANDSIZEHA (size of agr. and non-agr. land)
&
Household, continuous
\\
\hline
TANHHEXP (total expenditures)
&
Household, continuous
\\
\hline
TEXP (expenditures in category)
&
Household, continuous
\\
\hline
INCTOTGROSSHH (total income)
&
Household, continuous
\\
\hline
INC (income in category)
&
Household, continuous
\\
\hline
GENDER (sex)
&
Individual, categorical
\\
\hline
REL (relationship to household head)
&
Individual, categorical
\\
\hline
MARITAL (marital status)
&
Individual, categorical
\\
\hline
AGEYRS (age in completed years)
&
Individual, semi-continuous
\\
\hline
EDYRSCURATT (years of education for currently enrolled)
&
Individual, semi-continuous
\\
\hline
EDUCY (highest level of education completed)
&
Individual, categorical
\\
\hline
ATSCHOOL (currently enrolled in school)
&
Individual, categorical
\\
\hline
INDUSTRY1 (industry classification)
&
Individual, categorical
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsection{Step 5: Data key uses and selection of utility measures}
\label{\detokenize{casestudies:step-5-data-key-uses-and-selection-of-utility-measures}}
In this case study, our aim is to create a SUF that provides sufficient
information for accredited researchers. We know that the primary use of
these data will be to evaluate indicators relating to income and
inequality. Examples are the GINI coefficient and indicators on what
share of income is spent on what type of expenditures. Furthermore, we
focus on some education indicators. \hyperref[\detokenize{casestudies:tab93}]{Table \ref{\detokenize{casestudies:tab93}}} gives an overview of the
utility measures we selected. Besides these utility measures, which are
specific to the data uses, we also do standard checks, such as comparing
tabulations, cross-tabulations and summary statistics before and after
anonymization.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Overview of selected utility measures}\label{\detokenize{casestudies:tab93}}\label{\detokenize{casestudies:id23}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline

Gini point estimates and confidence intervals for total expenditures
&
.
\\
\hline
Lorenz curves for total expenditures
&\\
\hline
Mean monthly per capita total expenditures by area of residence
&\\
\hline
Average share of components for expenditures
&\\
\hline
Mean monthly per capita total income by area of residence
&\\
\hline
Average share of components for income
&\\
\hline
Net enrollment in primary education by gender
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

There are no published figures and statistics available that are
calculated from this dataset because it is a demo. In general, the
published figures should be re-computed based on the anonymized dataset
and compared to the published figures in Step 11. Large differences
would reduce the credibility of the anonymized dataset.


\subsection{Hierarchical (household) structure}
\label{\detokenize{casestudies:hierarchical-household-structure}}
Our demo survey collects data on individuals in households. The
household structure is important for data users and should be considered
in the risk assessment. Since some variables are measured on the
household level and thus have identical values for each household
member, the values of the household variables should be treated in the
same way for each household member (see the Section
\sphinxhref{anon\_methods.html\#Anonymizationofthequasi-identifierhouseholdsize}{Anonymization of the quasi-identifier household size}).
Therefore, we
first anonymize only the household variables. After this, we merge them
with the individual-level variables and then anonymize the
individual-level and household-level variables jointly.

Since the data has a hierarchical structure, Steps 6 through 10 are
repeated twice: Steps 6a through 10a are for the household-level
variables and Steps 6b through 10b for the combined dataset. In this
way, we ensure that household-level variable values remain consistent
across household members for each household and the household structure
cannot be used to re-identify individuals. This is further explained in
the Sections \sphinxhref{measure\_risk.html\#Levelsofrisk}{Levels of risk}
and \sphinxhref{sdcMicro.html\#Randomizingorderandnumberingofindividualsorhouseholds}{Randomizing order and numbering of individuals or households} .

Before continuing to Step 6a, we select the categorical key variables,
continuous key variables and any variables selected for use in PRAM
routines, as well as household-level sampling weights. We extract these
selected household variables and the households from the dataset and
save them as \sphinxstyleemphasis{fileHH}. The choice of PRAM variables is further explained
in Step 8a. \hyperref[\detokenize{casestudies:code97}]{Listing \ref{\detokenize{casestudies:code97}}} illustrates how these steps are done in \sphinxstyleemphasis{R} (see
also the Section \sphinxhref{sdcMicro.html\#Householdstructure}{Household structure}).

\begin{sphinxadmonition}{note}{Note:}
In our dataset, some of the categorical variables when imported from the STATA file were not imported as
factors. sdcMicro requires that these be converted to factors before
proceeding.
\end{sphinxadmonition}

Conversion of these variables to factors is also shown in \hyperref[\detokenize{casestudies:code97}]{Listing \ref{\detokenize{casestudies:code97}}}.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code97}}}
\sphinxSetupCaptionForVerbatim{Selecting the variables for the household-level anonymization}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Select variables (household level)}
\PYG{c+c1}{\PYGZsh{} Key variables (household level)}
selectedKeyVarsHH \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{URBRUR\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{REGION\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{HHSIZE\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{OWNHOUSE\PYGZsq{}}\PYG{p}{,}
                      \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{OWNAGLAND\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{RELIG\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Changing variables to class factor}
\PYG{k+kp}{file}\PYG{o}{\PYGZdl{}}URBRUR    \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{as.factor}\PYG{p}{(}\PYG{k+kp}{file}\PYG{o}{\PYGZdl{}}URBRUR\PYG{p}{)}
\PYG{k+kp}{file}\PYG{o}{\PYGZdl{}}REGION    \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{as.factor}\PYG{p}{(}\PYG{k+kp}{file}\PYG{o}{\PYGZdl{}}REGION\PYG{p}{)}
\PYG{k+kp}{file}\PYG{o}{\PYGZdl{}}OWNHOUSE  \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{as.factor}\PYG{p}{(}\PYG{k+kp}{file}\PYG{o}{\PYGZdl{}}OWNHOUSE\PYG{p}{)}
\PYG{k+kp}{file}\PYG{o}{\PYGZdl{}}OWNAGLAND \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{as.factor}\PYG{p}{(}\PYG{k+kp}{file}\PYG{o}{\PYGZdl{}}OWNAGLAND\PYG{p}{)}
\PYG{k+kp}{file}\PYG{o}{\PYGZdl{}}RELIG     \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{as.factor}\PYG{p}{(}\PYG{k+kp}{file}\PYG{o}{\PYGZdl{}}RELIG\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Numerical variables}
numVarsHH \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{LANDSIZEHA\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TANHHEXP\PYGZsq{}}\PYG{p}{,}   \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TFOODEXP\PYGZsq{}}\PYG{p}{,}      \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TALCHEXP\PYGZsq{}}\PYG{p}{,}
              \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TCLTHEXP\PYGZsq{}}\PYG{p}{,}   \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{THOUSEXP\PYGZsq{}}\PYG{p}{,}   \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TFURNEXP\PYGZsq{}}\PYG{p}{,}      \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{THLTHEXP\PYGZsq{}}\PYG{p}{,}
              \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TTRANSEXP\PYGZsq{}}\PYG{p}{,}  \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TCOMMEXP\PYGZsq{}}\PYG{p}{,}   \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TRECEXP\PYGZsq{}}\PYG{p}{,}       \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TEDUEXP\PYGZsq{}}\PYG{p}{,}
              \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TRESHOTEXP\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TMISCEXP\PYGZsq{}}\PYG{p}{,}   \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCRMT\PYGZsq{}}\PYG{p}{,}
              \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCWAGE\PYGZsq{}}\PYG{p}{,}    \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCFARMBSN\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCNFARMBSN\PYGZsq{}}\PYG{p}{,}   \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCRENT\PYGZsq{}}\PYG{p}{,}
              \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCFIN\PYGZsq{}}\PYG{p}{,}     \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCPENSN\PYGZsq{}}\PYG{p}{,}   \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCOTHER\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} PRAM variables}
pramVarsHH \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{ROOF\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TOILET\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{WATER\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{ELECTCON\PYGZsq{}}\PYG{p}{,}
               \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{FUELCOOK\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{OWNMOTORCYCLE\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{CAR\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TV\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{LIVESTOCK\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} sample weight (WGTPOP) (household)}
weightVarHH \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{WGTPOP\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} All household level variables}
HHVars \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{HID\PYGZsq{}}\PYG{p}{,} selectedKeyVarsHH\PYG{p}{,} pramVarsHH\PYG{p}{,} numVarsHH\PYG{p}{,} weightVarHH\PYG{p}{)}
\end{sphinxVerbatim}

We then extract these variables from \sphinxstyleemphasis{file}, the dataframe in \sphinxstyleemphasis{R} that
contains all variables. Every household has the same number of entries
as it has members (e.g., a household of three will be repeated three
times in \sphinxstyleemphasis{fileHH}). Before analyzing the household-level variables, we
select only one entry per household, as illustrated in \hyperref[\detokenize{casestudies:code98}]{Listing \ref{\detokenize{casestudies:code98}}}. This
is further explained in the Section \sphinxhref{sdcMicro.html\#Householdstructure}{Household structure}.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code98}}}
\sphinxSetupCaptionForVerbatim{Taking a subset with only households}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Create subset of file with households and HH variables}
fileHH \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{file}\PYG{p}{[}\PYG{p}{,}HHVars\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Remove duplicated rows based on IDH, select uniques,}
\PYG{c+c1}{\PYGZsh{} one row per household in fileHH}
fileHH \PYG{o}{\PYGZlt{}\PYGZhy{}} fileHH\PYG{p}{[}\PYG{k+kp}{which}\PYG{p}{(}\PYG{o}{!}\PYG{k+kp}{duplicated}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}\PYG{p}{]}

\PYG{k+kp}{dim}\PYG{p}{(}fileHH\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 2000   39}
\end{sphinxVerbatim}

The file \sphinxstyleemphasis{fileHH} contains 2,000 households and 39 variables. We are now
ready to create our \sphinxstyleemphasis{sdcMicro} object with the corresponding variables
we selected in \hyperref[\detokenize{casestudies:code97}]{Listing \ref{\detokenize{casestudies:code97}}}. For our case study, we will create an
\sphinxstyleemphasis{sdcMicro} object called \sphinxstyleemphasis{sdcHH} based on the data in \sphinxstyleemphasis{fileHH}, which we
will use for steps 6a \textendash{} 10a (see \hyperref[\detokenize{casestudies:code99}]{Listing \ref{\detokenize{casestudies:code99}}}).

\begin{sphinxadmonition}{note}{Note:}
When the sdcMicro object is created, the sdcMicro package automatically calculates and
stores the risk measures for the data.
\end{sphinxadmonition}

This leads us to Step 6a.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code99}}}
\sphinxSetupCaptionForVerbatim{Creating a \sphinxstyleemphasis{sdcMicro} object for the household variables}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Create initial SDC object for household level variables}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} createSdcObj\PYG{p}{(}dat \PYG{o}{=} fileHH\PYG{p}{,} keyVars \PYG{o}{=} selectedKeyVarsHH\PYG{p}{,} pramVars \PYG{o}{=} pramVarsHH\PYG{p}{,}
                      weightVar \PYG{o}{=} weightVarHH\PYG{p}{,} numVars \PYG{o}{=} numVarsHH\PYG{p}{)}

numHH \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{length}\PYG{p}{(}fileHH\PYG{p}{[}\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} number of households}
\end{sphinxVerbatim}


\subsection{Step 6a: Assessing disclosure risk (household level)}
\label{\detokenize{casestudies:step-6a-assessing-disclosure-risk-household-level}}
As a first measure, we evaluate the number of households violating
k-anonymity at the levels 2, 3 and 5.

\hyperref[\detokenize{casestudies:tab94}]{Table \ref{\detokenize{casestudies:tab94}}} shows the number of violating households as well as the
percentage of the total number of households. \hyperref[\detokenize{casestudies:code910}]{Listing \ref{\detokenize{casestudies:code910}}} illustrates
how to find these values with \sphinxstyleemphasis{sdcMicro}. The print() function in
\sphinxstyleemphasis{sdcMicro} shows only the values for thresholds 2 and 3. Values for
other thresholds can be calculated manually by summing up the
frequencies smaller than the k-anonymity threshold, as shown in \hyperref[\detokenize{casestudies:code910}]{Listing \ref{\detokenize{casestudies:code910}}}.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Number and proportion of households violating k-anonymity}\label{\detokenize{casestudies:tab94}}\label{\detokenize{casestudies:id24}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
k-anonymity level
&\sphinxstyletheadfamily 
Number of HH violating
&\sphinxstyletheadfamily 
Percentage of total number of HH
\\
\hline
2
&
103
&
5.15 \%
\\
\hline
3
&
229
&
11.45 \%
\\
\hline
5
&
489
&
24.45 \%
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code910}}}
\sphinxSetupCaptionForVerbatim{Showing number of households violating k-anonymity for levels 2, 3 and 5}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Number of observations violating k\PYGZhy{}anonymity (thresholds 2 and 3)}
\PYG{k+kp}{print}\PYG{p}{(}sdcHH\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Infos on 2/3\PYGZhy{}Anonymity:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Number of observations violating}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 2\PYGZhy{}anonymity: 103}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 3\PYGZhy{}anonymity: 229}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Percentage of observations violating}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 2\PYGZhy{}anonymity: 5.150 \PYGZpc{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 3\PYGZhy{}anonymity: 11.450 \PYGZpc{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}

\PYG{c+c1}{\PYGZsh{} Calculate sample frequencies and count number of obs. violating k(5) \PYGZhy{} anonymity}
kAnon5 \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{sum}\PYG{p}{(}sdcHH\PYG{o}{@}risk\PYG{o}{\PYGZdl{}}individual\PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{o}{\PYGZlt{}} \PYG{l+m}{5}\PYG{p}{)}

kAnon5
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 489}

\PYG{c+c1}{\PYGZsh{} As percentage of total}
kAnon5 \PYG{o}{/} numHH
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 0.2445}
\end{sphinxVerbatim}

It is often useful to view the values for the household(s) that violate
\(k\)-anonymity. This might help clarify which variables cause the
uniqueness of these households; this can then be used later when
choosing appropriate SDC methods. \hyperref[\detokenize{casestudies:code911}]{Listing \ref{\detokenize{casestudies:code911}}} shows how to assess the
values of the households violating 3- and 5-anonymity. It seems that
among the categorical key variables, the variable HHSIZE is responsible
for many of the unique combinations and the origin of much of the risk.
Having determined this, we can flag HHSIZE as a possible first variable
to treat to obtain the required risk level. In practice, with a variable
like HHSIZE, this will likely involve removing large households from the
dataset to be released. As explained in the Section
\sphinxhref{anon\_methods.html\#Anonymizationofthequasi-identifierhouseholdsize}{Anonymization of the quasi-identifier household size}
, recoding and local
suppression are no valid options for the variable HHSIZE. The
frequencies of household size in \hyperref[\detokenize{casestudies:tab97}]{Table \ref{\detokenize{casestudies:tab97}}} show that there
are few households with more than 13 household members. This makes these
households easily identifiable based on the number of household members
and at high risk of re-identification, also in the context of the nosy
neighbor scenario.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code911}}}
\sphinxSetupCaptionForVerbatim{Showing households that violate \(k\)-anonymity}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Show values of key variable of records that violate k\PYGZhy{}anonymity}
fileHH\PYG{p}{[}sdcHH\PYG{o}{@}risk\PYG{o}{\PYGZdl{}}individual\PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{o}{\PYGZlt{}} \PYG{l+m}{3}\PYG{p}{,} selectedKeyVarsHH\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} for 3\PYGZhy{}anonymity}
fileHH\PYG{p}{[}sdcHH\PYG{o}{@}risk\PYG{o}{\PYGZdl{}}individual\PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{o}{\PYGZlt{}} \PYG{l+m}{5}\PYG{p}{,} selectedKeyVarsHH\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} for 5\PYGZhy{}anonymity}
\end{sphinxVerbatim}

We also assess the disclosure risk of the categorical variables with the
individual and global risk measures as described in the Sections
\sphinxhref{measure\_risk.html\#Individualrisk}{Individual risk} and
\sphinxhref{measure\_risk.html\#Globalrisk}{Global risk}.
In \sphinxstyleemphasis{fileHH} every entry represents a household. Therefore, we use
the individual non-hierarchical risk here, where the individual refers
in this case to a household. \sphinxstyleemphasis{fileHH} contains only households and has
no hierarchical structure. In Step 6b, we evaluate the hierarchical risk
in \sphinxstyleemphasis{file}, the dataset containing both households and individuals. The
individual and global risk measures automatically take into
consideration the household weights, which we defined in \hyperref[\detokenize{casestudies:code97}]{Listing \ref{\detokenize{casestudies:code97}}}. In
our file, the global risk measure calculated using the chosen key
variables is 0.05\%. This percentage is extremely low and corresponds to
1.03 expected re-identifications. The results are also shown in \hyperref[\detokenize{casestudies:code912}]{Listing \ref{\detokenize{casestudies:code912}}}.
This low figure can be explained by the relatively small sample
size of 0.25\% of the total population. Furthermore, one should keep in
mind that this risk measure is based only on the categorical
quasi-identifiers at the household level. \hyperref[\detokenize{casestudies:code912}]{Listing \ref{\detokenize{casestudies:code912}}} illustrates how
to print the global risk measure.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code912}}}
\sphinxSetupCaptionForVerbatim{Printing global risk measures}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{k+kp}{print}\PYG{p}{(}sdcHH\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{risk\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Risk measures:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Number of observations with higher risk than the main part of the data: 0}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Expected number of re\PYGZhy{}identifications: 1.03 (0.05 \PYGZpc{})}
\end{sphinxVerbatim}

The global risk measure does not provide information about the spread of
the individual risk measures. There might be a few households with
relatively high risk, while the global (average) risk is low. It is
therefore useful as a next step to inspect the observations with
relatively high risk. The highest risk is 5.5\% and only 14 households
have risk larger than 1\%. \hyperref[\detokenize{casestudies:code913}]{Listing \ref{\detokenize{casestudies:code913}}} shows how to display those
households with risk over a certain threshold. Here the threshold is
0.01 (1\%).

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code913}}}
\sphinxSetupCaptionForVerbatim{Observations with individual risk higher than 1\%}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Observations with risk above certain threshold (0.01)}
fileHH\PYG{p}{[}sdcHH\PYG{o}{@}risk\PYG{o}{\PYGZdl{}}individual\PYG{p}{[}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{risk\PYGZdq{}}\PYG{p}{]} \PYG{o}{\PYGZgt{}} \PYG{l+m}{0.01}\PYG{p}{,}\PYG{p}{]}
\end{sphinxVerbatim}

Since the selected key variables at the household level are both
categorical and numerical, the individual and global risk measures based
on frequency counts do not completely reflect the disclosure risk of the
entire dataset. Both categorical and continuous key variables are
important for the data users, thus options like recoding the continuous
variables (e.g., by creating quantiles of income and expenditure
variables) to make all of them categorical will likely not satisfy the
data user’s needs. We therefore avoid recoding continuous variables and
assess the disclosure risk of the categorical and continuous variables
separately. This approach can be partly justified by the fact that any
potential matching to external data sources for the continuous and
categorical variables are available from different external data sources
and as such will not be used simultaneously for matching.

\sphinxstylestrong{Continuous variables}

To measure the risk of the continuous variables, we use an interval
measure, which measures the number of anonymized values that are too
close to their original values. See the Section \sphinxhref{measure\_risk.html\#Intervalmeasure}{Interval measure}
for more information
on interval-based risk measures for continuous variables. This measure
is an ex-post measure, meaning that the risk can be evaluated only after
anonymization and measures whether the perturbation is sufficiently
large. Since it is an ex-post measure, we can evaluate it only in Step
9a after the variables have been treated. Evaluating this measure based
on the original data would lead to a risk of 100\%; all values would be
too close to the original values since they would coincide with the
original values, no matter how small the chosen intervals would be.

We also look at the distribution of LANDSIZEHA. In the variable
LANDSIZEHA high values are rare and can lead to re-identification. An
example is a large landowner in a specific region. To evaluate the
distribution of the variable LANDSIZEHA, we look at the percentiles.
Every percentile represents approximately 20 households. In addition, we
look at the values of the largest 50 plots. \hyperref[\detokenize{casestudies:code914}]{Listing \ref{\detokenize{casestudies:code914}}} shows how to
use \sphinxstyleemphasis{R} to display the quantiles and the largest landplots. \hyperref[\detokenize{casestudies:tab95}]{Table \ref{\detokenize{casestudies:tab95}}}
shows the 90$^{\text{th}}$ \textendash{} 100$^{\text{th}}$ percentiles and \hyperref[\detokenize{casestudies:tab96}]{Table \ref{\detokenize{casestudies:tab96}}}
displays the largest 50 values for LANDSIZEHA. Based on these values, we
conclude that values of LANDSIZEHA over 40 make the household very
identifiable. These large households and households with large land
plots need extra protection, as discussed in Step 8a.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code914}}}
\sphinxSetupCaptionForVerbatim{Percentiles of LANDSIZE and listing the sizes of the largest 50 plots}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} 1st \PYGZhy{} 100th percentiles of land size}
quantile\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{,} probs \PYG{o}{=} \PYG{p}{(}\PYG{l+m}{1}\PYG{o}{:}\PYG{l+m}{100}\PYG{p}{)}\PYG{o}{/}\PYG{l+m}{100}\PYG{p}{,} na.rm\PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Values of landsize for largest 50 plots}
\PYG{k+kp}{tail}\PYG{p}{(}\PYG{k+kp}{sort}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{)}\PYG{p}{,} n \PYG{o}{=} \PYG{l+m}{50}\PYG{p}{)}
\end{sphinxVerbatim}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Percentiles 90-100 of the variable LANDSIZE}\label{\detokenize{casestudies:tab95}}\label{\detokenize{casestudies:id25}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
Percentile
&\sphinxstyletheadfamily 
90
&\sphinxstyletheadfamily 
91
&\sphinxstyletheadfamily 
92
&\sphinxstyletheadfamily 
93
&\sphinxstyletheadfamily 
94
&\sphinxstyletheadfamily 
95
\\
\hline
Value
&
6.00
&
8.00
&
8.09
&
10.12
&
10.12
&
10.12
\\
\hline
Percentile
&
96
&
97
&
98
&
99
&
100
&\\
\hline
Value
&
12.14
&
20.23
&
33.83
&
121.41
&
1,214.08
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{50 largest values of the variable LANDSIZE}\label{\detokenize{casestudies:tab96}}\label{\detokenize{casestudies:id26}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|T|T|T|}
\hline

12.14
&
15.00
&
15.37
&
15.78
&
16.19
&
20.00
&
20.23
&
20.23
&
20.23
&
20.23
\\
\hline
20.23
&
20.23
&
20.23
&
20.23
&
20.23
&
20.23
&
20.23
&
20.23
&
20.23
&
20.23
\\
\hline
20.23
&
20.23
&
20.50
&
30.35
&
32.38
&
40.47
&
40.47
&
40.47
&
40.47
&
40.47
\\
\hline
40.47
&
40.47
&
80.93
&
80.93
&
80.93
&
80.93
&
121.41
&
121.41
&
161.88
&
161.88
\\
\hline
161.88
&
182.11
&
246.86
&
263.05
&
283.29
&
404.69
&
404.69
&
607.04
&
809.39
&
1214.08
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsection{Step 7a: Assessing utility measures (household level)}
\label{\detokenize{casestudies:step-7a-assessing-utility-measures-household-level}}
The utility of the data does not only depend on the household level
variables, but on the combination of household-level and
individual-level variables. Therefore, it is not useful to evaluate all
the utility measures selected in Step 5 at this stage, i.e., before
anonymizing the individual level variables. We restrict the initial
measurement of utility to those measures that are solely based on the
household variables. In our dataset, these are the measures related to
income and expenditure and their distributions. The results are
presented in Step 10a, together with the results after anonymization,
which allow direct comparison. If after the next anonymization step it
appears that the data utility has been significantly decreased by the
suppression of some household level variables, we can return to this
step.


\subsection{Step 8a: Choice and application of SDC methods (household variables)}
\label{\detokenize{casestudies:step-8a-choice-and-application-of-sdc-methods-household-variables}}
This step is divided into the anonymization of the variable HHSIZE, as
this is a special case, the anonymization of the other selected
categorical quasi-identifiers and the anonymization of the selected
continuous quasi-identifiers.

\sphinxstylestrong{Variable HHSIZE}

The variable HHSIZE poses a problem for the anonymization of the file,
since suppressing it will not anonymize this variable: a simple
headcount based on the household ID would allow the reconstruction of
this variable. \hyperref[\detokenize{casestudies:tab97}]{Table \ref{\detokenize{casestudies:tab97}}} shows the absolute frequencies of HHSIZE. The
number of households for each size larger than 13 is 6 or fewer and can
be considered outliers with a higher risk of re-identification, as
discussed in Step 6a. One way to deal with this is to remove all
households of size 14 or larger from the dataset %
\begin{footnote}[1]\sphinxAtStartFootnote
Other methods and guidance on treating datasets where household size
is a quasi-identifier are discussed in the Section
\sphinxhref{anon\_methods.html\#Anonymizationofthequasi-identifierhouseholdsize}{Anonymization of the quasi-identifier household size}.
%
\end{footnote}.
Removing 29 households of size 14 or larger reduces the number of
2-anonymity violations by 18, of 3-anonymity violations by 26 and of
5-anonymity violations by 29. This means that all removed households
violated 5-anonymity due to the value of the variable HHSIZE and many of
them 2- or 3-anonymity. In addition, the average individual risk amongst
the 29 households is 0.15\%, which is almost three times higher than the
average individual risk of all households. The impact on the global risk
measure of removing these 29 households is, however, limited, due to the
relatively small number of removed households in comparison to the total
number of 2,000 households. Removing the households is primarily to
protect these specific households, not to reduce the global risk.

Changes, such as removing records, cannot be done in the
\sphinxstyleemphasis{sdcMicro} object. \hyperref[\detokenize{casestudies:code915}]{Listing \ref{\detokenize{casestudies:code915}}} illustrates the way to remove households
and recreate the \sphinxstyleemphasis{sdcMicro} object.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Frequencies of variable HHSIZE (household size)}\label{\detokenize{casestudies:tab97}}\label{\detokenize{casestudies:id27}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|T|T|T|T|T|T|}
\hline

HHSIZE
&
1
&
2
&
3
&
4
&
5
&
6
&
7
&
8
&
9
&
10
&
11
&
12
\\
\hline
Frequency
&
152
&
194
&
238
&
295
&
276
&
252
&
214
&
134
&
84
&
66
&
34
&
21
\\
\hline
HHSIZE
&
13
&
14
&
15
&
16
&
17
&
18
&
19
&
20
&
21
&
22
&
33
&\\
\hline
Frequency
&
11
&
6
&
6
&
5
&
4
&
2
&
1
&
2
&
1
&
1
&
1
&\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code915}}}
\sphinxSetupCaptionForVerbatim{Removing households with large (rare) household sizes}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Tabulation of variable HHSIZE}
\PYG{k+kp}{table}\PYG{p}{(}sdcHH\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}HHSIZE\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Remove large households (14 or more household members) from file and fileHH}
file \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{file}\PYG{p}{[}\PYG{o}{!}\PYG{k+kp}{file}\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{HHSIZE\PYGZsq{}}\PYG{p}{]} \PYG{o}{\PYGZgt{}=} \PYG{l+m}{14}\PYG{p}{,}\PYG{p}{]}

fileHHnew \PYG{o}{\PYGZlt{}\PYGZhy{}} fileHH\PYG{p}{[}\PYG{o}{!}fileHH\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{HHSIZE\PYGZsq{}}\PYG{p}{]} \PYG{o}{\PYGZgt{}=} \PYG{l+m}{14}\PYG{p}{,}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Create new sdcMicro object based on the file without the removed households}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} createSdcObj\PYG{p}{(}dat\PYG{o}{=}fileHHnew\PYG{p}{,} keyVars\PYG{o}{=}selectedKeyVarsHH\PYG{p}{,} pramVars\PYG{o}{=}pramVarsHH\PYG{p}{,}
                      weightVar\PYG{o}{=}weightVarHH\PYG{p}{,} numVars \PYG{o}{=} numVarsHH\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxstylestrong{Categorical variables}

We are now ready to move on to the choice of SDC methods for the
categorical variables on the household level in our dataset. As noted in
our discussion of the methods, applying perturbative methods and local
suppression may lead to large loss of utility. The common approach is to
apply recoding to the largest possible extent as a first approach, to
reach a prescribed level of risk and reduce the number of suppressions
needed. Only after that should methods such as local suppression be
applied. If this approach does not already achieve the desired result,
we can consider perturbative methods.

Since the file is to be released as a SUF, we can keep a higher level of
detail in the data. The selected categorical key variables at the
household level are not suitable for recoding at this point. Due to the
relatively low risk of re-identification based on the five selected
categorical household level variables, it is possible in this case to
use an option like local suppression to achieve our desired level of
risk. Applying local suppression when initial risk is relatively low
will likely only lead to suppression of few observations and thus limit
the loss of utility. If, however, the data had been measured to have a
relatively high risk, then applying local suppression without previous
recoding would likely result in a large number of suppressions and
greater information loss. Efforts such a recoding should be taken first
before suppressing in cases where risk is initially measured as high.
Recoding will reduce risk with little information loss and thus the
number of suppressions, if local suppression is applied as an additional
step. We apply local suppression to reach 2-anonymity. The choice of the
low level of two is based on the overall low re-identification risk due
to the high sample weights and the release as SUF. High sample weights
mean, ceteris paribus, a low level of re-identification risk. Achieving
2-anonymity is the same as removing sample uniques. This leads to 42
suppressions in the variable HHSIZE and 4 suppressions in the variable
REGION. As explained earlier, suppression of the value of the variable
HHSIZE does not lead to actual suppression of this information.
Therefore, we redo the local suppression, but this time we tell
\sphinxstyleemphasis{sdcMicro} to, if possible, not suppress HHSIZE but one of the other
variables.

In \sphinxstyleemphasis{sdcMicro} it is possible to tell the algorithm which variables are
important and less important for making small changes (see also the Section
\sphinxhref{anon\_methods.html\#Localsuppression}{Local suppression}).
To prevent HHSIZE being suppressed, we set the importance of
HHSIZE in the importance vectors to the highest (i.e., 1). \hyperref[\detokenize{casestudies:code916}]{Listing \ref{\detokenize{casestudies:code916}}}
shows how to apply local suppression and put importance on the variable
HHSIZE. The variable REGION is the type of variable that should not have
any suppressions either. We also set the importance of REGION to 2 and
the importance of RURURB to 3. This leads to an order of the variables
to be considered for suppression by the algorithm. Instead of 42
suppressions in the variable HHSIZE, this leads one suppressed value in
the variable HHSIZE, and to 6, 1, 48 and 16 suppressions respectively
for the variables URBRUR, REGION, OWNAGLAND and RELIG (which we set as
less important). The importance is clearly reflected in the number of
suppression. The total number of suppressions is higher than without
importance vector (71 vs. 46), but 2-anonymity is achieved in the
dataset with fewer suppressions in the variables HHSIZE and REGION. We
remove the one household with the suppressed value of HHSIZE (13) to
protect this household.

\begin{sphinxadmonition}{note}{Note:}
In \hyperref[\detokenize{casestudies:code916}]{Listing \ref{\detokenize{casestudies:code916}}} we use the undolast() function in sdcMicro to go one step back after we had first
applied local suppression with no importance vector.
\end{sphinxadmonition}

The undolast() function restores the \sphinxstyleemphasis{sdcMicro} object back to the previous state
(i.e., before we applied local suppression), which allows us to rerun
the same command, but this time with an importance vector set. The
undolast() function can only be used to go one step back.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code916}}}
\sphinxSetupCaptionForVerbatim{Local suppression with and without importance vector}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Local suppression}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} localSuppression\PYG{p}{(}sdcHH\PYG{p}{,} k\PYG{o}{=}\PYG{l+m}{2}\PYG{p}{,} importance \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} no importance vector}

\PYG{k+kp}{print}\PYG{p}{(}sdcHH\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Local Suppression:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     KeyVar \textbar{} Suppressions (\PYGZsh{}) \textbar{} Suppressions (\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     URBRUR \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     REGION \textbar{}                4 \textbar{}            0.203}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     HHSIZE \textbar{}               37 \textbar{}            1.877}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  OWNAGLAND \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}      RELIG \textbar{}                0 \textbar{}            0.000}

sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} undolast\PYG{p}{(}sdcHH\PYG{p}{)}

sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} localSuppression\PYG{p}{(}sdcHH\PYG{p}{,} k\PYG{o}{=}\PYG{l+m}{2}\PYG{p}{,} importance \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+m}{3}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{5}\PYG{p}{,} \PYG{l+m}{5}\PYG{p}{)}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} importance on HHSIZE (1), REGION (2) and URBRUR (3)}

\PYG{k+kp}{print}\PYG{p}{(}sdcHH\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Local Suppression:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     KeyVar \textbar{} Suppressions (\PYGZsh{}) \textbar{} Suppressions (\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     URBRUR \textbar{}                6 \textbar{}            0.304}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     REGION \textbar{}                1 \textbar{}            0.051}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     HHSIZE \textbar{}                1 \textbar{}            0.051}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  OWNAGLAND \textbar{}               43 \textbar{}            2.182}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}      RELIG \textbar{}               16 \textbar{}            0.812}
\end{sphinxVerbatim}

The variables ROOF, TOILET, WATER, ELECTCON, FUELCOOK, OWNMOTORCYCLE,
CAR, TV and LIVESTOCK are not sensitive variables and were not selected
as quasi-identifiers because we assumed that there are no external data
sources containing this information that could be used for matching.
Values can be easily observed or be known to neighbors, however, and
therefore are important, together with other variables, for the
spontaneous recognition scenario and nosy neighbor scenario. To
anonymize these variables, we want to introduce a low level of
uncertainty in them. Therefore, we decide to use invariant PRAM for the
variables ROOF, TOILET, WATER, ELECTCON, FUELCOOK, OWNMOTORCYCLE, CAR,
TV and LIVESTOCK, where we treat LIVESTOCK as a semi-continuous variable
due to the low number of different values.
The Section \sphinxhref{anon\_methods.html\#PRAM(PostRAndomizationMethod)}{PRAM (Post RAndomization Method)} provides more
information on the PRAM method and its implementation in \sphinxstyleemphasis{sdcMicro}.
\hyperref[\detokenize{casestudies:code917}]{Listing \ref{\detokenize{casestudies:code917}}} illustrates how to apply PRAM. We choose the parameter
\sphinxstyleemphasis{pd}, the lower bound for the probability that a value is not changed,
to be relatively high at 0.8. We can choose a high value, because the
variables themselves are not sensitive and we only want to introduce a
low level of changes to minimize the utility loss. Because the
distribution of many of the variables chosen for PRAM depends on the
REGION, we decide to use the variable REGION as a strata variable. In
this way the transition matrix is computed for each region separately.
Because PRAM is a probabilistic method, we set a seed for the random
number generator before applying PRAM to ensure reproducibility of the
results.

\begin{sphinxadmonition}{note}{Note:}
In practice, it is not advisable to set a seed of
12345, but rather a longer more complex and less easy to guess
sequence.
\end{sphinxadmonition}

The seed should not be released, since it allows for
reconstructing the original values if combined with the transition
matrix. The transition matrix can be released: this allows for
consistent statistical inference by correcting the statistical methods
used if the researcher has knowledge about the PRAM method (at this
point \sphinxstyleemphasis{sdcMicro} does not allow the retrieval of the transition matrix).

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code917}}}
\sphinxSetupCaptionForVerbatim{Applying PRAM}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Pram}
\PYG{k+kp}{set.seed}\PYG{p}{(}\PYG{l+m}{12345}\PYG{p}{)}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} pram\PYG{p}{(}sdcHH\PYG{p}{,} strata\PYGZus{}variables \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{REGION\PYGZdq{}}\PYG{p}{,} pd \PYG{o}{=} \PYG{l+m}{0.8}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Number of changed observations:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} ROOF != ROOF\PYGZus{}pram : 98 (4.97\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} TOILET != TOILET\PYGZus{}pram : 151 (7.66\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} WATER != WATER\PYGZus{}pram : 167 (8.47\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} ELECTCON != ELECTCON\PYGZus{}pram : 90 (4.57\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} FUELCOOK != FUELCOOK\PYGZus{}pram : 113 (5.73\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} OWNMOTORCYCLE != OWNMOTORCYCLE\PYGZus{}pram : 41 (2.08\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} CAR != CAR\PYGZus{}pram : 172 (8.73\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} TV != TV\PYGZus{}pram : 137 (6.95\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} LIVESTOCK != LIVESTOCK\PYGZus{}pram : 149 (7.56\PYGZpc{})}
\end{sphinxVerbatim}

PRAM has changed values within the variables according to the invariant
transition matrices. Since we used the invariant PRAM method (see
the Section \sphinxhref{anon\_methods.html\#PRAM(PostRAndomizationMethod)}{PRAM (Post RAndomization Method)}),
the absolute univariate frequencies remain unchanged.
This is not the case for the multivariate frequencies. In Step 10a we
compare the changes in the multivariate frequencies for the PRAMmed
variables.

\sphinxstylestrong{Continuous variables}

We have selected income and expenditures variables and the variable
LANDSIZEHA as numerical quasi-identifiers, as discussed in Step 4. In
Step 5 we identified variables having high interest for the users of our
data: many users use the data for measuring inequality and expenditure
patterns.

Based on the risk evaluation in Step 6a, we decide to anonymize the
variable LANDSIZEHA by top coding at the value 40 (cf. \hyperref[\detokenize{casestudies:tab95}]{Table \ref{\detokenize{casestudies:tab95}}} and
\hyperref[\detokenize{casestudies:tab96}]{Table \ref{\detokenize{casestudies:tab96}}}) and round values smaller than 1 to one digit, and values
larger than 1 to zero digits. Rounding the values prevents exact
matching with the available cadastral register. Furthermore, we group
the values between 5 and 40 in the groups 5 \textendash{} 19 and 20 \textendash{} 39. After
these steps, no household has a unique plot size and the number of
households in the sample with the same plot size was increased to at
least 7. This is shown by the tabulation of the variable LANDSIZEHA
after manipulation in the last line of \hyperref[\detokenize{casestudies:code918}]{Listing \ref{\detokenize{casestudies:code918}}}. In addition, all
outliers have been removed by top coding the values. This has reduced
the risk of spontaneous recognition as discussed in Step 6. How to
recode values in \sphinxstyleemphasis{R} is introduced in the Section \sphinxhref{anon\_methods.html\#Recoding}{Recoding}
and, for this particular case, shown in \hyperref[\detokenize{casestudies:code918}]{Listing \ref{\detokenize{casestudies:code918}}}.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code918}}}
\sphinxSetupCaptionForVerbatim{Anonymizing the variable LANDSIZEHA}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Rounding values of LANDSIZEHA to 1 digit for plots smaller than 1 and}
\PYG{c+c1}{\PYGZsh{} to 0 digits for plots larger than 1}
sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{[}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA \PYG{o}{\PYGZlt{}=} \PYG{l+m}{1} \PYG{o}{\PYGZam{}}
                              \PYG{o}{!}\PYG{k+kp}{is.na}\PYG{p}{(}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{)}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}}
             \PYG{k+kp}{round}\PYG{p}{(}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{[}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA \PYG{o}{\PYGZlt{}=} \PYG{l+m}{1} \PYG{o}{\PYGZam{}}
                                                 \PYG{o}{!}\PYG{k+kp}{is.na}\PYG{p}{(}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
                   digits \PYG{o}{=} \PYG{l+m}{1}\PYG{p}{)}

sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{[}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA \PYG{o}{\PYGZgt{}} \PYG{l+m}{1} \PYG{o}{\PYGZam{}}
                              \PYG{o}{!}\PYG{k+kp}{is.na}\PYG{p}{(}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{)}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}}
             \PYG{k+kp}{round}\PYG{p}{(}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{[}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA \PYG{o}{\PYGZgt{}} \PYG{l+m}{1} \PYG{o}{\PYGZam{}}
                                                 \PYG{o}{!}\PYG{k+kp}{is.na}\PYG{p}{(}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
                   digits \PYG{o}{=} \PYG{l+m}{0}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Grouping values of LANDSIZEHA into intervals 5\PYGZhy{}19, 20\PYGZhy{}39}
sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{[}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA \PYG{o}{\PYGZgt{}=} \PYG{l+m}{5} \PYG{o}{\PYGZam{}}
sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA \PYG{o}{\PYGZlt{}} \PYG{l+m}{20} \PYG{o}{\PYGZam{}} \PYG{o}{!}\PYG{k+kp}{is.na}\PYG{p}{(}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{)}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{13}

sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{[}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA \PYG{o}{\PYGZgt{}=} \PYG{l+m}{20} \PYG{o}{\PYGZam{}}
sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA \PYG{o}{\PYGZlt{}} \PYG{l+m}{40} \PYG{o}{\PYGZam{}}\PYG{o}{!}\PYG{k+kp}{is.na}\PYG{p}{(}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{)}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{30}

\PYG{c+c1}{\PYGZsh{} Topcoding values of LANDSIZEHA larger than 40 (also recomputes risk after manual changes)}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} topBotCoding\PYG{p}{(}sdcHH\PYG{p}{,} value \PYG{o}{=} \PYG{l+m}{40}\PYG{p}{,} replacement \PYG{o}{=} \PYG{l+m}{40}\PYG{p}{,} kind \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{top\PYGZsq{}}\PYG{p}{,} column \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{LANDSIZEHA\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Results for LANDSIZEHA}
\PYG{k+kp}{table}\PYG{p}{(}sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}LANDSIZEHA\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}   0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9   1   2   3   4  13  30  40}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 188 109  55  30  24  65  22   7  31  16 154 258  53  60 113  18  25}
\end{sphinxVerbatim}

For the expenditure and income variables we compared, \sphinxstylestrong{based on the
actual case study data}, several methods. As mentioned earlier, the
main use of the data is to compute inequality measures, such as the Gini
coefficient. Recoding these variables into percentiles creates
difficulties computing these measures or changes these measures to a
large extent and is hence not a suitable method. Often, income and
expenditure variables that are released in a SUF are anonymized by
top-coding. This protects the outliers, which are the values that are
the most at risk. Top-coding, however, destroys the inequality
information in the data, by removing high (and low) incomes. Therefore,
we decide to use noise addition. To take into account the higher risk of
outliers, we add a higher level of noise to those.

Adding noise can lead to a transformation of the shape of the
distribution. Depending on the magnitude of the noise (see the Section
\sphinxhref{anon\_methods.html\#Noiseaddition}{Noise addition}
for the definition of the magnitude of noise), the values of income can
also become negative. One way to solve this would be to cut off the
values below zero and set them to zero. This would, however, destroy the
properties conserved by noise addition (amongst others the value of the
expected mean, see also the Section \sphinxhref{anon\_methods.html\#Noiseaddition}{Noise addition})
and we chose to keep the negative values.

As mentioned before, the aggregates of income and expenditures are the
sums of the components. Adding noise to each of the components might
lead to violation of this condition. Therefore, one solution is to add
noise to the aggregates and remove the components. We prefer to keep the
components in the data and apply noise addition to each component
separately. This allows to apply a lower level of noise than when
applying noise only to the aggregates. A noise level of 0.01 seems to be
sufficient with extra noise of 0.05 added to the outliers. The outliers
are defined by a robust Mahalanobis distance
(see the Section \sphinxhref{anon\_methods.html\#Noiseaddition}{Noise addition}). After
adding noise to the components, we recomputed the aggregates as the sum
of the perturbed components.

\begin{sphinxadmonition}{note}{Note:}
This result is only based on the actual case study dataset and is not necessarily true for other datasets.
\end{sphinxadmonition}

The noise addition is shown in \hyperref[\detokenize{casestudies:code919}]{Listing \ref{\detokenize{casestudies:code919}}}. Before applying
probabilistic methods such as noise addition, we set a seed for the
random number generator. This allows us to reproduce the results.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code919}}}
\sphinxSetupCaptionForVerbatim{Anonymizing continuous variables}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Add noise to income and expenditure variables by category}

\PYG{c+c1}{\PYGZsh{} Anonymize components}
compExp \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TFOODEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TALCHEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TCLTHEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{THOUSEXP\PYGZdq{}}\PYG{p}{,}
             \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TFURNEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{THLTHEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TTRANSEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TCOMMEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TRECEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TEDUEXP\PYGZdq{}}\PYG{p}{,}
             \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TRESHOTEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TMISCEXP\PYGZdq{}}\PYG{p}{)}
\PYG{k+kp}{set.seed}\PYG{p}{(}\PYG{l+m}{123}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Add noise to expenditure variables}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} addNoise\PYG{p}{(}noise \PYG{o}{=} \PYG{l+m}{0.01}\PYG{p}{,} obj \PYG{o}{=} sdcHH\PYG{p}{,} variables \PYG{o}{=} compExp\PYG{p}{,} method \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{additive\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Add noise to outliers}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} addNoise\PYG{p}{(}noise \PYG{o}{=} \PYG{l+m}{0.05}\PYG{p}{,} obj \PYG{o}{=} sdcHH\PYG{p}{,} variables \PYG{o}{=} compExp\PYG{p}{,} method \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{outdect\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Sum over expenditure categories to obtain consistent totals}
sdcHH\PYG{o}{@}manipNumVars\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TANHHEXP\PYGZsq{}}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{rowSums}\PYG{p}{(}sdcHH\PYG{o}{@}manipNumVars\PYG{p}{[}\PYG{p}{,}compExp\PYG{p}{]}\PYG{p}{)}
compInc \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCRMT\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCWAGE\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCFARMBSN\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCNFARMBSN\PYGZsq{}}\PYG{p}{,}
             \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCRENT\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCFIN\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCPENSN\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCOTHER\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Add noise to income variables}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} addNoise\PYG{p}{(}noise \PYG{o}{=} \PYG{l+m}{0.01}\PYG{p}{,} obj \PYG{o}{=} sdcHH\PYG{p}{,} variables \PYG{o}{=} compInc\PYG{p}{,} method \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{additive\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Add noise to outliers}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} addNoise\PYG{p}{(}noise \PYG{o}{=} \PYG{l+m}{0.05}\PYG{p}{,} obj \PYG{o}{=} sdcHH\PYG{p}{,} variables \PYG{o}{=} compInc\PYG{p}{,} method \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{outdect\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Sum over income categories to obtain consistent totals}
sdcHH\PYG{o}{@}manipNumVars\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZsq{}}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{rowSums}\PYG{p}{(}sdcHH\PYG{o}{@}manipNumVars\PYG{p}{[}\PYG{p}{,}compInc\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} recalculate risks after manually changing values in sdcMicro object}
calcRisks\PYG{p}{(}sdcHH\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Step 9a: Re-measure risk}
\label{\detokenize{casestudies:step-9a-re-measure-risk}}
For the categorical variables, we conclude that we have achieved
2-anonymity in the data with local suppression. Only 104 households, or
about 5\% of the total number, violate 3-anonymity. \hyperref[\detokenize{casestudies:tab98}]{Table \ref{\detokenize{casestudies:tab98}}} gives an
overview of these risk measures. The global risk is reduced to 0.02\%
(expected number of re-identifications 0.36), which is extremely low.
Therefore, we conclude that based on the categorical variables, the data
has been sufficiently anonymized. No household has a risk of
re-identification higher than 0.01 (1\%). By removing households with
rare values (or outliers) of the variable HHSIZE, we have reduced the
risk of spontaneous recognition of these households. This reasoning can
also be applied to the result of the risk of recoding the variable
LANDSIZEHA and PRAMming the variables identified to be important in the
nosy neighbor scenario. An intruder cannot know with certainty whether a
household that he recognizes in the data is the correct household, due
to the noise.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Number and proportion of households violating k-anonymity after anonymization}\label{\detokenize{casestudies:tab98}}\label{\detokenize{casestudies:id28}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
k-anonymity
&\sphinxstyletheadfamily 
Number HH violating
&\sphinxstyletheadfamily 
Percentage
\\
\hline
2
&
0
&
0 \%
\\
\hline
3
&
104
&
5.28 \%
\\
\hline
5
&
374
&
18.70 \%
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

These measures refer only to the categorical variables. To evaluate the
risk of the continuous variables we could use an interval measure or
closest neighbor algorithm. These risk measures are discussed in the Section
\sphinxhref{measure\_risk.html\#Riskmeasuresforcontinuousvariables}{Risk measures for continuous variables}.
We chose to use an interval measure, since exact value matching is
not our largest concern based on the assumed scenarios and external data
sources. Instead, datasets with similar values but not the exact same
values could be used for matching. Here the main concern is that the
values are sufficiently far from the original values, which is measured
with an interval measure.

\hyperref[\detokenize{casestudies:code920}]{Listing \ref{\detokenize{casestudies:code920}}} shows how to evaluate the interval measure for each of the
expenditure variables, which are contained in the vector
\sphinxstyleemphasis{compExp} %
\begin{footnote}[2]\sphinxAtStartFootnote
For illustrative purposes, we only show this evaluation for the
expenditure variables. It can be easily copied for the income
variables. The results are similar.
%
\end{footnote}. The different values of the parameter
\sphinxstyleemphasis{k} in the function dRisk() define the size of the interval around the
original value, as explained in the Section \sphinxhref{risk\_measure.html\#Intervalmeasure}{Interval measure}.
The larger \sphinxstyleemphasis{k}, the
larger the intervals, the higher the probability that a perturbed value
is in the interval around the original value and the higher the risk
measure. The result is satisfactory with relatively small intervals (k =
0.01), but not when increasing the size of the intervals. In our case, k
= 0.01 is sufficiently large, since we are looking at the components,
not the aggregates. We have to pay special attention to the outliers.
Here the value 0.01 for k is too small to assume that they are protected
when outside this small interval. It would be necessary to check
outliers and their perturbed values and there might be a need for a
higher level of perturbation for outliers. We conclude that, from a risk
perspective and based on the interval measure, the chosen levels of
noise are acceptable. In the next step, we will look at the impact on
the data utility of the noise addition.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code920}}}
\sphinxSetupCaptionForVerbatim{Measuring risk of re-identification of continuous variables}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
dRisk\PYG{p}{(}sdcHH\PYG{o}{@}origData\PYG{p}{[}\PYG{p}{,}compExp\PYG{p}{]}\PYG{p}{,} xm \PYG{o}{=} sdcHH\PYG{o}{@}manipNumVars\PYG{p}{[}\PYG{p}{,}compExp\PYG{p}{]}\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{0.01}\PYG{p}{)}
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} \PYG{l+m}{0.0608828}

dRisk\PYG{p}{(}sdcHH\PYG{o}{@}origData\PYG{p}{[}\PYG{p}{,}compExp\PYG{p}{]}\PYG{p}{,} xm \PYG{o}{=} sdcHH\PYG{o}{@}manipNumVars\PYG{p}{[}\PYG{p}{,}compExp\PYG{p}{]}\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{0.02}\PYG{p}{)}
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} \PYG{l+m}{0.9025875}

dRisk\PYG{p}{(}sdcHH\PYG{o}{@}origData\PYG{p}{[}\PYG{p}{,}compExp\PYG{p}{]}\PYG{p}{,} xm \PYG{o}{=} sdcHH\PYG{o}{@}manipNumVars\PYG{p}{[}\PYG{p}{,}compExp\PYG{p}{]}\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{0.05}\PYG{p}{)}
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} \PYG{l+m}{1}
\end{sphinxVerbatim}


\subsection{Step 10a: Re-measure utility}
\label{\detokenize{casestudies:step-10a-re-measure-utility}}
None of the variables has been recoded and the original level of detail
in the data is kept, except for the variable LANDSIZEHA. As described in
Step 8a, local suppression has only removed a few values in the other
variables, which has not greatly reduced the validity of the data.

The univariate frequency distributions of the variables ROOF, TOILET,
WATER, ELECTCON, FUELCOOK, OWNMOTORCYCLE, CAR, TV and LIVESTOCK did not,
by definition of the invariant PRAM method (see the Section
\sphinxhref{anon\_methods.html\#PRAM(PostRAndomizationMethod)}{PRAM (Post RAndomization Method)}), change
to a large extent. The tabulations are presented in \hyperref[\detokenize{casestudies:tab99}]{Table \ref{\detokenize{casestudies:tab99}}} (the
values 1 \textendash{} 9 and NA in the first row are the values of the variables and
.m after the variable name refers to the values after anonymization).

\begin{sphinxadmonition}{note}{Note:}
Although the frequencies are almost the same, this does not mean
that the values of particular households did not change.
\end{sphinxadmonition}

Values have been swapped between households. This becomes apparent when looking at
the multivariate frequencies of the WATER with the variable URBRUR in
\hyperref[\detokenize{casestudies:tab910}]{Table \ref{\detokenize{casestudies:tab910}}}. The multivariate frequencies of the PRAMmed with the
variable URBRUR could be of interest for users, but these are not
preserved. Since we applied PRAM within the regions, the multivariate
frequencies of the PRAMmed variables with REGION are preserved.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Univariate frequencies of the PRAMmed variable before and after anonymization}\label{\detokenize{casestudies:tab99}}\label{\detokenize{casestudies:id29}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
.
&\sphinxstyletheadfamily 
0
&\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily 
2
&\sphinxstyletheadfamily 
3
&\sphinxstyletheadfamily 
4
&\sphinxstyletheadfamily 
5
&\sphinxstyletheadfamily 
6
&\sphinxstyletheadfamily 
7
&\sphinxstyletheadfamily 
8
&\sphinxstyletheadfamily 
9
&\sphinxstyletheadfamily 
NA
\\
\hline
ROOF
&&
27
&
1
&
914
&
307
&
711
&&&&
10
&
1
\\
\hline
ROOF.m
&&
25
&
1
&
907
&
319
&
712
&&&&
6
&
1
\\
\hline
TOILET
&&
76
&
594
&
817
&
481
&&&&&
3
&\\
\hline
TOILET.m
&&
71
&
597
&
816
&
483
&&&&&
4
&\\
\hline
WATER
&&
128
&
323
&
304
&
383
&
562
&
197
&
18
&
21
&
35
&\\
\hline
WATER.m
&&
134
&
319
&
308
&
378
&
573
&
188
&
16
&
21
&
34
&\\
\hline
ELECTCON
&
768
&
216
&
8
&
2
&&&&&&&
977
\\
\hline
ELECTCON.m
&
761
&
218
&
8
&
3
&&&&&&&
981
\\
\hline
FUELCOOK
&&
1289
&
21
&
376
&
55
&
36
&&&&
139
&
55
\\
\hline
FUELCOOK.m
&&
1284
&
22
&
383
&
50
&
39
&&&&
143
&
50
\\
\hline
OWNMOTORCYCLE
&
1883
&
86
&&&&&&&&&
2
\\
\hline
OWNMOTORCYCLE.m
&
1882
&
86
&&&&&&&&&
2
\\
\hline
CAR
&
963
&
31
&&&&&&&&&
977
\\
\hline
CAR.m
&
966
&
25
&&&&&&&&&\\
\hline
TV
&
1216
&
264
&&&&&&&&&
491
\\
\hline
TV.m
&
1203
&
272
&&&&&&&&&
496
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Multivariate frequencies of the variables WATER with RURURB before and after anonymization}\label{\detokenize{casestudies:tab910}}\label{\detokenize{casestudies:id30}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
.
&\sphinxstyletheadfamily 
1
&\sphinxstyletheadfamily 
2
&\sphinxstyletheadfamily 
3
&\sphinxstyletheadfamily 
4
&\sphinxstyletheadfamily 
5
&\sphinxstyletheadfamily 
6
&\sphinxstyletheadfamily 
7
&\sphinxstyletheadfamily 
8
&\sphinxstyletheadfamily 
9
\\
\hline
WATER/URB
&
11
&
49
&
270
&
306
&
432
&
183
&
12
&
15
&
21
\\
\hline
WATER/RUR
&
114
&
274
&
32
&
76
&
130
&
14
&
6
&
6
&
14
\\
\hline
WATER/URB.m
&
79
&
220
&
203
&
229
&
402
&
125
&
10
&
12
&
19
\\
\hline
WATER/RUR.m
&
54
&
98
&
105
&
147
&
169
&
63
&
6
&
9
&
15
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

For conciseness, we restrict ourselves to the analysis of the
expenditure variables. The analysis of the income variables can be done
in the same way and leads to similar results.

We look at the effect of anonymization on some indicators as discussed
in Step 5. \hyperref[\detokenize{casestudies:tab911}]{Table \ref{\detokenize{casestudies:tab911}}} presents the point estimates and bootstrapped
confidence interval of the GINI coefficient %
\begin{footnote}[3]\sphinxAtStartFootnote
To compute the GINI coefficient, bootstrap to construct the
confidence intervals and plot the Lorenz curve we used the \sphinxstyleemphasis{R}
packages \sphinxstyleemphasis{laeken, reldist, bootstrap} and \sphinxstyleemphasis{ineq}.
%
\end{footnote} for
the sum of the expenditure components. The calculation of the GINI
coefficient and the confidence interval are based on the positive
expenditure values. We observe very small changes in the Gini
coefficient, that are statistically negligible. We use a visualization
to illustrate the impact on utility of the anonymization. Visualizations
are discussed in the Section
\sphinxhref{utility.html\#Assessingdatautilitywiththehelpofdatavisualizations(inR)}{Assessing data utility with the help of data visualizations (in R)}
and the specific \sphinxstyleemphasis{R} code for this case
study is available in the \sphinxstyleemphasis{R} script. The change in the inequality
measures is illustrated in \hyperref[\detokenize{casestudies:fig91}]{Fig.\@ \ref{\detokenize{casestudies:fig91}}}, which shows the Lorenz curves
based on the positive expenditure values before and after anonymization.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{GINI point estimates and bootstrapped confidence intervals for sum of expenditure components}\label{\detokenize{casestudies:tab911}}\label{\detokenize{casestudies:id31}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
.
&\sphinxstyletheadfamily 
before
&\sphinxstyletheadfamily 
after
\\
\hline
Point estimate
&
0.510
&
0.508
\\
\hline
Left bound of CI
&
0.476
&
0.476
\\
\hline
Right bound of CI
&
0.539
&
0.538
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{media/image21}.png}
\caption{Lorenz curve based on positive total expenditures values}\label{\detokenize{casestudies:fig91}}\label{\detokenize{casestudies:id32}}\end{figure}

We compare the mean monthly expenditures (MME) and mean monthly income
(MMI) for rural, urban and total population. The results are shown in
\hyperref[\detokenize{casestudies:tab912}]{Table \ref{\detokenize{casestudies:tab912}}}. We observe that the chosen levels of noise add only small
distortions to the MME and slightly larger changes to the MMI.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Mean monthly expenditure and mean monthly income per capita by rural/urban}\label{\detokenize{casestudies:tab912}}\label{\detokenize{casestudies:id33}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
.
&\sphinxstyletheadfamily 
before
&\sphinxstyletheadfamily 
after
\\
\hline
MME rural
&
400.5
&
398.5
\\
\hline
MME urban
&
457.3
&
459.9
\\
\hline
MME total
&
412.6
&
412.6
\\
\hline
MMI rural
&
397.1
&
402.2
\\
\hline
MMI urban
&
747.6
&
767.8
\\
\hline
MMI total
&
472.1
&
478.5
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\hyperref[\detokenize{casestudies:tab913}]{Table \ref{\detokenize{casestudies:tab913}}} shows the share of each of the components of the expenditure
variables before and after anonymization.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Shares of expenditures components}\label{\detokenize{casestudies:tab913}}\label{\detokenize{casestudies:id34}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
.
&\sphinxstyletheadfamily 
TFOODEXP
&\sphinxstyletheadfamily 
TALCHEXP
&\sphinxstyletheadfamily 
TCLTHEXP
&\sphinxstyletheadfamily 
THOUSEXP
&\sphinxstyletheadfamily 
TFURNEXP
&\sphinxstyletheadfamily 
THLTHEXP
\\
\hline
before
&
0.58
&
0.01
&
0.03
&
0.09
&
0.02
&
0.03
\\
\hline
after
&
0.59
&
0.01
&
0.03
&
0.09
&
0.02
&
0.03
\\
\hline
.
&
TTRANSEXP
&
TCOMMEXP
&
TRECEXP
&
TEDUEXP
&
TRESHOTEXP
&
TMISCEXP
\\
\hline
before
&
0.04
&
0.02
&
0.00
&
0.08
&
0.03
&
0.05
\\
\hline
after
&
0.04
&
0.02
&
0.00
&
0.08
&
0.03
&
0.05
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Anonymization for the creation of a SUF will inevitably lead to some
degree of utility loss. It is important to describe this loss in the
external report, so that users are aware of the changes in the data.
This is described in Step 11 and presented in
\sphinxhref{appendices.html\#AppendixC:InternalandExternalReportsforCaseStudies}{Appendix C}.
\sphinxhref{appendices.html\#AppendixC:InternalandExternalReportsforCaseStudies}{Appendix C}
also shows summary statistics and tabulations of the household level
variables before and after anonymization.

\sphinxstylestrong{Merging the household- and individual-level variables}

The next step is to merge the treated household variables with the
untreated individual variables for the anonymization of the individual
level variables. \hyperref[\detokenize{casestudies:code921}]{Listing \ref{\detokenize{casestudies:code921}}} shows the steps to merge these files. This
also includes the selection of variables used in the anonymization of
the individual-level variables. We create the \sphinxstyleemphasis{sdcMicro} object for the
anonymization of the individual variables in the same way as for the
household variable in \hyperref[\detokenize{casestudies:code99}]{Listing \ref{\detokenize{casestudies:code99}}}. Subsequently, we repeat Steps 6-10
for the individual-level variables.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code921}}}
\sphinxSetupCaptionForVerbatim{Merging the files with household and individual-level variables and creating an \sphinxstyleemphasis{sdcMicro} object for the anonymization of the individual-level variables}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Select variables (individual level)}
\PYG{c+c1}{\PYGZsh{} Key variables (individual level)}
selectedKeyVarsIND \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{GENDER\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{REL\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{MARITAL\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{AGEYRS\PYGZsq{}}\PYG{p}{,}
                       \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{EDUCY\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{ATSCHOOL\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INDUSTRY1\PYGZsq{}}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} list of selected key variables}

\PYG{c+c1}{\PYGZsh{} Sample weight (WGTHH, individual weight)}
selectedWeightVarIND \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{WGTHH\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Household ID}
selectedHouseholdID \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IDH\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} No strata}

\PYG{c+c1}{\PYGZsh{} Recombining anonymized HH datasets and individual level variables}
indVars \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{IDH\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{IDP\PYGZdq{}}\PYG{p}{,} selectedKeyVarsIND\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{WGTHH\PYGZdq{}}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} HID and all non HH variables}
fileInd \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{file}\PYG{p}{[}indVars\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} subset of file without HHVars}

HHmanip \PYG{o}{\PYGZlt{}\PYGZhy{}} extractManipData\PYG{p}{(}sdcHH\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} manipulated variables HH}
HHmanip \PYG{o}{\PYGZlt{}\PYGZhy{}} HHmanip\PYG{p}{[}HHmanip\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IDH\PYGZsq{}}\PYG{p}{]} \PYG{o}{!=} \PYG{l+m}{1782}\PYG{p}{,}\PYG{p}{]}

fileCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{merge}\PYG{p}{(}HHmanip\PYG{p}{,} fileInd\PYG{p}{,} by.x\PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IDH\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}

fileCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} fileCombined\PYG{p}{[}\PYG{k+kp}{order}\PYG{p}{(}fileCombined\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IDH\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}
fileCombined\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IDP\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,}\PYG{p}{]}

\PYG{k+kp}{dim}\PYG{p}{(}fileCombined\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} SDC objects with all variables and treated HH vars for}
\PYG{c+c1}{\PYGZsh{} anonymization of individual level variables}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} createSdcObj\PYG{p}{(}dat \PYG{o}{=} fileCombined\PYG{p}{,} keyVars \PYG{o}{=} selectedKeyVarsIND\PYG{p}{,}
                            weightVar \PYG{o}{=} selectedWeightVarIND\PYG{p}{,} hhId \PYG{o}{=} selectedHouseholdID\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Step 6b: Assessing disclosure risk (individual level)}
\label{\detokenize{casestudies:step-6b-assessing-disclosure-risk-individual-level}}
All key variables at the individual level are categorical. Therefore, we
can use k-anonymity and the individual and global risk measures (see
the Sections \sphinxhref{measure\_risk.html\#Individualrisk}{Individual risk}
and \sphinxhref{measure\_risk.html\#Globalrisk}{Global risk}).
The hierarchical risk is now of interest, given
the household structure in the dataset \sphinxstyleemphasis{fileCombined}, which includes
both household- and individual-level variables. The number of
individuals (absolute and relative) that violate k-anonymity at the
levels 2, 3 and 5 are shown in \hyperref[\detokenize{casestudies:tab914}]{Table \ref{\detokenize{casestudies:tab914}}}.

\begin{sphinxadmonition}{note}{Note:}
k-anonymity does not consider the household structure and therefore underestimates the risk.
Therefore, we are more interested in the individual and global hierarchical risk measures.
\end{sphinxadmonition}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{k-anonymity violations}\label{\detokenize{casestudies:tab914}}\label{\detokenize{casestudies:id35}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
k-anonymity
&\sphinxstyletheadfamily 
Number HH violating
&\sphinxstyletheadfamily 
Percentage
\\
\hline
2
&
998
&
9.91\%
\\
\hline
3
&
1,384
&
13.75\%
\\
\hline
5
&
2,194
&
21.79\%
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The global risk measures can be found using \sphinxstyleemphasis{R} as illustrated in
\hyperref[\detokenize{casestudies:code922}]{Listing \ref{\detokenize{casestudies:code922}}}. The global risk is 0.24\%, which corresponds to 24 expected
re-identifications. Accounting for the hierarchical structure, this
rises to 1.26\%, or 127 expected re-identifications. The global risk
measures are low compared to the number of \(k\)-anonymity violators due to
the low sampling weights. The high number of \(k\)-anonymity violators is
mainly due to the very detailed age variable. The risk measures are
based only on the individual level variables, since we assume that the
individual and household level variables are be used simultaneously by
an intruder. If we would consider an intruder scenario where these
variables are used simultaneously by an intruder to re-identify
individuals, the household level variables should also be taken into
account here. This would results in a high number of key variables.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code922}}}
\sphinxSetupCaptionForVerbatim{Global risk of the individual-level variables}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{k+kp}{print}\PYG{p}{(}sdcCombined\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{risk\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Risk measures:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Number of observations with higher risk than the main part of the data: 0}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Expected number of re\PYGZhy{}identifications: 23.98 (0.24 \PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Information on hierarchical risk:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Expected number of re\PYGZhy{}identifications: 127.12 (1.26 \PYGZpc{})}
\end{sphinxVerbatim}


\subsection{Step 7b: Assessing utility (individual level)}
\label{\detokenize{casestudies:step-7b-assessing-utility-individual-level}}
We evaluate the utility measures selected in Step 5 besides some general
utility measures. The values computed from the raw data are presented in
step 10b to allow for direct comparison with the values computed from
the anonymized data.


\subsection{Step 8b: Choice and application of SDC methods (individual level)}
\label{\detokenize{casestudies:step-8b-choice-and-application-of-sdc-methods-individual-level}}
We use the same approach for the anonymization of the individual-level
categorical key variables as for the household level categorical
variables described earlier: first use global recoding to limit the
necessary number of suppressions, then apply local suppressions and
finally, if necessary, use of perturbative methods.

The variable AGEYRS (i.e., age in years) has many different values (age
in months for children 0 \textendash{} 1 years and age in years for individuals over
1 year). This level of detail leads to a high level of re-identification
risk, given external datasets with exact age as well as knowledge of the
exact age of close relatives. We have to reduce the level of detail in
the age variables by recoding the age values (see the Section
\sphinxhref{anon\_methods.html\#Recoding}{Recoding} ). First, we recode the values from 15 to 65 in ten-year
intervals. Since some indicators related to education are computed from
the survey dataset, our first approach is not to recode the age range 0
\textendash{} 15 years. For children under the age of 1 year, we reduce the level of
detail and recode these to 0 years. These recodes are shown in \hyperref[\detokenize{casestudies:code923}]{Listing \ref{\detokenize{casestudies:code923}}}.
We also top-code age at the age of 65 years. This protects
individuals with high (rare) age values.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code923}}}
\sphinxSetupCaptionForVerbatim{Recoding age in 10-year intervals in the range 15 \textendash{} 65 and top code age over 65 years}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Recoding age and top coding age (top code 65), below that 10 year age}
\PYG{c+c1}{\PYGZsh{} groups, children aged under 1 are recoded 0 (previously in months)}

sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS\PYG{p}{[}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS \PYG{o}{\PYGZgt{}=} \PYG{l+m}{0} \PYG{o}{\PYGZam{}}
sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS \PYG{o}{\PYGZlt{}} \PYG{l+m}{1}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{0}

sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS\PYG{p}{[}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS \PYG{o}{\PYGZgt{}=} \PYG{l+m}{15} \PYG{o}{\PYGZam{}}
sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS \PYG{o}{\PYGZlt{}} \PYG{l+m}{25}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{20}

\PYG{k+kc}{...}

sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS\PYG{p}{[}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS \PYG{o}{\PYGZgt{}=} \PYG{l+m}{55} \PYG{o}{\PYGZam{}}
sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS \PYG{o}{\PYGZlt{}} \PYG{l+m}{66}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{60}

\PYG{c+c1}{\PYGZsh{} topBotCoding also recalculates risk based on manual recoding above}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{o}{*}\PYG{o}{*}topBotCoding\PYG{p}{(}obj \PYG{o}{=} sdcCombined\PYG{p}{,} value \PYG{o}{=} \PYG{l+m}{65}\PYG{p}{,}
replacement \PYG{o}{=} \PYG{l+m}{65}\PYG{p}{,} kind \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{top\PYGZsq{}}\PYG{p}{,} column \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{AGEYRS\PYGZsq{}}\PYG{p}{)}

\PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} check results}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    0    1    2    3    4    5    6    7    8    9   10   11   12   13   14}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  311  367  340  332  260  334  344  297  344  281  336  297  326  299  263}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}   20   30   40   50   60   65}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 1847 1220  889  554  314  325}
\end{sphinxVerbatim}

These recodes already reduce the risk to 531 individuals violating
3-anonymity. We could recode the values of age in the lower range
according to the age categories users require (e.g., 8 \textendash{} 11 for
education). There are many different categories for different
indicators, however, including education indicators. This would reduce
the utility of the data for some users. Therefore, we decide to look
first at the number of suppressions needed in local suppression after
this limited recoding. If the number of suppressions is too high, we can
go back and recode age in the range 1 \textendash{} 14 years.

In \hyperref[\detokenize{casestudies:code924}]{Listing \ref{\detokenize{casestudies:code924}}} we demonstrate how one might experiment with local
suppression to find the best option. We use local suppression to achieve
3-anonymity (see the Section \sphinxhref{anon\_methods.html\#Localsuppression}{Local suppression} . On the first
attempt, we do not specify any importance vector; this leads to many
suppressions in the variable AGEYRS (see \hyperref[\detokenize{casestudies:tab915}]{Table \ref{\detokenize{casestudies:tab915}}} below, first row),
however. This is undesirable from a utility point of view. Therefore, we
decide to specify an importance vector to prevent suppressions in the
variable AGEYRS. Suppressing the variable GENDER is also undesirable
from the utility point of view. The variable GENDER is a type of
variable that should not have suppressions. We set GENDER as variable
with the second highest importance. After specifying the importance
vector to prevent suppressions of the age variable, there are no age
suppressions (see \hyperref[\detokenize{casestudies:tab915}]{Table \ref{\detokenize{casestudies:tab915}}}, second row). The total number of
suppressions in the other variables increased, however, from 253 to 323
because of the importance vector. This is to be expected because the
algorithm without the importance vector minimizes the total number of
suppressions by first suppressing values in variables with many
categories \textendash{} in this case, age and gender. Specifying an importance
vector prevents reaching this optimality and hence leads to a higher
total number of suppressions. There is a trade-off between which
variables are suppressed and the total number of suppressions. After
specifying an importance vector, the variable REL has many suppressions
(see \hyperref[\detokenize{casestudies:tab915}]{Table \ref{\detokenize{casestudies:tab915}}}, second row). We choose this second option.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code924}}}
\sphinxSetupCaptionForVerbatim{Experimenting with different options in local suppression}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Copy of sdcMicro object to later undo steps}
sdcCopy \PYG{o}{\PYGZlt{}\PYGZhy{}} sdcCombined

\PYG{c+c1}{\PYGZsh{} Importance vectors for local suppression (depending on utility measures)}
impVec1 \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kc}{NULL} \PYG{c+c1}{\PYGZsh{} for optimal suppression}
impVec2 \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{rep}\PYG{p}{(}\PYG{k+kp}{length}\PYG{p}{(}selectedKeyVarsIND\PYG{p}{)}\PYG{p}{,} \PYG{k+kp}{length}\PYG{p}{(}selectedKeyVarsIND\PYG{p}{)}\PYG{p}{)}
impVec2\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{AGEYRS\PYGZsq{}}\PYG{p}{,} selectedKeyVarsIND\PYG{p}{)}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{1} \PYG{c+c1}{\PYGZsh{} AGEYRS}
impVec2\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{GENDER\PYGZsq{}}\PYG{p}{,} selectedKeyVarsIND\PYG{p}{)}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{2} \PYG{c+c1}{\PYGZsh{} GENDER}

\PYG{c+c1}{\PYGZsh{} Local suppression without importance vector}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} localSuppression\PYG{p}{(}sdcCombined\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{2}\PYG{p}{,} importance \PYG{o}{=} impVec1\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Number of suppressions per variable}
\PYG{k+kp}{print}\PYG{p}{(}sdcCombined\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Local Suppression:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}       KeyVar \textbar{} Suppressions (\PYGZsh{}) \textbar{} Suppressions (\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}       GENDER \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}          REL \textbar{}               34 \textbar{}            0.338}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}      MARITAL \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}       AGEYRS \textbar{}              195 \textbar{}            1.937}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}        EDUCY \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  EDYRSCURRAT \textbar{}                3 \textbar{}            0.030}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     ATSCHOOL \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    INDUSTRY1 \textbar{}               21 \textbar{}            0.209}

\PYG{c+c1}{\PYGZsh{} Number of suppressions per variable for each value of AGEYRS}
\PYG{k+kp}{table}\PYG{p}{(}sdcCopy\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 30 40 50 60 65}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  0  0  0  0  0  0  2  0  2  1  0  1  4  1  5 25 53 37 36 15 13}

\PYG{c+c1}{\PYGZsh{} Undo local suppression}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} undolast\PYG{p}{(}sdcCombined\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Local suppression with importance vector on AGEYRS and GENDER}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} localSuppression\PYG{p}{(}sdcCombined\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{2}\PYG{p}{,} importance \PYG{o}{=} impVec2\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Number of suppressions per variable}
\PYG{k+kp}{print}\PYG{p}{(}sdcCombined\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Local Suppression:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}       KeyVar \textbar{} Suppressions (\PYGZsh{}) \textbar{} Suppressions (\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}       GENDER \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}          REL \textbar{}              323 \textbar{}            3.208}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}      MARITAL \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}       AGEYRS \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}        EDUCY \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  EDYRSCURRAT \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     ATSCHOOL \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    INDUSTRY1 \textbar{}                0 \textbar{}            0.000}

\PYG{c+c1}{\PYGZsh{} Number of suppressions for each value of the variable AGEYRS}
\PYG{k+kp}{table}\PYG{p}{(}sdcCopy\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 30 40 50 60 65}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0}
\end{sphinxVerbatim}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Number of suppressions by variable for different variations of local suppression}\label{\detokenize{casestudies:tab915}}\label{\detokenize{casestudies:id36}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
Local suppression options
&\sphinxstyletheadfamily 
GENDER
&\sphinxstyletheadfamily 
REL
&\sphinxstyletheadfamily 
MARITAL
&\sphinxstyletheadfamily 
AGEYRS
&\sphinxstyletheadfamily 
EDUCY
&\sphinxstyletheadfamily 
EDYRSCURATT
&\sphinxstyletheadfamily 
ATSCHOOL
&\sphinxstyletheadfamily 
INDUSTRY1
\\
\hline
k = 2, no imp
&
0
&
34
&
0
&
195
&
0
&
3
&
0
&
21
\\
\hline
k = 2, imp on AGEYRS
&
0
&
323
&
0
&
0
&
0
&
0
&
0
&
0
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsection{Step 9b: Re-measure risk (individual level)}
\label{\detokenize{casestudies:step-9b-re-measure-risk-individual-level}}
We re-evaluate the risk measures selected in Step 6b. \hyperref[\detokenize{casestudies:tab916}]{Table \ref{\detokenize{casestudies:tab916}}} shows
that local suppression, not surprisingly, has reduced the number of
individuals violating 2-anonymity to 0.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{k-anonymity violations}\label{\detokenize{casestudies:tab916}}\label{\detokenize{casestudies:id37}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
k-anonymity
&\sphinxstyletheadfamily 
Number HH violating
&\sphinxstyletheadfamily 
Percentage
\\
\hline
2
&
0
&
0.00 \%
\\
\hline
3
&
197
&
1.96 \%
\\
\hline
5
&
518
&
5.15 \%
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The hierarchical global risk was reduced to 0.11\%, which corresponds to
11.3 expected re-identifications. The highest individual hierarchical
re-identification risk is 1.21\%. These risk levels would seem acceptable
for a SUF.


\subsection{Step 10b: Re-measure utility (individual level)}
\label{\detokenize{casestudies:step-10b-re-measure-utility-individual-level}}
We selected two utility measures for the individual variables: primary
and secondary education enrollment, both also by gender. These two
measures are sensitive to changes in the variables gender (GENDER), age
(AGEYRS) and education (EDUCY and EDYRSATCURR), and therefore give a
good overview of the impact of the anonymization. As shown in \hyperref[\detokenize{casestudies:tab917}]{Table \ref{\detokenize{casestudies:tab917}}}
the anonymization did not change the results. The results of the
tabulations in
\sphinxhref{appendices.html\#AppendixC:InternalandExternalReportsforCaseStudies}{Appendix C}
confirm these results.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Net enrollment in primary and secondary education by gender}\label{\detokenize{casestudies:tab917}}\label{\detokenize{casestudies:id38}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
.
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{7}}
\sphinxstyletheadfamily Primary education
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{7}}
\sphinxstyletheadfamily Secondary education
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstyletheadfamily &\sphinxstyletheadfamily &\sphinxstyletheadfamily &\sphinxstyletheadfamily &\sphinxstyletheadfamily &\sphinxstyletheadfamily &\sphinxstyletheadfamily \\
\hline
Before
&
72.6\%
&
74.2\%
&
70.9\%
&
42.0\%
&
44.8\%
&
39.1\%
\\
\hline
After
&
72.6\%
&
74.2\%
&
70.9\%
&
42.0\%
&
44.8\%
&
39.1\%
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsection{Step 11: Audit and reporting}
\label{\detokenize{casestudies:step-11-audit-and-reporting}}
In the audit step, we check whether the data allow for reproduction of
published figures from the original dataset and relationships between
variables and other data characteristics are preserved in the
anonymization process. In short, we check whether the dataset is valid
for analytical purposes. There are no figures available that were
published from the dataset and need to be reproducible from the
anonymized data.

In Step 2, we explored the data characteristics and relationships
between variables. These data characteristics and relationships have
been mainly preserved, since we took them into account when choosing the
appropriate anonymization methods. The variables TANHHEXP and
INCTOTGROSSHH are the sums of the individual components, because we
added noise to the components and reconstructed the aggregates by
summing over the components. Initially, the income variables were all
positive. This characteristic has been violated, as a result of noise
addition. Since values of the variable AGEYRS were not perturbed, but
only recoded and suppressed, we did not introduce unlikely combinations,
such as a 60-year-old individual enrolled in primary education. Also, by
separating the anonymization process into two parts, one for
household-level variables and one for individual-level variables, the
values of variables measured at the household level agree for all
members of each household.

Furthermore, we drafted two reports, internal and external, on the
anonymization of the case study dataset. The internal report includes
the methods used, the risk before and after anonymization as well as the
reasons for the selected methods and their parameters. The external
report focuses on the changes in the data and the loss in utility. Focus
here should be on the number of suppressions as well as the perturbative
methods (PRAM). This is described in the previous steps.

\begin{sphinxadmonition}{note}{Note:}
When creating a SUF, it is inevitable that there will be a loss of
information and it is very important for the users to be aware of these
changes and release them in a report that accompanies the data.
\end{sphinxadmonition}

\sphinxhref{appendices.html\#AppendixC:InternalandExternalReportsforCaseStudies}{Appendix C}
provides examples of an internal and external report of the
anonymization process of this dataset. Depending on the users and
readers of the reports, the content may differ. The code to this case
study shows how to obtain the information for the reports. Some measures
are also available in the standard reports generated with the report()
function. This is shown in \hyperref[\detokenize{casestudies:code925}]{Listing \ref{\detokenize{casestudies:code925}}}. The report() function will only
use the data available in the \sphinxstyleemphasis{sdcMicro} object, which does not contain
all households for sdcHH.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code925}}}
\sphinxSetupCaptionForVerbatim{Using the report() function for internal and external reports}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Create reports with sdcMicro report() function}
report\PYG{p}{(}sdcHH\PYG{p}{,} internal \PYG{o}{=} \PYG{n+nb+bp}{F}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} external (brief) report}
report\PYG{p}{(}sdcHH\PYG{p}{,} internal \PYG{o}{=} \PYG{n+nb+bp}{T}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} internal (extended) report}

\PYG{c+c1}{\PYGZsh{} Create reports with sdcMicro report() function}
report\PYG{p}{(}sdcCombined\PYG{p}{,} internal \PYG{o}{=} \PYG{n+nb+bp}{F}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} external (brief) report}
report\PYG{p}{(}sdcCombined\PYG{p}{,} internal \PYG{o}{=} \PYG{n+nb+bp}{T}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} internal (extended) report}
\end{sphinxVerbatim}


\subsection{Step 12: Data release}
\label{\detokenize{casestudies:step-12-data-release}}
The final step is the release of the anonymized dataset together with
the external report. \hyperref[\detokenize{casestudies:code926}]{Listing \ref{\detokenize{casestudies:code926}}} shows how to collect the data from the
\sphinxstyleemphasis{sdcMicro} object with the extractManipData() function. Before releasing
the file, we add an individual ID to the file (line number in
household). We export the anonymized dataset in as \sphinxstyleemphasis{STATA} file. The Section
\sphinxhref{sdcMicro.html\#ReadfunctionsinR}{Read functions in R}
presents functions for exporting files in other data formats.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code926}}}
\sphinxSetupCaptionForVerbatim{Exporting the anonymized dataset}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Anonymized dataset}
\PYG{c+c1}{\PYGZsh{} Household variables and individual variables}
\PYG{c+c1}{\PYGZsh{} extracts all variables, not just the manipulated ones}
dataAnon \PYG{o}{\PYGZlt{}\PYGZhy{}} extractManipData\PYG{p}{(}sdcCombined\PYG{p}{,} ignoreKeyVars \PYG{o}{=} \PYG{n+nb+bp}{F}\PYG{p}{,} ignorePramVars \PYG{o}{=} \PYG{n+nb+bp}{F}\PYG{p}{,}
                             ignoreNumVars \PYG{o}{=} \PYG{n+nb+bp}{F}\PYG{p}{,} ignoreStrataVar \PYG{o}{=} \PYG{n+nb+bp}{F}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Create STATA file}
write.dta\PYG{p}{(}dataframe \PYG{o}{=} dataAnon\PYG{p}{,} file\PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Case1DataAnon.dta\PYGZsq{}}\PYG{p}{,} convert.dates\PYG{o}{=}\PYG{k+kc}{TRUE}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Case study 2 - PUF}
\label{\detokenize{casestudies:case-study-2-puf}}
This case study is a continuation of case study 1 in the Section
{\hyperref[\detokenize{casestudies:case-study-1-suf}]{\sphinxcrossref{Case study 1- SUF}}} . Case
study 1 produces a SUF file. In this case study we use this SUF file to
produce a PUF file of the same dataset, which can be freely distributed.
The structure of the SUF and PUF releases will be the same. However, the
PUF will contain fewer variables and less (detailed) information than
the SUF. We refer to the Section {\hyperref[\detokenize{casestudies:case-study-1-suf}]{\sphinxcrossref{Case study 1- SUF}}}
for a description of the dataset.

\begin{sphinxadmonition}{note}{Note:}
It is also possible to directly produce a PUF from a dataset
without first creating a SUF.
\end{sphinxadmonition}

As in case study 1, we show how the creation of a PUF can be achieved
using the open source and free \sphinxstyleemphasis{sdcMicro} package and \sphinxstyleemphasis{R}. A
ready-to-run \sphinxstyleemphasis{R} script for this case study and the dataset are also
available to reproduce the results and allow the user to adapt the code
(see \sphinxurl{http://ihsn.org/home/projects/sdc-practice}). Extracts of this code
are presented in this section to illustrate several steps of the
anonymization process.

\begin{sphinxadmonition}{note}{Note:}
The choices of methods and parameters in this case study are based on this particular dataset and the results and
choices might be different for other datasets.
\end{sphinxadmonition}

This case study follows the steps of the SDC process outlined in
\sphinxhref{process.html}{The SDC Process}.


\subsection{Step 1: Need for disclosure control}
\label{\detokenize{casestudies:id6}}
The same reasoning as in case study 1 applies: the SUF dataset produced
in case study 1 contains data on individuals and households and some
variables are confidential and/or sensitive. The decisions made in case
study 1 are based on the disclosure scenarios for a SUF release. The
anonymization applied for the SUF does not provide sufficient protection
for the release as PUF and the SUF file cannot be released as PUF
without further treatment. Therefore, we have to repeat the SDC process
with a different set of disclosure scenarios based on the
characteristics of a PUF release (see Step 4). This leads to different
risk measures, lower accepted risk levels and different SDC methods.


\subsection{Step 2: Data preparation and exploring data characteristics}
\label{\detokenize{casestudies:id7}}
In order to guarantee consistency between the released PUF and SUF
files, which is required to prevent intruders from using the datasets
together (SUF users have also access to the PUF file), we have to use
the anonymized SUF file to create the PUF file (see also the Section
\sphinxhref{process.html\#Step3:Typeofrelease}{Step 3: Type of release}).
In this way all information in the PUF file is also contained in the
SUF, and the PUF does not provide additional information to an intruder
with access to the SUF. We load the required packages to read the data
(\sphinxstyleemphasis{foreign} package for \sphinxstyleemphasis{STATA} files) and load the SUF dataset into
“file” as illustrated in \hyperref[\detokenize{casestudies:code927}]{Listing \ref{\detokenize{casestudies:code927}}}. We also load the original data
file (raw data) as “fileOrig”. We need the raw data to undo perturbative
methods used in case study 1 (see Step 8) and to compare data utility
measures (see Step 5). To evaluate the utility loss in the PUF, we have
to compare the information in the anonymized PUF file with the
information in the raw data. For an overview of the data characteristics
and a description of the variables in both files, we refer to Step 2 of
{\hyperref[\detokenize{casestudies:case-study-1-suf}]{\sphinxcrossref{Case study 1- SUF}}} .

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code927}}}
\sphinxSetupCaptionForVerbatim{Loading required packages and datasets}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Load required packages}
\PYG{k+kn}{library}\PYG{p}{(}foreign\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} for read/write function for STATA}
\PYG{k+kn}{library}\PYG{p}{(}sdcMicro\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} sdcMicro package}

\PYG{c+c1}{\PYGZsh{} Set working directory \PYGZhy{} set to the path on your machine}
\PYG{k+kp}{setwd}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{/Users/CaseStudy2\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Specify file name of SUF file from case study 1}
fname \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{CaseDataAnon.dta\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Specify file name of original dataset (raw data)}
fnameOrig \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{CaseA.dta\PYGZdq{}}

\PYG{c+c1}{\PYGZsh{} Read\PYGZhy{}in files}
file     \PYG{o}{\PYGZlt{}\PYGZhy{}} read.dta\PYG{p}{(}fname\PYG{p}{,} convert.factors \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} SUF file case study 1}
fileOrig \PYG{o}{\PYGZlt{}\PYGZhy{}} read.dta\PYG{p}{(}fnameOrig\PYG{p}{,} convert.factors \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} original data}
\end{sphinxVerbatim}

We check the number of variables and number of observations of both
files and the variable names of the SUF file, as shown in \hyperref[\detokenize{casestudies:code928}]{Listing \ref{\detokenize{casestudies:code928}}}.
The PUF file has fewer records and fewer variables than the original
data file, since we removed large households and several variables to
generate the SUF file.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code928}}}
\sphinxSetupCaptionForVerbatim{Number of individuals and variables and variable names}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Dimensions of file (observations, variables)}
\PYG{k+kp}{dim}\PYG{p}{(}\PYG{k+kp}{file}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 10068    49}

\PYG{k+kp}{dim}\PYG{p}{(}fileOrig\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 10574    68}

\PYG{k+kp}{colnames}\PYG{p}{(}\PYG{k+kp}{file}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Variable names}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  [1] \PYGZdq{}IDH\PYGZdq{}           \PYGZdq{}URBRUR\PYGZdq{}        \PYGZdq{}REGION\PYGZdq{}        \PYGZdq{}HHSIZE\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  [5] \PYGZdq{}OWNAGLAND\PYGZdq{}     \PYGZdq{}RELIG\PYGZdq{}         \PYGZdq{}ROOF\PYGZdq{}          \PYGZdq{}TOILET\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  [9] \PYGZdq{}WATER\PYGZdq{}         \PYGZdq{}ELECTCON\PYGZdq{}      \PYGZdq{}FUELCOOK\PYGZdq{}      \PYGZdq{}OWNMOTORCYCLE\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [13] \PYGZdq{}CAR\PYGZdq{}           \PYGZdq{}TV\PYGZdq{}            \PYGZdq{}LIVESTOCK\PYGZdq{}     \PYGZdq{}LANDSIZEHA\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [17] \PYGZdq{}TANHHEXP\PYGZdq{}      \PYGZdq{}TFOODEXP\PYGZdq{}      \PYGZdq{}TALCHEXP\PYGZdq{}      \PYGZdq{}TCLTHEXP\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [21] \PYGZdq{}THOUSEXP\PYGZdq{}      \PYGZdq{}TFURNEXP\PYGZdq{}      \PYGZdq{}THLTHEXP\PYGZdq{}      \PYGZdq{}TTRANSEXP\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [25] \PYGZdq{}TCOMMEXP\PYGZdq{}      \PYGZdq{}TRECEXP\PYGZdq{}       \PYGZdq{}TEDUEXP\PYGZdq{}       \PYGZdq{}TRESTHOTEXP\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [29] \PYGZdq{}TMISCEXP\PYGZdq{}      \PYGZdq{}INCTOTGROSSHH\PYGZdq{} \PYGZdq{}INCRMT\PYGZdq{}        \PYGZdq{}INCWAGE\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [33] \PYGZdq{}INCFARMBSN\PYGZdq{}    \PYGZdq{}INCNFARMBSN\PYGZdq{}   \PYGZdq{}INCRENT\PYGZdq{}       \PYGZdq{}INCFIN\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [37] \PYGZdq{}INCPENSN\PYGZdq{}      \PYGZdq{}INCOTHER\PYGZdq{}      \PYGZdq{}WGTPOP\PYGZdq{}        \PYGZdq{}IDP\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [41] \PYGZdq{}GENDER\PYGZdq{}        \PYGZdq{}REL\PYGZdq{}           \PYGZdq{}MARITAL\PYGZdq{}       \PYGZdq{}AGEYRS\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [45] \PYGZdq{}EDUCY\PYGZdq{}         \PYGZdq{}EDYRSCURRAT\PYGZdq{}   \PYGZdq{}ATSCHOOL\PYGZdq{}      \PYGZdq{}INDUSTRY1\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [49] \PYGZdq{}WGTHH\PYGZdq{}}
\end{sphinxVerbatim}

To get an overview of the values of the variables, we use tabulations
and cross-tabulations for categorical variables and summary statistics
for continuous variables. To include the number of missing values (‘NA’
or other), we use the option useNA = “ifany” in the table() function.
For some variables, these tabulations differ from the tabulations of the
raw data, due to the anonymization of the SUF file.

In \hyperref[\detokenize{casestudies:tab918}]{Table \ref{\detokenize{casestudies:tab918}}} the variables in the dataset “file” are listed along with
concise descriptions of the variables, the level at which they are
collected (individual level (IND) or household level (HH)), the
measurement type (continuous, semi-continuous or categorical) and value
ranges. Note that the dataset contains a selection of 49 variables of
the 68 variable selected for the SUF release. The variables have been
preselected based on their relevance for data users and some variables
were removed while creating a SUF file. The numerical values for many of
the categorical variables are codes that refer to values, e.g., in the
variable “URBRUR”, 1 stands for ‘rural’ and 2 for ‘urban’. More
information on the meanings of coded values of the categorical variables
is available in the \sphinxstyleemphasis{R} code for this case study.

Any data cleaning, such as recoding missing value codes and removing
empty variables, was already done in case study 1. The same holds for
removing any direct identifiers. Direct identifiers are not released in
the SUF file.

We identified the following sensitive variables in the dataset:
variables related to schooling and labor force status as well as income
and expenditure related variables. These variables need protection.
Whether a variable is considered sensitive may depend on the release
type, country and the dataset itself.


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{|l|l|l|l|l|l|}
\caption{Overview of the variables in the dataset\strut}\label{\detokenize{casestudies:tab918}}\label{\detokenize{casestudies:id39}}\\*[\sphinxlongtablecapskipadjust]
\hline
\sphinxstyletheadfamily 
No.
&\sphinxstyletheadfamily 
Variable name
&\sphinxstyletheadfamily 
Description
&\sphinxstyletheadfamily 
Level
&\sphinxstyletheadfamily 
Measurement
&\sphinxstyletheadfamily 
Values
\\
\hline
\endfirsthead

\multicolumn{6}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} -- continued from previous page}}}\\
\hline
\sphinxstyletheadfamily 
No.
&\sphinxstyletheadfamily 
Variable name
&\sphinxstyletheadfamily 
Description
&\sphinxstyletheadfamily 
Level
&\sphinxstyletheadfamily 
Measurement
&\sphinxstyletheadfamily 
Values
\\
\hline
\endhead

\hline
\multicolumn{6}{r}{\makebox[0pt][r]{\sphinxtablecontinued{Continued on next page}}}\\
\endfoot

\endlastfoot

1
&
IDH
&
Household ID
&
HH
&
.
&
1-2,000
\\
\hline
2
&
IDP
&
Individual ID
&
IND
&
.
&
1-13
\\
\hline
3
&
REGION
&
Region
&
HH
&
categorical
&
1-6
\\
\hline
4
&
URBRUR
&
Area of residence
&
HH
&
categorical
&
1, 2
\\
\hline
5
&
WGTHH
&
Individual weighting coefficient
&
HH
&
weight
&
31.2-8495.7
\\
\hline
6
&
WGTPOP
&
Population weighting coefficient
&
IND
&
weight
&
45.8-93452.2
\\
\hline
7
&
HHSIZE
&
Household size
&
HH
&
semi-continuous
&
1-33
\\
\hline
8
&
GENDER
&
Gender
&
IND
&
categorical
&
0, 1
\\
\hline
9
&
REL
&
Relationship to household head
&
IND
&
categorical
&
1-9
\\
\hline
10
&
MARITAL
&
Marital status
&
IND
&
categorical
&
1-6
\\
\hline
11
&
AGEYRS
&
Age in completed years
&
IND
&
semi-continuous
&
0-65
\\
\hline
12
&
RELIG
&
Religion of household head
&
HH
&
categorical
&
1, 5-7, 9
\\
\hline
13
&
ATSCHOOL
&
Currently enrolled in school
&
IND
&
categorical
&
0, 1
\\
\hline
14
&
EDUCY
&
Highest
level of education attended
&
IND
&
categorical
&
1-6
\\
\hline
15
&
EDYRSCUR
AT
&
Years of
education for currently enrolled
&
IND
&
semi-continuous
&
1-18
\\
\hline
16
&
INDUSTRY
&
Industry
classification (1-digit)
&
IND
&
categorical
&
1-10
\\
\hline
17
&
ROOF
&
Main
material used for roof
&
IND
&
categorical
&
1-5, 9
\\
\hline
18
&
TOILET
&
Main
toilet facility
&
HH
&
categorical
&
1-4, 9
\\
\hline
19
&
ELECTCON
&
Electricity
&
HH
&
categorical
&
0-3
\\
\hline
20
&
FUELCOOK
&
Main
cooking fuel
&
HH
&
categorical
&
1-5, 9
\\
\hline
21
&
WATER
&
Main
source of water
&
HH
&
categorical
&
1-9
\\
\hline
22
&
OWNAGLAN
&
Ownership
of agricultural land
&
HH
&
categorical
&
1-3
\\
\hline
23
&
LANDSIZE
&
Land size owned by household (ha)
(agric and non agric)
&
HH
&
continuous
&
0-40
\\
\hline
24
&
OWNMOTORYCLE
&
Ownership of motorcycle
&
HH
&
categorical
&
0, 1
\\
\hline
25
&
CAR
&
Ownership of car
&
HH
&
categorical
&
0, 1
\\
\hline
26
&
TV
&
Ownership
of television
&
HH
&
categorical
&
0, 1
\\
\hline
27
&
LIVESTOC
&
Number of
large-sized livestock owned
&
HH
&
semi-continuous
&
0-25
\\
\hline
28
&
INCRMT
&
Income \textendash{} Remittances
&
HH
&
continuous
&\\
\hline
29
&
INCWAGE
&
Income - Wages and salaries
&
HH
&
continuous
&\\
\hline
30
&
INCFARMBSN
&
Income - Gross income
from household farm businesses
&
HH
&
continuous
&\\
\hline
31
&
INCNFARMBSN
&
Income - Gross income from
household nonfarm businesses
&
HH
&
continuous
&\\
\hline
32
&
INCRENT
&
Income - Rent
&
HH
&
continuous
&\\
\hline
33
&
INCFIN
&
Income - Financial
&
HH
&
continuous
&\\
\hline
34
&
INCPENSN
&
Income - Pensions/social assistance
&
HH
&
continuous
&\\
\hline
35
&
INCOTHER
&
Income - Other
&
HH
&
continuous
&\\
\hline
36
&
INCTOTGROSHH
&
Income - Total
&
HH
&
continuous
&\\
\hline
37
&
FARMEMP
&&&&\\
\hline
38
&
TFOODEXP
&
Total expenditure on food
&
HH
&
continuous
&\\
\hline
39
&
TALCHEXP
&
Total expenditure on alcoholic
beverages, tobacco and narcotics
&
HH
&
continuous
&\\
\hline
40
&
TCLTHEXP
&
Total expenditure on clothing
&
HH
&
continuous
&\\
\hline
41
&
THOUSEXP
&
Total expenditure on housing
&
HH
&
continuous
&\\
\hline
42
&
TFURNEXP
&
Total expenditure on furnishing
&
HH
&
continuous
&\\
\hline
43
&
THLTHEXP
&
Total expenditure on health
&
HH
&
continuous
&\\
\hline
43
&
TTRANSEXP
&
Total expenditure on transport
&
HH
&
continuous
&\\
\hline
44
&
TCOMMEXP
&
Total expenditure on communication
&
HH
&
continuous
&\\
\hline
45
&
TRECEXP
&
Total expenditure on recreation
&
HH
&
continuous
&\\
\hline
46
&
TEDUEXP
&
Total expenditure on education
&
HH
&
continuous
&\\
\hline
47
&
TRESHOTEXP
&
Total expenditure on restaurants
and hotels
&
HH
&
continuous
&\\
\hline
48
&
TMISCEXP
&
Total expenditure on
miscellaneous spending
&
HH
&
continuous
&\\
\hline
49
&
TANHHEXP
&
Total annual nominal household
expenditures
&
HH
&
continuous
&\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}

It is always important to ensure that the relationships between
variables in the data are preserved during the anonymization process and
to explore and take note of these relationships before beginning the
anonymization. At the end of the anonymization process before the
release of the data, an audit should be conducted, using these initial
results, to check that these relationships are maintained in the
anonymized dataset (see Step 11).

In our dataset, we identify several relationships between variables that
need to be preserved during the anonymization process. The variables
“TANHHEXP” and “INCTOTGROSSHH” represent the total annual nominal
household expenditure and the total gross annual household income,
respectively, and these variables are aggregations of existing income
and expenditure components in the dataset.

The variables related to education are available only for individuals in
the appropriate age groups and missing for other individuals. In
addition, the household-level variables (cf. fourth column of \hyperref[\detokenize{casestudies:tab918}]{Table \ref{\detokenize{casestudies:tab918}}})
have the same values for all members in any particular household.
The value of household size corresponds to the actual number of
individuals belonging to that household in the dataset. As we proceed,
we have to take care that these relationships and structures are
preserved in the anonymization process.

We assume that the data are collected in a survey that uses simple
sampling of households. The data contains two weight coefficients:
“WGTHH” and “WGTPOP”. The relationship between the weights is
\(WGTPOP = WGTHH * HHSIZE\). “WGTPOP” is the sampling weight
for the households and “WGTHH” is the sampling weight for the
individuals to be used for disclosure risk calculations. “WGTHH” is used
for computing individual-level indicators (such as education) and
“WGTPOP” is used for population level indicators (such as income
indicators). There are no strata variables available in the data. We
will use “WGTPOP” for the anonymization of the household variables and
“WGTHH” for the anonymization of the individual-level variables.


\subsection{Step 3: Type of release}
\label{\detokenize{casestudies:id8}}
In this case study, we assume that the file will be released as a PUF,
which will be freely available to anyone interested in the data (see
the Section \sphinxhref{release\_types.html\#ConditionsforPUFs}{Conditions for PUFs}
for the conditions and more information on the release of
PUFs). The PUF release is intended for users with lower information
requirements (e.g., students) and researchers interested in the
structure of the data and willing to do preliminary research. The PUF
file can give an idea to the researcher whether it is worthwhile for
their research to apply for access to the SUF file. Researchers willing
to do more in-depth research will most likely apply for SUF access.
Generally, users of a PUF file are not restricted by an agreement that
prevents them from using the data to re-identify individuals and hence
the accepted risk level is much lower than in the case of the SUF and
the set of released variables is limited.


\subsection{Step 4: Intruder scenarios and choice of key variables}
\label{\detokenize{casestudies:id9}}
Next, based on the release type, we reformulate the intruder scenarios
for the PUF release. This leads to the selection of a set of
quasi-identifiers. Since this case study is based on a demo dataset, we
do not have a real context and we cannot define exact disclosure
scenarios. Therefore, we make hypothetical assumptions on possible
disclosure scenarios. We consider two types of disclosure scenarios: 1)
matching with other publically available datasets and 2) spontaneous
recognition. Since the dataset will be distributed as PUF, there are de
facto no restrictions on the use of the dataset by intruders.

For the sake of illustration, we assume that population registers are
available with the demographic variables gender, age, place of residence
(region, urban/rural), religion and other variables such as marital
status and variables relating to education and professional status that
are also present in our dataset. In addition, we assume that there is a
publically available cadastral register on land ownership. Based on this
analysis of available data sources, we have selected in case study 1 the
variables “REGION”, “URBRUR”, “HHSIZE”, “OWNAGLAND”, “RELIG”, “GENDER”,
“REL” (relationship to household head), “MARITAL” (marital status),
“AGEYRS”, “INDUSTRY1” and two variables relating to school attendance as
categorical quasi-identifiers, the expenditure and income variables as
well as LANDSIZEHA as continuous quasi-identifiers. According to our
assessment, these variables might enable an intruder to re-identify an
individual or household in the dataset by matching with other available
datasets. The key variables for PUF release generally coincide with the
key variables for the SUF release. Possibly, more variables could be
added, since the user has more possibilities to match the data
extensively and is not bound by any contract, as is in the case of the
SUF file. Equally, some key variables in the SUF file may not be
released in the PUF file and, as a consequence, these variables are
removed from the list of key variables.

Upon further consideration, this initial set of identifying variables is
too large for a PUF release, as the number of possible combinations
(keys) is very high and hence many respondents could be identified based
on these variables. Therefore, we decide to limit the set of key
variables, by excluding variables from the dataset for PUF release. The
choice of variables to be removed is led by the needs of the intended
PUF users. Assuming the typical users are mainly interested in aggregate
income and expenditure data, we can therefore remove from the initial
set of key variables “OWNAGLAND”, “RELIG” and “LANDSIZEHA” at the
household level and “EDYRSCURRAT” and “ATSCHOOL” at the individual
level.

\begin{sphinxadmonition}{note}{Note:}
These variables will not be released in the PUF file.
\end{sphinxadmonition}

We also remove the income and expenditure components from the list of
key variables, since we reduce their information content by building
proportions (see Step 8a). The list of the remaining key variables is
presented in \hyperref[\detokenize{casestudies:tab919}]{Table \ref{\detokenize{casestudies:tab919}}}.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Overview of selected key variables for PUF file}\label{\detokenize{casestudies:tab919}}\label{\detokenize{casestudies:id40}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
Variable name
&\sphinxstyletheadfamily 
Variable description
&\sphinxstyletheadfamily 
Measurement level
\\
\hline
REGION
&
region
&
Household,
categorical
\\
\hline
URBRUR
&
area of residence
&
Household,
categorical
\\
\hline
HHSIZE
&
household size
&
Household,
categorical
\\
\hline
TANHHEXP
&
total expenditure
&
Household, continuous
\\
\hline
INCTOTGROSSHH
&
total income
&
Household, continuous
\\
\hline
GENDER
&
gender
&
Individual,
categorical
\\
\hline
REL
&
relationship to
household head
&
Individual,
categorical
\\
\hline
MARITAL
&
marital status
&
Individual,
categorical
\\
\hline
AGEYRS
&
age in completed
years
&
Individual,
semi-continuous/categorical
\\
\hline
EDUCY
&
highest level of
education completed
&
Individual,
categorical
\\
\hline
INDUSTRY1
&
industry
classification
&
Individual,
categorical
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The decision to release the dataset as a PUF means the level of
anonymization will be relatively high and consequently, the variables
are less detailed (e.g., after recoding) and a scenario of spontaneous
recognition is less likely. Nevertheless, we should check for rare
combinations or unusual patterns in the variables. Variables that may
lead to spontaneous recognition in our sample are amongst others
“HHSIZE” (household size) as well as “INCTOTGROSSHH” (aggregate income)
and “TANHHEXP” (total expenditure). Large households and households with
high income are easily identifiable, especially when combined with other
identifying variables such as a geographical identifier (“REGION”).
There might be only one or a few households/individuals in a certain
region with a high income, such as the local doctor. Variables that are
easily observable and known by neighbors such as “ROOF”, “TOILET”,
“WATER”, “ELECTCON”, “FUELCOOK”, “OWNMOTORCYCLE”, “CAR”, “TV” and
“LIVESTOCK” may also need protection depending on what stands out in the
community, since a user might be able to identify persons (s)he knows.
This is called the nosy-neighbor scenario.


\subsection{Step 5: Data key uses and selection of utility measures}
\label{\detokenize{casestudies:id10}}
A PUF file contains less information and the file is generally used by
students as a teaching file, by researchers to get an idea about the
data structure, and for simple analyses. The users have generally lower
requirements than for a SUF file and the results of analysis may be less
precise. The researcher interested in a more detailed dataset, would
have to apply for access to the SUF file. Therefore, we select more
aggregate utility measures for the PUF file that reflect the intended
use of a PUF file. Data intensive measures, such as the Gini
coefficient, cannot be computed from the PUF file. Besides the standard
utility measures, such as tabulations, we evaluate the decile dispersion
ratio and a regression with the income deciles as regressand.

To measure the information loss, we should compare the initial data file
before any anonymization (including the anonymization for the SUF) with
the file after the anonymization for the PUF. Comparing the files
directly before and after the PUF anonymization would underestimate the
information loss, as this would omit the information loss due to SUF
anonymization. Therefore, in Step 2, we also loaded the raw dataset.

\sphinxstylestrong{Hierarchical (household) structure}

As noted in case study 1, the data has a household structure. For the
SUF release, we protected large households by removing these from the
dataset. Since some variables are measured on the household level and
thus have identical values for each household member, the values of the
household variables should be treated in the same way for each household
member (see the Section
\sphinxhref{anon\_methods.html\#Anonymizationofthequasi-identifierhouseholdsize}{Anonymization of the quasi-identifier household size}
). Therefore, we first anonymize only the
household variables. After this, we merge them with the individual-level
variables and then anonymize the individual-level and household-level
variables jointly.

Since the data has a hierarchical structure, Steps 6 through 10 are
repeated twice: Steps 6a through 10a are for the household-level
variables and Steps 6b through 10b for the combined dataset. In this
way, we ensure that household-level variable values remain consistent
across household members for each household and the household structure
cannot be used to re-identify individuals. This is further explained in
the Sections \sphinxhref{measure\_risk.html\#Levelsofrisk}{Levels of risk}
and \sphinxhref{sdcMicro.html\#Householdstructure}{Household structure}.

Before continuing to Step 6a, we select the categorical key variables,
continuous key variables and any variables selected for use in PRAM
routines, as well as household-level sampling weights in \sphinxstyleemphasis{R}. We also
collect the variable names of the variables that will not be released.
The PRAM variables are variables select for the PRAM routine, which we
discuss further in Step 8a. We extract these selected household
variables from the SUF dataset and save them as “fileHH”. The choice of
PRAM variables is further explained in Step 8a. \hyperref[\detokenize{casestudies:code929}]{Listing \ref{\detokenize{casestudies:code929}}} illustrates
how these steps are done in \sphinxstyleemphasis{R} (see also the Section
\sphinxhref{sdcMicro.html\#Householdstructure}{Household structure}).

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code929}}}
\sphinxSetupCaptionForVerbatim{Selecting the variables for the household-level anonymization}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Categorical key variables at household level}
selectedKeyVarsHH \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{URBRUR\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{REGION\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{HHSIZE\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Continuous key variables}
numVarsHH \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TANHHEXP\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} PRAM variables}
pramVarsHH \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{ROOF\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TOILET\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{WATER\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{ELECTCON\PYGZsq{}}\PYG{p}{,}
                \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{FUELCOOK\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{OWNMOTORCYCLE\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{CAR\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TV\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{LIVESTOCK\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Household weight}
weightVarHH \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{WGTPOP\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Variables not suitable for release in PUF (HH level)}
varsNotToBeReleasedHH \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{OWNAGLAND\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{RELIG\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{LANDSIZEHA\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Vector with names of all HH level variables}
HHVars \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IDH\PYGZsq{}}\PYG{p}{,} selectedKeyVarsHH\PYG{p}{,} pramVarsHH\PYG{p}{,} numVarsHH\PYG{p}{,} weightVarHH\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Create subset of file with only HH level variables}
fileHH \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{file}\PYG{p}{[}\PYG{p}{,}HHVars\PYG{p}{]}
\end{sphinxVerbatim}

Every household has the same number of entries as it has members (e.g.,
a household of three will be repeated three times in “fileHH”). Before
analyzing the household-level variables, we select only one entry per
household, as illustrated in \hyperref[\detokenize{casestudies:code930}]{Listing \ref{\detokenize{casestudies:code930}}}. This is further explained in
the Section \sphinxhref{sdcMicro.html\#Householdstructure}{Household structure}.
In the same way we extract “fileOrigHH” from “fileOrig”.
“fileOrigHH” contains all variables from the raw data, but contains
every household only once. We need “fileOrigHH” in Steps 8a and 10a for
undoing some perturbative methods used in the SUF file and computing
utility measures from the raw data respectively.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code930}}}
\sphinxSetupCaptionForVerbatim{Taking a subset with only households}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Remove duplicated rows based on IDH, one row per household in fileHH}
fileHH \PYG{o}{\PYGZlt{}\PYGZhy{}} fileHH\PYG{p}{[}\PYG{k+kp}{which}\PYG{p}{(}\PYG{o}{!}\PYG{k+kp}{duplicated}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} SUF file}
fileOrigHH \PYG{o}{\PYGZlt{}\PYGZhy{}} fileOrig\PYG{p}{[}\PYG{k+kp}{which}\PYG{p}{(}\PYG{o}{!}\PYG{k+kp}{duplicated}\PYG{p}{(}fileOrig\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{)}\PYG{p}{,}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} original dataset}

\PYG{c+c1}{\PYGZsh{} Dimensions of fileHH}
\PYG{k+kp}{dim}\PYG{p}{(}fileHH\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 1970   16}

\PYG{k+kp}{dim}\PYG{p}{(}fileOrigHH\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 2000   68}
\end{sphinxVerbatim}

The file “fileHH” contains 1,970 households and 16 variables. We are now
ready to create our \sphinxstyleemphasis{sdcMicro} object with the corresponding variables
we selected in \hyperref[\detokenize{casestudies:code928}]{Listing \ref{\detokenize{casestudies:code928}}}. For our case study, we will create an
\sphinxstyleemphasis{sdcMicro} object called “sdcHH” based on the data in “fileHH”, which we
will use for steps 6a \textendash{} 10a (see \hyperref[\detokenize{casestudies:code934}]{Listing \ref{\detokenize{casestudies:code934}}}).

\begin{sphinxadmonition}{note}{Note:}
When the sdcMicro object is created, the sdcMicro package automatically
calculates and stores the risk measures for the data.
\end{sphinxadmonition}

This leads us to Step 6a.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code931}}}
\sphinxSetupCaptionForVerbatim{Creating a \sphinxstyleemphasis{sdcMicro} object for the household variables}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Create initial sdcMicro object for household level variables}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} createSdcObj\PYG{p}{(}dat \PYG{o}{=} fileHH\PYG{p}{,} keyVars \PYG{o}{=} selectedKeyVarsHH\PYG{p}{,}
                      pramVars \PYG{o}{=} pramVarsHH\PYG{p}{,} weightVar \PYG{o}{=} weightVarHH\PYG{p}{,} numVars \PYG{o}{=} numVarsHH\PYG{p}{)}
numHH \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{length}\PYG{p}{(}fileHH\PYG{p}{[}\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} number of households}
\end{sphinxVerbatim}


\subsection{Step 6a: Assessing disclosure risk (household level)}
\label{\detokenize{casestudies:id11}}
Based on the key variables selected in the disclosure scenarios, we can
evaluate the risk at the household level. The PUF risk measures show a
lower risk level than in the SUF file after anonymization in case study
1. The reason is that the set of key variables is smaller, since some
variables will not be released in the PUF file. Removing (key) variables
reduces the risk, and it is one of the most straightforward SDC methods.

As a first measure, we evaluate the number of households violating
\(k\)-anonymity at the levels 2, 3 and 5. \hyperref[\detokenize{casestudies:tab920}]{Table \ref{\detokenize{casestudies:tab920}}} shows the
number of violating households as well as the percentage of the total
number of households. \hyperref[\detokenize{casestudies:code932}]{Listing \ref{\detokenize{casestudies:code932}}} illustrates how to find these values
with \sphinxstyleemphasis{sdcMicro}. The print() function in \sphinxstyleemphasis{sdcMicro} shows only the
values for thresholds 2 and 3. Values for other thresholds can be
calculated manually by summing up the frequencies smaller than the
\(k\)-anonymity threshold, as shown in \hyperref[\detokenize{casestudies:code932}]{Listing \ref{\detokenize{casestudies:code932}}}. The number of
violators is already at a low level, due to the prior anonymization of
the SUF file and the reduced set of key variables.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Number and proportion of households violating \(k\)-anonymity}\label{\detokenize{casestudies:tab920}}\label{\detokenize{casestudies:id41}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
k-anonymity level
&\sphinxstyletheadfamily 
Number of HH violating
&\sphinxstyletheadfamily 
Percentage of total number of HH
\\
\hline
2
&
0
&
0.0\%
\\
\hline
3
&
18
&
0.9\%
\\
\hline
5
&
92
&
4.7\%
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code932}}}
\sphinxSetupCaptionForVerbatim{Showing number of households violating \(k\)-anonymity for levels 2, 3 and 5}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Number of observations violating k\PYGZhy{}anonymity (thresholds 2 and 3)}
\PYG{k+kp}{print}\PYG{p}{(}sdcHH\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Infos on 2/3\PYGZhy{}Anonymity:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Number of observations violating}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 2\PYGZhy{}anonymity: 0}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 3\PYGZhy{}anonymity: 18}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Percentage of observations violating}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 2\PYGZhy{}anonymity: 0.000 \PYGZpc{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 3\PYGZhy{}anonymity: 0.914 \PYGZpc{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}

\PYG{c+c1}{\PYGZsh{} Calculate sample frequencies and count number of obs. violating k(5) \PYGZhy{} anonymity}
kAnon5 \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{sum}\PYG{p}{(}sdcHH\PYG{o}{@}risk\PYG{o}{\PYGZdl{}}individual\PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{o}{\PYGZlt{}} \PYG{l+m}{5}\PYG{p}{)}
kAnon5
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 92}

\PYG{c+c1}{\PYGZsh{} As percentage of total}
kAnon5 \PYG{o}{/} numHH
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 0.04670051}
\end{sphinxVerbatim}

It is often useful to view the records of the household(s) that violate
\(k\)-anonymity. This might help to find which variables cause the
uniqueness of these households; this can then be used later when
choosing appropriate SDC methods. \hyperref[\detokenize{casestudies:code932}]{Listing \ref{\detokenize{casestudies:code932}}} shows how to access the
values of the households violating 3 and 5-anonymity. Not surprisingly,
the variable “HHSIZE” is responsible for many of the unique combinations
and the origin of much of the risk. This is even the case after removing
large households for the SUF release.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code933}}}
\sphinxSetupCaptionForVerbatim{Showing records of households that violate \(k\)-anonymity}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Show values of key variable of records that violate k\PYGZhy{}anonymity}
fileHH\PYG{p}{[}sdcHH\PYG{o}{@}risk\PYG{o}{\PYGZdl{}}individual\PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{o}{\PYGZlt{}} \PYG{l+m}{3}\PYG{p}{,} selectedKeyVarsHH\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} for 3\PYGZhy{}anonymity}
fileHH\PYG{p}{[}sdcHH\PYG{o}{@}risk\PYG{o}{\PYGZdl{}}individual\PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{o}{\PYGZlt{}} \PYG{l+m}{5}\PYG{p}{,} selectedKeyVarsHH\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} for 5\PYGZhy{}anonymity}
\end{sphinxVerbatim}

We also assess the disclosure risk of the categorical variables with the
individual and global risk measures as described in the Sections
\sphinxhref{measure\_risk.html\#Individualrisk}{Individual risk}
and \sphinxhref{measure\_risk.html\#Globalrisk}{Global risk}.
In “fileHH” every entry represents a household. Therefore, we use
the individual non-hierarchical risk here, where the individual refers
in this case to a household. “fileHH” is a subset of the complete
dataset and contains only households and has, contrary to the complete
dataset, no hierarchical structure. In Step 6b, we evaluate the
hierarchical risk in the dataset “file”, the dataset containing both
households and individuals. The individual and global risk measures
automatically take into consideration the household weights, which we
defined in \hyperref[\detokenize{casestudies:code929}]{Listing \ref{\detokenize{casestudies:code929}}}. In our file, the global risk measure calculated
using the chosen key variables is lower than 0.01\% (the smallest
reported value is 0.01\%, in fact the global risk is 0.0000642 \%). This
percentage is extremely low and corresponds to 0.13 expected
re-identifications. The results are also shown in \hyperref[\detokenize{casestudies:code934}]{Listing \ref{\detokenize{casestudies:code934}}}. This low
figure can be explained by the relatively small sample size of 0.25\% of
the total population (see case study 1). Furthermore, one should keep in
mind that this risk measure is based only on the categorical
quasi-identifiers at the household level.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code934}}}
\sphinxSetupCaptionForVerbatim{Printing global risk measures}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{k+kp}{print}\PYG{p}{(}sdcHH\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{risk\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Risk measures:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Number of observations with higher risk than the main part of the data: 0}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Expected number of re\PYGZhy{}identifications: 0.13 (0.01 \PYGZpc{})}
\end{sphinxVerbatim}

The global risk measure does not provide information about the spread of
the individual risk measures. There might be a few households with
relatively high risk, while the global (average) risk is low. Therefore
we check the highest individual risk as shown in \hyperref[\detokenize{casestudies:code935}]{Listing \ref{\detokenize{casestudies:code935}}}. The
individual risk of the household with the highest risk is 0.1 \%, which
is still very low.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code935}}}
\sphinxSetupCaptionForVerbatim{Determining the highest individual risk}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Highest individual risk}
\PYG{k+kp}{max}\PYG{p}{(}sdcHH\PYG{o}{@}risk\PYG{o}{\PYGZdl{}}individual\PYG{p}{[}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{risk\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 0.001011633}
\end{sphinxVerbatim}

Since the selected key variables at the household level are both
categorical and numerical, the individual and global risk measures based
on frequency counts do not completely reflect the disclosure risk of the
entire dataset. When generating the SUF file, we concluded that recoding
of continuous variables to make them all categorical would likely not
satisfy the needs of the SUF users. For the PUF file it is acceptable to
recode continuous variables, such as income and expenditures since PUF
content is typically less detailed. In Step 8a we will recode these
variables into deciles and convert them into categorical variables.
Therefore, we exclude these variables from the risk calculations now We
take these variables into account while remeasuring risk after
anonymization.


\subsection{Step 7a: Assessing utility measures (household level)}
\label{\detokenize{casestudies:id12}}
The utility of the data does not only depend on the household level
variables, but on the combination of household-level and
individual-level variables. Therefore, it is not useful to evaluate all
the utility measures selected in Step 5 at this stage, i.e., before
anonymizing the individual level variables. We restrict the initial
measurement of utility to those measures that are solely based on the
household variables. In our dataset, these are the measures related to
income and expenditure and their distributions. The results are
presented in Step 10a, together with the results after anonymization,
which allow direct comparison. If after the next anonymization step it
appears that the data utility has been significantly decreased by the
suppression of some household level variables, we can return to this
step.

\begin{sphinxadmonition}{note}{Note:}
To analyze the utility loss, the utility measures before
anonymization have to be calculated from the raw data and not from the
anonymized SUF file.
\end{sphinxadmonition}

Not all measures from case study 1 can be
computed from the PUF file, since the information content is lower. The
set of utility measures we use to evaluate the information loss in the
PUF file consists of measures that need less detailed variables. This
reflects the lower requirements a PUF user has on the dataset.


\subsection{Step 8a: Choice and application of SDC methods (household level)}
\label{\detokenize{casestudies:step-8a-choice-and-application-of-sdc-methods-household-level}}
This step is divided into the anonymization of the categorical key
variables and the continuous key variables, since different methods are
used for both sets of variables. As already discussed in Step 4, we do
not release all variables in the PUF file. At the household level
“RELIG” (religion of household head), “OWNAGLAND” (land ownership) and
“LANDSIZEHA” (plot size in ha) are not released in addition to the
variables removed for the SUF release. For the sake of illustration, we
assume that the variable “RELIG” is too sensitive and the variables
“OWNAGLAND” and “LANDSIZEHA” are too identifying.

\sphinxstylestrong{Categorical variables}

We are now ready to move on to the choice of SDC methods for the
categorical variables on the household level in our dataset. In the SUF
file we already recoded some of the key variables and used local
suppression. We only have three categorical key variables at the
household level; “URBRUR”, “REGION” and “HHSIZE”. The selected
categorical key variables at the household level are not suitable for
recoding at this point, since the values cannot be grouped further.
“URBRUR” has only two distinct categories and “REGION” has only six
non-combinable regions. As noted before, the variable “HHSIZE” can be
reconstructed by a headcount per household. Therefore, recoding of this
variable alone does not lead to disclosure control.

Due to the relatively low risk of re-identification based on the three
selected categorical household level variables, it is possible in this
case to use an option like local suppression to achieve our desired
level of risk. Applying local suppression when initial risk is
relatively low will likely only lead to suppression of few observations
and thus limit the loss of utility. If, however, the data had been
measured to have a relatively high risk, then applying local suppression
without previous recoding would likely result in a large number of
suppressions and greater information loss. Efforts such a recoding
should be taken first before suppressing values in cases where risk is
initially measured as high. Recoding will reduce risk with little
information loss and thus the number of suppressions, if local
suppression is applied as an additional step.

We apply local suppression to reach 5-anonymity. The chosen level of
five is higher than in the SUF release and is based on the release type
as PUF. This leads to a total of 39 suppressions, all in the variable
“HHSIZE”. As explained earlier, suppression of the value of the variable
“HHSIZE” does not lead to actual suppression of this information.
Therefore, we redo the local suppression, but this time we tell
\sphinxstyleemphasis{sdcMicro} to, if possible, not suppress “HHSIZE” but one of the other
variables. Alternatively, we could remove households with suppressed
values of the variable “HHSIZE”, remove large households or split
households.

In \sphinxstyleemphasis{sdcMicro} it is possible to tell the algorithm which variables are
important and less important for making small changes (see also the Section
\sphinxhref{anon\_methods.html\#Localsuppression}{Local suppression}).
To prevent values of the variable “HHSIZE” being suppressed, we
set the importance of “HHSIZE” in the importance vectors to the highest
(i.e., 1). We try two different importance vectors: the first where
“REGION” is more important than “URBRUR” and the second with the
importance of “REGION” and “URBRUR” swapped. \hyperref[\detokenize{casestudies:code936}]{Listing \ref{\detokenize{casestudies:code936}}} shows how to
apply local suppression and put importance on the variable “HHSIZE”.

\begin{sphinxadmonition}{note}{Note:}
In \hyperref[\detokenize{casestudies:code936}]{Listing \ref{\detokenize{casestudies:code936}}} we use the undolast() function in sdcMicro
to go one step back after we had first applied local suppression with no
importance vector.
\end{sphinxadmonition}

The undolast() function restores the \sphinxstyleemphasis{sdcMicro}
object back to the previous state (i.e., before we applied local
suppression), which allows us to rerun the same command, but this time
with an importance vector set. The undolast() function can only be used
to go one step back.

The suppression patterns of the three different options are shown in
\hyperref[\detokenize{casestudies:tab921}]{Table \ref{\detokenize{casestudies:tab921}}}. The importance is clearly reflected in the number of
suppressions per variable. The total number of suppressions is with an
importance vector higher than without an importance vector (44/73 vs.
39), but 5-anonymity is achieved in the dataset with no suppressions in
the variable “HHSIZE”. This means that we do not have to remove or split
households. The variable “REGION” is the type of variable that should
not have any suppressions either. From that perspective we chose the
third option. This leads to more suppressions, but no suppressions in
“HHSIZE” and as few as possible in “REGION”.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Number of suppressions by variable after local suppression with and without importance vector}\label{\detokenize{casestudies:tab921}}\label{\detokenize{casestudies:id42}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
Key variable
&\sphinxstartmulticolumn{3}%
\begin{varwidth}[t]{\sphinxcolwidth{3}{4}}
\sphinxstyletheadfamily Number of suppressions and proportion of total
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstyletheadfamily 
.
&\sphinxstyletheadfamily 
No importance vector
&\sphinxstyletheadfamily 
Importance HHSIZE, URBRUR, REGION
&\sphinxstyletheadfamily 
Importance HHSIZE, REGION, URBRUR
\\
\hline
URBRUR
&
0 (0.0 \%)
&
2 (0.1 \%)
&
61 (3.1 \%)
\\
\hline
REGION
&
0 (0.0 \%)
&
42 (2.1 \%)
&
12 (0.6 \%)
\\
\hline
HHSIZE
&
39 (2.0 \%)
&
0 (0.0 \%)
&
0 (0.0 \%)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code936}}}
\sphinxSetupCaptionForVerbatim{Local suppression with and without importance vector}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Local suppression to achieve 5\PYGZhy{}anonimity}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} localSuppression\PYG{p}{(}sdcHH\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{5}\PYG{p}{,} importance \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} no importance vector}
\PYG{k+kp}{print}\PYG{p}{(}sdcHH\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Local Suppression:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  KeyVar \textbar{} Suppressions (\PYGZsh{}) \textbar{} Suppressions (\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  URBRUR \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  REGION \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  HHSIZE \textbar{}               39 \textbar{}            1.980}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}

\PYG{c+c1}{\PYGZsh{} Undo suppressions to see the effect of an importance vector}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} undolast\PYG{p}{(}sdcHH\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Redo local suppression minimizing the number of suppressions in HHSIZE}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} localSuppression\PYG{p}{(}sdcHH\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{5}\PYG{p}{,} importance \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{3}\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{)}\PYG{p}{)}

\PYG{k+kp}{print}\PYG{p}{(}sdcHH\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Local Suppression:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  KeyVar \textbar{} Suppressions (\PYGZsh{}) \textbar{} Suppressions (\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  URBRUR \textbar{}                2 \textbar{}            0.102}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  REGION \textbar{}               42 \textbar{}            2.132}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  HHSIZE \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}

\PYG{c+c1}{\PYGZsh{} Undo suppressions to see the effect of a different importance vector}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} undolast\PYG{p}{(}sdcHH\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Redo local suppression minimizing the number of suppressions in HHSIZE}
sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} localSuppression\PYG{o}{*}\PYG{p}{(}sdcHH\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{5}\PYG{p}{,} importance \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+m}{3}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{)}\PYG{p}{)}

\PYG{k+kp}{print}\PYG{p}{(}sdcHH\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Local Suppression:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  KeyVar \textbar{} Suppressions (\PYGZsh{}) \textbar{} Suppressions (\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  URBRUR \textbar{}               61 \textbar{}            3.096}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  REGION \textbar{}               12 \textbar{}            0.609}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  HHSIZE \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\end{sphinxVerbatim}

In case study 1 we applied invariant PRAM to the variables “ROOF”,
“TOILET”, “WATER”, “ELECTCON”, “FUELCOOK”, “OWNMOTORCYCLE”, “CAR”, “TV”
and “LIVESTOCK”, since these variables are not sensitive and were not
selected as quasi-identifiers because we assumed that there are no
external data sources containing this information that could be used for
matching. Values can be easily observed or be known to neighbors,
however, and therefore are important, together with other variables, for
the nosy neighbor scenario. For the PUF release we would like to level
of uncertainty by increasing the number of changes. Therefore, we redo
PRAM with a different transition matrix. As discussed in the Section
\sphinxhref{anon\_methods.html\#PRAM(PostRAndomizationMethod)}{PRAM (Post RAndomization Method)},
the invariant PRAM method has the property that the univariate
distributions do not change. To maintain this property, we reapply PRAM
to the raw data, rather than to the already PRAMmed variables in the SUF
file.

\hyperref[\detokenize{casestudies:code937}]{Listing \ref{\detokenize{casestudies:code937}}} illustrates how to apply PRAM. We use the original values
to apply PRAM and replace the values in the \sphinxstyleemphasis{sdcMicro} object with these
values. We choose the parameter ‘pd’, the lower bound for the
probability that a value is not changed, to be relatively low at 0.6.
This is a lower value than the 0.8 used in the SUF file and will lead to
a higher number of changes (cf. \hyperref[\detokenize{casestudies:code917}]{Listing \ref{\detokenize{casestudies:code917}}}). This is
acceptable for a PUF file and introduces more uncertainty as required
for a PUF release. \hyperref[\detokenize{casestudies:code937}]{Listing \ref{\detokenize{casestudies:code937}}} also shows the number of changed records
per variables. Because PRAM is a probabilistic method, we set a seed for
the random number generator before applying PRAM to ensure
reproducibility of the results.

\begin{sphinxadmonition}{note}{Note:}
In some cases the choice of the seed matters. The choice of seed changes the results.
\end{sphinxadmonition}

The seed should not be released, since it allows for reconstructing the original values
if combined with the transition matrix. The transition matrix can be
released: this allows for consistent statistical inference by correcting
the statistical methods used if the researcher has knowledge about the
PRAM method (at this point \sphinxstyleemphasis{sdcMicro} does not allow to retrieve the
transition matrix).

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code937}}}
\sphinxSetupCaptionForVerbatim{Applying PRAM}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} PRAM}
\PYG{k+kp}{set.seed}\PYG{p}{(}\PYG{l+m}{10987}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Replace PRAM variables in sdcMicro object sdcHH with the original raw values}
sdcHH\PYG{o}{@}origData\PYG{p}{[}\PYG{p}{,}pramVarsHH\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} fileHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} pramVarsHH\PYG{p}{]}
sdcHH\PYG{o}{@}manipPramVars \PYG{o}{\PYGZlt{}\PYGZhy{}} fileHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} pramVarsHH\PYG{p}{]}

sdcHH \PYG{o}{\PYGZlt{}\PYGZhy{}} pram\PYG{p}{(}obj \PYG{o}{=} sdcHH\PYG{p}{,} pd \PYG{o}{=} \PYG{l+m}{0.6}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Number of changed observations:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{} \PYGZhy{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} ROOF != ROOF\PYGZus{}pram : 305 (15.48\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} TOILET != TOILET\PYGZus{}pram : 260 (13.2\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} WATER != WATER\PYGZus{}pram : 293 (14.87\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} ELECTCON != ELECTCON\PYGZus{}pram : 210 (10.66\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} FUELCOOK != FUELCOOK\PYGZus{}pram : 315 (15.99\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} OWNMOTORCYCLE != OWNMOTORCYCLE\PYGZus{}pram : 95 (4.82\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} CAR != CAR\PYGZus{}pram : 255 (12.94\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} TV != TV\PYGZus{}pram : 275 (13.96\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} LIVESTOCK != LIVESTOCK\PYGZus{}pram : 109 (5.53\PYGZpc{})}
\end{sphinxVerbatim}

PRAM has changed values within the variables according to the invariant
transition matrices. Since we used the invariant PRAM method (see
the Section \sphinxhref{anon\_methods.html\#PRAM(PostRAndomizationMethod)}{PRAM (Post RAndomization Method)}),
the absolute univariate frequencies remain approximately
unchanged. This is not the case for the multivariate frequencies. In
Step 10a we compare the multivariate frequencies before and after
anonymization for the PRAMmed variables.

\sphinxstylestrong{Continuous variables}

We have selected the variables “INCTOTGROSSHH” (total income) and
“TANHHEXP” (total expenditure) as numerical quasi-identifiers, as
discussed in Step 4. In Step 5 we identified variables having high
interest for the users of our data: many users use the data for
measuring inequality and expenditure patterns. The noise addition in the
SUF file does not protect these variables sufficiently, especially,
because outliers are not protected. Therefore, we decide to recode total
income and total expenditure into deciles.

As with PRAM, we want to compute the deciles from the raw data rather
than from the perturbed values in the SUF file. We compute the deciles
directly from the raw data and overwrite these values in the \sphinxstyleemphasis{sdcMicro}
object. Subsequently, we compute the mean of each decile from the raw
data and replace the values for total income and total expenditures with
the mean of the respective decile. In this way the mean of both
variables does not change. This approach can be interpreted as
univariate microaggregation with very large groups (group size n/10)
with the mean as replacement value (see the Section
\sphinxhref{anon\_methods.html\#Microaggregation}{Microaggregation}).

The information in the income and expenditure variables by component is
too sensitive to release as PUF, and, summing those variables would
allow an intruder to reconstruct the totals. PUF users might however be
interested in the shares. Therefore, we decide to keep the income and
expenditure components as proportions of the raw totals, rounded to two
digits. The anonymization of the income and expenditure variables is
shown in \hyperref[\detokenize{casestudies:code938}]{Listing \ref{\detokenize{casestudies:code938}}}.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code938}}}
\sphinxSetupCaptionForVerbatim{Anonymization of income and expenditure variables}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Create bands (deciles) for income and expenditure variables}
\PYG{p}{(}aggregates\PYG{p}{)} based on the original data
decExp \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{as.numeric}\PYG{p}{(}\PYG{k+kp}{cut}\PYG{p}{(}fileOrigHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TANHHEXP\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
                         quantile\PYG{p}{(}fileOrigHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TANHHEXP\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
                                  \PYG{p}{(}\PYG{l+m}{0}\PYG{o}{:}\PYG{l+m}{10}\PYG{p}{)}\PYG{o}{/}\PYG{l+m}{10}\PYG{p}{,} na.rm \PYG{o}{=} \PYG{n+nb+bp}{T}\PYG{p}{)}\PYG{p}{,}
                         include.lowest \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,} labels \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{3}\PYG{p}{,} \PYG{l+m}{4}\PYG{p}{,} \PYG{l+m}{5}\PYG{p}{,} \PYG{l+m}{6}\PYG{p}{,} \PYG{l+m}{7}\PYG{p}{,} \PYG{l+m}{8}\PYG{p}{,} \PYG{l+m}{9}\PYG{p}{,} \PYG{l+m}{10}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
 decInc \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{as.numeric}\PYG{p}{(}\PYG{k+kp}{cut}\PYG{p}{(}fileOrigHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
                          quantile\PYG{p}{(}fileOrigHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
                                   \PYG{p}{(}\PYG{l+m}{0}\PYG{o}{:}\PYG{l+m}{10}\PYG{p}{)}\PYG{o}{/}\PYG{l+m}{10}\PYG{p}{,} na.rm \PYG{o}{=} \PYG{n+nb+bp}{T}\PYG{p}{)}\PYG{p}{,}
                          include.lowest \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,} labels  \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{3}\PYG{p}{,} \PYG{l+m}{4}\PYG{p}{,} \PYG{l+m}{5}\PYG{p}{,} \PYG{l+m}{6}\PYG{p}{,} \PYG{l+m}{7}\PYG{p}{,} \PYG{l+m}{8}\PYG{p}{,} \PYG{l+m}{9}\PYG{p}{,} \PYG{l+m}{10}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Mean values of deciles}
decExpMean \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{round}\PYG{p}{(}\PYG{k+kp}{sapply}\PYG{p}{(}\PYG{k+kp}{split}\PYG{p}{(}fileOrigHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TANHHEXP\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
                                 decExp\PYG{p}{)}\PYG{p}{,} \PYG{k+kp}{mean}\PYG{p}{)}\PYG{p}{)}
decIncMean \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{round}\PYG{p}{(}\PYG{k+kp}{sapply}\PYG{p}{(}\PYG{k+kp}{split}\PYG{p}{(}fileOrigHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
                                decInc\PYG{p}{)}\PYG{p}{,} \PYG{k+kp}{mean}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Replace with mean value of decile}
sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}TANHHEXP \PYG{o}{\PYGZlt{}\PYGZhy{}} decExpMean\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}decExp\PYG{p}{,}\PYG{k+kp}{names}\PYG{p}{(}decExpMean\PYG{p}{)}\PYG{p}{)}\PYG{p}{]}
sdcHH\PYG{o}{@}manipNumVars\PYG{o}{\PYGZdl{}}INCTOTGROSSHH \PYG{o}{\PYGZlt{}\PYGZhy{}} decIncMean\PYG{p}{[}\PYGZbs{} \PYG{k+kp}{match}\PYG{p}{(}decInc\PYG{p}{,} \PYG{k+kp}{names}\PYG{p}{(}decIncMean\PYG{p}{)}\PYG{p}{)}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Recalculate risks after manually changing values in sdcMicro object calcRisks(sdcHH)}
calcRisks\PYG{p}{(}sdcHH\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Extract data from sdcHH}
HHmanip \PYG{o}{\PYGZlt{}\PYGZhy{}} extractManipData\PYG{p}{(}sdcHH\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} manipulated variables HH}

\PYG{c+c1}{\PYGZsh{} Keep components of expenditure and income as share of total,}
\PYG{c+c1}{\PYGZsh{} use original data since previous data was perturbed}
compExp \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TFOODEXP\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TALCHEXP\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TCLTHEXP\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{THOUSEXP\PYGZsq{}}\PYG{p}{,}
             \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TFURNEXP\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{THLTHEXP\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TTRANSEXP\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TCOMMEXP\PYGZsq{}}\PYG{p}{,}
             \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TRECEXP\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TEDUEXP\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TRESTHOTEXP\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{TMISCEXP\PYGZsq{}}\PYG{p}{)}
compInc \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCRMT\PYGZsq{}}\PYG{p}{,}  \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCWAGE\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCFARMBSN\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCNFARMBSN\PYGZsq{}}\PYG{p}{,}
             \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCRENT\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCFIN\PYGZsq{}}\PYG{p}{,}  \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCPENSN\PYGZsq{}}\PYG{p}{,}   \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INCOTHER\PYGZsq{}}\PYG{p}{)}
HHmanip \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{cbind}\PYG{p}{(}HHmanip\PYG{p}{,} \PYG{k+kp}{round}\PYG{p}{(}fileOrigHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} compExp\PYG{p}{]} \PYG{o}{/}
                                fileOrigHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,}
                                           \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TANHHEXP\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{)}\PYG{p}{)}
HHmanip \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{cbind}\PYG{p}{(}HHmanip\PYG{p}{,} \PYG{k+kp}{round}\PYG{p}{(}fileOrigHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} compInc\PYG{p}{]} \PYG{o}{/}
                                fileOrigHH\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}fileHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{,} fileOrigHH\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,}
                                           \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Step 9a: Re-measure risk (household level)}
\label{\detokenize{casestudies:step-9a-re-measure-risk-household-level}}
For the categorical variables, we conclude that we have achieved
5-anonymity in the data with local suppression. 5-anonymity also implies
2- and 3-anonymity. The global risk stayed close to zero (as the
expected number of re-identifications), which is very low. Therefore, we
conclude that based on the categorical variables, the data has been
sufficiently anonymized. One should keep in mind that the anonymization
methods applied are complementing the ones used for the SUF.

\begin{sphinxadmonition}{note}{Note:}
The methods selected methods in this case study alone would not be
sufficient to protect the data set for a PUF release.
\end{sphinxadmonition}

We have reduced the risk of spontaneous recognition of households, by
removing the variable “LANDSIZEHA” and PRAMming the variables identified
to be important in the nosy neighbor scenario. An intruder cannot know
with certainty whether a household that (s)he recognizes in the data is
the correct household, due to the noise in these variables.

These measures refer only to the categorical variables. To evaluate the
risk of the continuous variables we could use an interval measure or
closest neighbor algorithm. These risk measures are discussed in the Section
\sphinxhref{measure\_risk.html\#Riskmeasuresforcontinuousvariables}{Risk measures for continuous variables}.
We chose to use an interval measure, since exact value matching is
not our largest concern based on the assumed scenarios and external data
sources. Instead, datasets with similar values but not the exact same
values could be used for matching. Here the main concern is that the
values are sufficiently far from the original values, which is measured
with an interval measure.

\hyperref[\detokenize{casestudies:code939}]{Listing \ref{\detokenize{casestudies:code939}}} shows how to evaluate the interval measure for the
variables “INCTOTGROSSHH” and “TANHHEXP” (total income and expenditure).
The different values of the parameter \(k\) in the function dRisk()
define the size of the interval around the original value as a function
of the standard deviation, as explained in the Section
\sphinxhref{measure\_risk.html\#Intervalmeasure}{Interval measure} . The larger
\(k\), the larger the intervals, the higher the probability that a
perturbed value is in the interval around the original value and the
higher the risk measure. The results are satisfactory, especially when
keeping in mind that there are only 10 distinct values in the dataset
(the means of each of the deciles). All outliers have been recoded.
Looking at the proportions of the components, we do not detect any
outliers (households with an unusual high or low spending pattern in one
component).

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code939}}}
\sphinxSetupCaptionForVerbatim{Measuring risk of re-identification of continuous variables}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Risk evaluation continuous variables}
dRisk\PYG{p}{(}sdcHH\PYG{o}{@}origData\PYG{p}{[}\PYG{p}{,}\PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TANHHEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
      xm \PYG{o}{=} sdcHH\PYG{o}{@}manipNumVars\PYG{p}{[}\PYG{p}{,}\PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TANHHEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{0.01}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 0.4619289}

dRisk\PYG{p}{(}sdcHH\PYG{o}{@}origData\PYG{p}{[}\PYG{p}{,}\PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TANHHEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
      xm \PYG{o}{=} sdcHH\PYG{o}{@}manipNumVars\PYG{p}{[}\PYG{p}{,}\PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TANHHEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{0.02}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 0.642132}

dRisk\PYG{p}{(}sdcHH\PYG{o}{@}origData\PYG{p}{[}\PYG{p}{,}\PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TANHHEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,}
      xm \PYG{o}{=} sdcHH\PYG{o}{@}manipNumVars\PYG{p}{[}\PYG{p}{,}\PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{TANHHEXP\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INCTOTGROSSHH\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{0.05}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 0.8258883}
\end{sphinxVerbatim}


\subsection{Step 10a Re-measure utility (household level)}
\label{\detokenize{casestudies:step-10a-re-measure-utility-household-level}}
The utility in the data has decreased compared to the raw data, mainly
because variables were completely removed. Many of the utility measures
used in case study 1 are not applicable to the PUF file. However, by
replacing the deciles with their means, we can still use the income and
expenditure variables for arithmetic operations. Also the shares of the
income and expenditure components can still be used, since they are
based on the raw data.

We select two additional utility measures: the decile dispersion ratio
and the share of total consumption by the poorest decile. The decile
dispersion ratio is the ratio of the average income of the top decile
and the average income of the bottom decile. \hyperref[\detokenize{casestudies:code940}]{Listing \ref{\detokenize{casestudies:code940}}} shows how to
compute these from the raw data and the household variables after
anonymization. \hyperref[\detokenize{casestudies:tab922}]{Table \ref{\detokenize{casestudies:tab922}}} presents the estimated values. The differences
are small and mainly due to the removed households.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Comparison of utility measures}\label{\detokenize{casestudies:tab922}}\label{\detokenize{casestudies:id43}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
.
&\sphinxstyletheadfamily 
Raw data
&\sphinxstyletheadfamily 
PUF file
\\
\hline
Decile dispersion ratio
&
24.12
&
23.54
\\
\hline
Share of consumption by the poorest decile
&
0.0034
&
0.0035
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code940}}}
\sphinxSetupCaptionForVerbatim{Computation of decile dispersion ratio and share of total consumption by the poorest decile}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Decile dispersion ratio}
\PYG{c+c1}{\PYGZsh{} raw data}
\PYG{k+kp}{mean}\PYG{p}{(}\PYG{k+kp}{tail}\PYG{p}{(}\PYG{k+kp}{sort}\PYG{p}{(}fileOrigHH\PYG{o}{\PYGZdl{}}INCTOTGROSSHH\PYG{p}{)}\PYG{p}{,} n \PYG{o}{=} \PYG{l+m}{200}\PYG{p}{)}\PYG{p}{)} \PYG{o}{/}
  \PYG{k+kp}{mean}\PYG{p}{(}\PYG{k+kp}{head}\PYG{p}{(}\PYG{k+kp}{sort}\PYG{p}{(}fileOrigHH\PYG{o}{\PYGZdl{}}INCTOTGROSSHH\PYG{p}{)}\PYG{p}{,} n \PYG{o}{=} \PYG{l+m}{200}\PYG{p}{)}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 24.12152}

\PYG{k+kp}{mean}\PYG{p}{(}\PYG{k+kp}{tail}\PYG{p}{(}\PYG{k+kp}{sort}\PYG{p}{(}HHmanip\PYG{o}{\PYGZdl{}}INCTOTGROSSHH\PYG{p}{)}\PYG{p}{,} n \PYG{o}{=} \PYG{l+m}{197}\PYG{p}{)}\PYG{p}{)} \PYG{o}{/}
  \PYG{k+kp}{mean}\PYG{p}{(}\PYG{k+kp}{head}\PYG{p}{(}\PYG{k+kp}{sort}\PYG{p}{(}HHmanip\PYG{o}{\PYGZdl{}}INCTOTGROSSHH\PYG{p}{)}\PYG{p}{,} n \PYG{o}{=} \PYG{l+m}{197}\PYG{p}{)}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 23.54179}

\PYG{c+c1}{\PYGZsh{} Share of total consumption by the poorest decile households}
\PYG{k+kp}{sum}\PYG{p}{(}\PYG{k+kp}{head}\PYG{p}{(}\PYG{k+kp}{sort}\PYG{p}{(}fileOrigHH\PYG{o}{\PYGZdl{}}TANHHEXP\PYG{p}{)}\PYG{p}{,} n \PYG{o}{=} \PYG{l+m}{200}\PYG{p}{)}\PYG{p}{)} \PYG{o}{/} \PYG{k+kp}{sum}\PYG{p}{(}fileOrigHH\PYG{o}{\PYGZdl{}}TANHHEXP\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 0.003411664}

\PYG{k+kp}{sum}\PYG{p}{(}\PYG{k+kp}{head}\PYG{p}{(}\PYG{k+kp}{sort}\PYG{p}{(}HHmanip\PYG{o}{\PYGZdl{}}TANHHEXP\PYG{p}{)}\PYG{p}{,} n \PYG{o}{=} \PYG{l+m}{197}\PYG{p}{)}\PYG{p}{)} \PYG{o}{/} \PYG{k+kp}{sum}\PYG{p}{(}HHmanip\PYG{o}{\PYGZdl{}}TANHHEXP\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 0.003530457}
\end{sphinxVerbatim}

\sphinxstylestrong{Merging the household- and individual-level variables}

The next step is to merge the treated household variables with the
untreated individual variables for the anonymization of the individual
level variables. \hyperref[\detokenize{casestudies:code941}]{Listing \ref{\detokenize{casestudies:code941}}} shows the steps to merge these files. This
also includes the selection of variables used in the anonymization of
the individual-level variables. We create the \sphinxstyleemphasis{sdcMicro} object for the
anonymization of the individual variables in the same way as for the
household variable in \hyperref[\detokenize{casestudies:code931}]{Listing \ref{\detokenize{casestudies:code931}}}. Generally, at this stage, the
household level and individual level variables should be combined and
quasi-identifiers at both levels be used (see the Section \sphinxhref{measur\_risk.html\#Levelsofrisk}{Levels of risk}).
Unfortunately, in our dataset, this leads to long computation times.
Therefore, we create two \sphinxstyleemphasis{sdcMicro} objects, one with all key variables
(“sdcCombinedAll”) and one with only the individual level key variables
(“sdcCombined”). In Step 6b we compare the risk measures for both cases
and in Step 8b we discuss alternative approaches to keeping the complete
set of variables. We now repeat Steps 6-10 for the individual-level
variables.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code941}}}
\sphinxSetupCaptionForVerbatim{Merging the files with household and individual-level variables and creating an \sphinxstyleemphasis{sdcMicro} object for the anonymization of the individual-level variables}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Select variables (individual level)}
selectedKeyVarsIND \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{GENDER\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{REL\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{MARITAL\PYGZsq{}}\PYG{p}{,}
                       \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{AGEYRS\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{EDUCY\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{INDUSTRY1\PYGZsq{}}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} list of selected key variables}

\PYG{c+c1}{\PYGZsh{} sample weight (WGTHH, individual weight)}
selectedWeightVarIND \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{WGTHH\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Household ID}
selectedHouseholdID \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IDH\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Variables not suitable for release in PUF (IND level)}
varsNotToBeReleasedIND \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ATSCHOOL\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{EDYRSCURRAT\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} All individual level variables}
INDVars \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}selectedKeyVarsIND\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Recombining anonymized HH data sets and individual level variables}
indVars \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{IDH\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{IDP\PYGZdq{}}\PYG{p}{,} selectedKeyVarsIND\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{WGTHH\PYGZdq{}}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} HID and all non HH vars}
fileInd \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{file}\PYG{p}{[}indVars\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} subset of file without HHVars}
fileCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{merge}\PYG{p}{(}HHmanip\PYG{p}{,} fileInd\PYG{p}{,} by.x \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IDH\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
fileCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} fileCombined\PYG{p}{[}\PYG{k+kp}{order}\PYG{p}{(}fileCombined\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IDH\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}  fileCombined\PYG{p}{[}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IDP\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,}\PYG{p}{]}

\PYG{k+kp}{dim}\PYG{p}{(}fileCombined\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 10068    44}

\PYG{c+c1}{\PYGZsh{} SDC objects with only IND level variables}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} createSdcObj\PYG{p}{(}dat \PYG{o}{=} fileCombined\PYG{p}{,} keyVars \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}selectedKeyVarsIND\PYG{p}{)}\PYG{p}{,}
                            weightVar \PYG{o}{=} selectedWeightVarIND\PYG{p}{,} hhId \PYG{o}{=} selectedHouseholdID\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} SDC objects with both HH and IND level variables}
sdcCombinedAll \PYG{o}{\PYGZlt{}\PYGZhy{}} createSdcObj\PYG{p}{(}dat \PYG{o}{=} fileCombined\PYG{p}{,}
                               keyVars \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}selectedKeyVarsIND\PYG{p}{,} selectedKeyVarsHH \PYG{p}{)}\PYG{p}{,}
                               weightVar \PYG{o}{=} selectedWeightVarIND\PYG{p}{,} hhId \PYG{o}{=} selectedHouseholdID\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Step 6b: Assessing disclosure risk (individual level)}
\label{\detokenize{casestudies:id13}}
As first measure, we evaluate the number of records violating
\(k\)-anonymity at the levels 2, 3 and 5. \hyperref[\detokenize{casestudies:tab923}]{Table \ref{\detokenize{casestudies:tab923}}} shows the
number of violating individuals as well as the percentage of the total
number of households. The second and third column refer to “sdcCombined”
and the fourth and fifth column to “sdcCombinedAll”. We see that
combining the individual level and household level variables leads to a
large increase in the number of \(k\)-anonymity violators. The
choice not to include the household level variables is pragmatically
driven by the computation time and can be justified by the different
type of variables on the household level and individual level. One could
assume that these variables are not available in the same dataset and
can therefore not simultaneously be used by an intruder to re-identify
individuals.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Number of records violating \(k\)-anonimity}\label{\detokenize{casestudies:tab923}}\label{\detokenize{casestudies:id44}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
.
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{5}}
\sphinxstyletheadfamily sdcCombined
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
&\sphinxstartmulticolumn{2}%
\begin{varwidth}[t]{\sphinxcolwidth{2}{5}}
\sphinxstyletheadfamily sdcCombinedAll
\par
\vskip-\baselineskip\vbox{\hbox{\strut}}\end{varwidth}%
\sphinxstopmulticolumn
\\
\hline\sphinxstyletheadfamily 
k-anonymity
&\sphinxstyletheadfamily 
Number of
records
violating
&\sphinxstyletheadfamily 
Percentage
of total
records
&\sphinxstyletheadfamily 
Number of
records
violating
&\sphinxstyletheadfamily 
Percentage
of total
records
\\
\hline
2
&
0
&
0.0 \%
&
4,048
&
40.2 \%
\\
\hline
3
&
167
&
1.7 \%
&
6,107
&
60.7 \%
\\
\hline
5
&
463
&
4.6 \%
&
8,292
&
82.4 \%
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

The global hierarchical risk measure is 0.095\%, which corresponds to
approximately 10 expected re-identifications. We use here the
hierarchical risk measure, since the re-identification of a single
household member would lead to the re-identification of the other
members of the same household too. This number is low compared to the
number of \(k\)-anonymity violations, due to the high sample
weights, which protect the data already to a large extent. Only 24
observations have an individual hierarchical risk higher than 1\%, with a
maximum of 1.17\%. This is mainly because of the lower sample weights of
these records. \hyperref[\detokenize{casestudies:code942}]{Listing \ref{\detokenize{casestudies:code942}}} shows how to retrieve these measures in \sphinxstyleemphasis{R}.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code942}}}
\sphinxSetupCaptionForVerbatim{Risk measures before anonymization}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
numIND \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{length}\PYG{p}{(}fileCombined\PYG{p}{[}\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} number of households}

\PYG{c+c1}{\PYGZsh{} Number of observations violating k\PYGZhy{}anonymity}
\PYG{k+kp}{print}\PYG{p}{(}sdcCombined\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Infos on 2/3\PYGZhy{}Anonymity:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Number of observations violating}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 2\PYGZhy{}anonymity: 0}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 3\PYGZhy{}anonymity: 167}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Percentage of observations violating}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 2\PYGZhy{}anonymity: 0.000 \PYGZpc{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  \PYGZhy{} 3\PYGZhy{}anonymity: 1.659 \PYGZpc{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}

\PYG{c+c1}{\PYGZsh{} Calculate sample frequencies and count number of obs. violating k(3,5) \PYGZhy{} anonymity}
kAnon5 \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{sum}\PYG{p}{(}sdcCombined\PYG{o}{@}risk\PYG{o}{\PYGZdl{}}individual\PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{l+m}{5}\PYG{p}{)}
kAnon5
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 463}

\PYG{c+c1}{\PYGZsh{} As percentage of total}
kAnon5 \PYG{o}{/} numIND
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 0.04598729}

\PYG{c+c1}{\PYGZsh{} Global risk on individual level}
\PYG{k+kp}{print}\PYG{p}{(}sdcCombined\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{risk\PYGZsq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Risk measures:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Number of observations with higher risk than the main part of the data: 0}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Expected number of re\PYGZhy{}identifications: 1.69 (0.02 \PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Information on hierarchical risk:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Expected number of re\PYGZhy{}identifications: 9.57 (0.10 \PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}

\PYG{c+c1}{\PYGZsh{} Number of observation with relatively high risk}
\PYG{k+kp}{dim}\PYG{p}{(}fileCombined\PYG{p}{[}sdcCombined\PYG{o}{@}risk\PYG{o}{\PYGZdl{}}individual\PYG{p}{[}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{hier\PYGZus{}risk\PYGZdq{}}\PYG{p}{]} \PYG{o}{\PYGZgt{}} \PYG{l+m}{0.01}\PYG{p}{,}\PYG{p}{]}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 24 44}

\PYG{c+c1}{\PYGZsh{} Highest individual risk}
\PYG{k+kp}{max}\PYG{p}{(}sdcCombined\PYG{o}{@}risk\PYG{o}{\PYGZdl{}}individual\PYG{p}{[}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{hier\PYGZus{}risk\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} [1] 0.01169091}
\end{sphinxVerbatim}


\subsection{Step 7b: Assessing utility measures (individual level)}
\label{\detokenize{casestudies:step-7b-assessing-utility-measures-individual-level}}
We evaluate the utility measures as discussed in Step 5 based on the raw
data (before applying any anonymization measures). The results are
presented in Step 10b together with the values after anonymization to
allow for direct comparison.


\subsection{Step 8b: Choice and application of SDC methods (individual level)}
\label{\detokenize{casestudies:id14}}
In this step, we discuss four different techniques used for
anonymization: 1) removing variables from the dataset to be released, 2)
recoding of categorical variables to reduce the level of detail, 3)
local suppression to achieve the required level of \(k\)-anonymity,
4) randomization of the order of the records in the file. Finally, we
discuss some alternative options for treating the household structure in
the dataset.

\sphinxstylestrong{Removing variables}

Additional to the variables removed from the dataset for the SUF release
(see case study 1), we further reduce the number of variables in the
dataset to be released. This is normal practice for PUF releases.
Sensitive or identifying variables are removed, which allows to release
other variables at a more detailed level. In a PUF release, the set of
key variables should be limited.

In our case, we decide to remove at the individual level the variables
“EDYRSCURRAT”, as this variable is too identifying (identifies whether
there are school-going children in the household). We keep the variable
“EDUCY” (highest level of education attended) for information on
education.

\begin{sphinxadmonition}{note}{Note:}
As an alternative to removing the variables from the
dataset, one could also set all values to missing. This would allow the
user to see the structure and variables contained in the SUF file.
\end{sphinxadmonition}

\sphinxstylestrong{Recoding}

As noted before, PUF users require a lower level of information and
therefore we can recode the key variables even further to reduce the
disclosure risk. The recoding of variables in case study 1 is not
sufficient for a PUF release. Therefore, we recode most of the
categorical key variables from \hyperref[\detokenize{casestudies:tab919}]{Table \ref{\detokenize{casestudies:tab919}}} to reduce the risk and number
of necessary suppressions by local suppression. \hyperref[\detokenize{casestudies:tab924}]{Table \ref{\detokenize{casestudies:tab924}}} gives an
overview of the recodes made. All new categories are formed with the
needs of the data user in mind. \hyperref[\detokenize{casestudies:code943}]{Listing \ref{\detokenize{casestudies:code943}}} shows how to do this in \sphinxstyleemphasis{R}
and also shows value labels and the univariate tabulations of these
variables before and after recoding.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Overview of recodes of categorical variables at individual level}\label{\detokenize{casestudies:tab924}}\label{\detokenize{casestudies:id45}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
Variable
&\sphinxstyletheadfamily 
Recoding
\\
\hline
REL (relation to household head)
&
recode ‘Father/Mother’, ‘
Grandchild’, ‘Son/Daughter in
law’, ‘Other relative’ to ‘Other
relative’ and recode ‘Domestic
help’ and ‘Non-relative’ to
‘Other’
\\
\hline
MARITAL (marital status)
&
recode ‘Married monogamous’,
‘Married polygamous’, ’Common
law, union coutumiere, union
libre, living together’ to
‘Married/living together’ and
‘Divorced/Separated’ and
‘Widowed’ to
‘Divorced/Separated/Widowed’
\\
\hline
AGEYRS (age in completed years)
&
recode values under 15 to 7
(other values have been recoded
for SUF)
\\
\hline
EDUCY (highest level of education completed)
&
recode ‘Completed lower secondary
(or post-primary vocational
education) but less than
completed upper secondary’,
‘Completed upper secondary (or
extended vocational/technical
education)’, ‘Post secondary
technical’ and ‘University and
higher’ to ‘Completed lower
secondary or higher’
\\
\hline
INDUSTRY1
&
recode to ‘primary’, ‘secondary’
and ‘tertiary’
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code943}}}
\sphinxSetupCaptionForVerbatim{Recoding the categorical and continuous variables}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Recode REL (relation to household head)}
\PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}REL\PYG{p}{,} useNA \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ifany\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    1    2    3    4    5    6    7    8    9 \PYGZlt{}NA\PYGZgt{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 1698 1319 4933   52  765   54  817   40   63  327}

\PYG{c+c1}{\PYGZsh{} 1 \PYGZhy{} Head, 2 \PYGZhy{} Spouse, 3 \PYGZhy{} Child, 4 \PYGZhy{} Father/Mother, 5 \PYGZhy{} Grandchild, 6 \PYGZhy{} Son/Daughter in law}
\PYG{c+c1}{\PYGZsh{} 7 \PYGZhy{} Other relative, 8 \PYGZhy{} Domestic help, 9 \PYGZhy{} Non\PYGZhy{}relative}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} groupVars\PYG{p}{(}sdcCombined\PYG{p}{,} var \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{REL\PYGZdq{}}\PYG{p}{,} before \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{4\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{5\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{6\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{7\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
                         after \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{7\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{7\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{7\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{7\PYGZdq{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} other relative}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} groupVars\PYG{p}{(}sdcCombined\PYG{p}{,} var \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{REL\PYGZdq{}}\PYG{p}{,} before \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{8\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{9\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
                         after \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{9\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{9\PYGZdq{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} other}

\PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}REL\PYG{p}{,} useNA \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ifany\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    1    2    3    7    9 \PYGZlt{}NA\PYGZgt{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 1698 1319 4933 1688  103  327}

\PYG{c+c1}{\PYGZsh{} Recode MARITAL (marital status)}
\PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}MARITAL\PYG{p}{,} useNA \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ifany\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    1    2    3    4    5    6 \PYGZlt{}NA\PYGZgt{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 3542 2141  415  295  330  329 3016}

\PYG{c+c1}{\PYGZsh{} 1 \PYGZhy{} Never married, 2 \PYGZhy{} Married monogamous, 3 \PYGZhy{} Married polygamous,}
\PYG{c+c1}{\PYGZsh{} 4 \PYGZhy{} Common law, union coutumiere, union libre, living together, 5 \PYGZhy{} Divorced/Separated,}
\PYG{c+c1}{\PYGZsh{} 6 \PYGZhy{} Widowed}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} groupVars\PYG{p}{(}sdcCombined\PYG{p}{,} var \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{MARITAL\PYGZdq{}}\PYG{p}{,} before \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{4\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
                         after \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2\PYGZdq{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} married/living together}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} groupVars\PYG{p}{(}sdcCombined\PYG{p}{,} var \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{MARITAL\PYGZdq{}}\PYG{p}{,} before \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{5\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{6\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
                         after \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{9\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{9\PYGZdq{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} divorced/seperated/widowed*}

\PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}MARITAL\PYG{p}{,} useNA \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ifany\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    1    2    9 \PYGZlt{}NA\PYGZgt{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 3542 2851  659 3016}

\PYG{c+c1}{\PYGZsh{} Recode AGEYRS (0\PYGZhy{}15 years)}
\PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS\PYG{p}{,} useNA \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ifany\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    0    1    2    3    4    5    6    7    8    9   10   11   12   13   14}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  311  367  340  332  260  334  344  297  344  281  336  297  326  299  263}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}   20   30   40   50   60   65 \PYGZlt{}NA\PYGZgt{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 1847 1220  889  554  314  325  188}

sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} groupVars\PYG{p}{(}sdcCombined\PYG{p}{,} var \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{AGEYRS\PYGZdq{}}\PYG{p}{,}
                         before \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{0\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{4\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{5\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{6\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{7\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{8\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{9\PYGZdq{}}\PYG{p}{,}
                                    \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{10\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{11\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{12\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{13\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{14\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
                         after \PYG{o}{=} \PYG{k+kp}{rep}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{7\PYGZdq{}}\PYG{p}{,} \PYG{l+m}{15}\PYG{p}{)}\PYG{p}{)}

\PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}AGEYRS\PYG{p}{,} useNA \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ifany\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    7   20   30   40   50   60   65 \PYGZlt{}NA\PYGZgt{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 4731 1847 1220  889  554  314  325  188}

sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} calcRisks\PYG{p}{(}sdcCombined\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Recode EDUCY (highest level of educ compl)}
\PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}EDUCY\PYG{p}{,} useNA \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ifany\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    0    1    2    3    4    5    6 \PYGZlt{}NA\PYGZgt{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 1582 4755 1062  330  139   46  104 2050}

\PYG{c+c1}{\PYGZsh{} 0 \PYGZhy{} No education, 1 \PYGZhy{} Pre\PYGZhy{}school/ Primary not completed,}
\PYG{c+c1}{\PYGZsh{} 2 \PYGZhy{}  Completed primary, but less than completed lower secondary}
\PYG{c+c1}{\PYGZsh{} 3 \PYGZhy{} Completed lower secondary (or post\PYGZhy{}primary vocational education)}
\PYG{c+c1}{\PYGZsh{}     but less than completed upper secondary}
\PYG{c+c1}{\PYGZsh{} 4 \PYGZhy{} Completed upper secondary (or extended vocational/technical education),}
\PYG{c+c1}{\PYGZsh{} 5 \PYGZhy{} Post secondary technical}
\PYG{c+c1}{\PYGZsh{} 6 \PYGZhy{} University and higher}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} groupVars\PYG{p}{(}sdcCombined\PYG{p}{,} var \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{EDUCY\PYGZdq{}}\PYG{p}{,} before \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{4\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{5\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{6\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
                         after \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} completed lower secondary or higher}
\PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}EDUCY\PYG{p}{,} useNA \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ifany\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    0    1    2    3 \PYGZlt{}NA\PYGZgt{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 1582 4755 1062  619 2050}

\PYG{c+c1}{\PYGZsh{} Recode INDUSTRY1 ()}
\PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}INDUSTRY1\PYG{p}{,} useNA \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ifany\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    1    2    3    4    5    6    7    8    9   10 \PYGZlt{}NA\PYGZgt{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 5300   16  153    2   93  484   95   17   70  292 3546}

\PYG{c+c1}{\PYGZsh{} 1 \PYGZhy{} Agriculture and Fishing, 2 \PYGZhy{} Mining, 3 \PYGZhy{} Manufacturing, 4 \PYGZhy{}  Electricity and Utilities}
\PYG{c+c1}{\PYGZsh{} 5 \PYGZhy{} Construction, 6 \PYGZhy{} Commerce, 7 \PYGZhy{} Transportation, Storage and  Communication, 8 \PYGZhy{} Financial, Insurance and Real Estate}
\PYG{c+c1}{\PYGZsh{} 9 \PYGZhy{} Services: Public Administration, 10 \PYGZhy{} Other Services, 11 \PYGZhy{} Unspecified}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} groupVars\PYG{p}{(}sdcCombined\PYG{p}{,} var \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INDUSTRY1\PYGZdq{}}\PYG{p}{,} before \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
                         after \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1\PYGZdq{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} primary}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} groupVars\PYG{p}{(}sdcCombined\PYG{p}{,} var \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INDUSTRY1\PYGZdq{}}\PYG{p}{,} before \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{4\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{5\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
                         after \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{2\PYGZdq{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} secondary}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} groupVars\PYG{p}{(}sdcCombined\PYG{p}{,} var \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{INDUSTRY1\PYGZdq{}}\PYG{p}{,} before \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{6\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{7\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{8\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{9\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{10\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
                         after \PYG{o}{=} \PYG{k+kt}{c}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{3\PYGZdq{}}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} tertiary}
\PYG{k+kp}{table}\PYG{p}{(}sdcCombined\PYG{o}{@}manipKeyVars\PYG{o}{\PYGZdl{}}INDUSTRY1\PYG{p}{,} useNA \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ifany\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    1    2    3 \PYGZlt{}NA\PYGZgt{}}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} 5316  248  958 3546}
\end{sphinxVerbatim}

\sphinxstylestrong{Local suppression}

The recoding has reduced the risk already considerably. We use local
suppression to achieve the required level of \(k\)-anonymity.
Generally, the required level of \(k\)-anonymity for PUF files is 3
or 5. In this case study, we require 5-anonimity. \hyperref[\detokenize{casestudies:code944}]{Listing \ref{\detokenize{casestudies:code944}}} shows the
suppression pattern without specifying an importance vector. All
suppressions are made in the variable “AGEYRS”. This is the variable
with the highest number of different values, and hence considered first
by the algorithm. We try different suppression patterns by specifying
importance vectors, but we decide that the pattern without importance
vector yields the best result. This is also the result with the lowest
total number of suppressions. Less than 1 percent suppression in the age
variable is acceptable. We could reduce this number by further recoding
the variable “AGEYRS”.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code944}}}
\sphinxSetupCaptionForVerbatim{Local suppression to reach 5-anonimity}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Local suppression without importance vector}
sdcCombined \PYG{o}{\PYGZlt{}\PYGZhy{}} localSuppression\PYG{p}{(}sdcCombined\PYG{p}{,} k \PYG{o}{=} \PYG{l+m}{5}\PYG{p}{,} importance \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Number of suppressions per variable}
\PYG{k+kp}{print}\PYG{p}{(}sdcCombined\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{} Local Suppression:}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     KeyVar \textbar{} Suppressions (\PYGZsh{}) \textbar{} Suppressions (\PYGZpc{})}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     GENDER \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}        REL \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}    MARITAL \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}     AGEYRS \textbar{}               91 \textbar{}            0.904}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}      EDUCY \textbar{}                0 \textbar{}            0.000}
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}  INDUSTRY1 \textbar{}                0 \textbar{}            0.000}
\end{sphinxVerbatim}

\sphinxstylestrong{Randomization of order of records}

The records in the dataset are ordered by region and household ID. There
is a certain geographical order of the households within the regions,
due to the way the households IDs were assigned. Intruders could
reconstruct suppressed values by using this structure. To prevent this,
we randomly reorder the records within the regions. \hyperref[\detokenize{casestudies:code945}]{Listing \ref{\detokenize{casestudies:code945}}} shows
how to do this in \sphinxstyleemphasis{R}. We first count the number of records per region

\begin{sphinxadmonition}{note}{Note:}
Some records have their region value suppressed, so we include the count of NAs.
\end{sphinxadmonition}

Subsequently, we draw randomly household IDs, in
such way that the regional division is respected. Finally, we sort the
file by the new, randomized, individual ID (“IDP”). Households with
suppressed values for “REGION” will be last in the reordered file.
Before randomizing the order, we extract the data from the \sphinxstyleemphasis{sdcMicro}
object “sdcCombined” as shown in \hyperref[\detokenize{casestudies:code945}]{Listing \ref{\detokenize{casestudies:code945}}}.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code945}}}
\sphinxSetupCaptionForVerbatim{Randomizing the order of records within regions}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Randomize order of households dataAnon and recode IDH to random}
number \PYG{p}{(}sort file by region\PYG{p}{)}
\PYG{k+kp}{set.seed}\PYG{p}{(}\PYG{l+m}{97254}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} Sort by region}
dataAnon \PYG{o}{\PYGZlt{}\PYGZhy{}} dataAnon\PYG{p}{[}\PYG{k+kp}{order}\PYG{p}{(}dataAnon\PYG{o}{\PYGZdl{}}REGION\PYG{p}{)}\PYG{p}{,}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Number of households per region}
hhperregion \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{table}\PYG{p}{(}dataAnon\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}\PYG{k+kp}{unique}\PYG{p}{(}dataAnon\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} dataAnon\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{REGION\PYGZdq{}}\PYG{p}{]}\PYG{p}{,}
                     useNA \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ifany\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Randomized IDH (household ID)}
randomHHid \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kt}{c}\PYG{p}{(}\PYG{k+kp}{sample}\PYG{p}{(}\PYG{l+m}{1}\PYG{o}{:}hhperregion\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]}\PYG{p}{,} hhperregion\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,}
                \PYG{k+kp}{unlist}\PYG{p}{(}\PYG{k+kp}{lapply}\PYG{p}{(}\PYG{l+m}{1}\PYG{o}{:}\PYG{p}{(}\PYG{k+kp}{length}\PYG{p}{(}hhperregion\PYG{p}{)}\PYG{l+m}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{,}
                              \PYG{k+kr}{function}\PYG{p}{(}i\PYG{p}{)}\PYG{p}{\PYGZob{}}\PYG{k+kp}{sample}\PYG{p}{(}\PYG{p}{(}\PYG{k+kp}{sum}\PYG{p}{(}hhperregion\PYG{p}{[}\PYG{l+m}{1}\PYG{o}{:}i\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{l+m}{1}\PYG{p}{)}\PYG{o}{:} \PYG{k+kp}{sum}\PYG{p}{(}hhperregion\PYG{p}{[}\PYG{l+m}{1}\PYG{o}{:}\PYG{p}{(}i\PYG{l+m}{+1}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} hhperregion\PYG{p}{[}\PYG{p}{(}i\PYG{l+m}{+1}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}

dataAnon\PYG{o}{\PYGZdl{}}IDH \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kp}{rep}\PYG{p}{(}randomHHid\PYG{p}{,} \PYG{k+kp}{table}\PYG{p}{(}dataAnon\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{[}\PYG{k+kp}{match}\PYG{p}{(}\PYG{k+kp}{unique}\PYG{p}{(}dataAnon\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,}
                                      \PYG{k+kp}{as.numeric}\PYG{p}{(}\PYG{k+kp}{names}\PYG{p}{(}\PYG{k+kp}{table}\PYG{p}{(}dataAnon\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Sort by IDH (and region)}
dataAnon \PYG{o}{\PYGZlt{}\PYGZhy{}} dataAnon\PYG{p}{[}\PYG{k+kp}{order}\PYG{p}{(}dataAnon\PYG{o}{\PYGZdl{}}IDH\PYG{p}{)}\PYG{p}{,}\PYG{p}{]}
\end{sphinxVerbatim}

\sphinxstylestrong{Alternative options for dealing with household structure}

In Step 6b we compared the disclosure risk for two cases: one with only
individual level key variables and another with individual level and
household level key variables combined. We decided to use only the
individual level key variables to reduce the computation time and
justified this choice by arguing that intruders cannot use household and
individual level variables simultaneously. This might not always be the
case. Therefore we explore other options to reduce the risk when taking
both individual level and household level variables into account. We
present two options: removing the household structure; and using options
in the local suppression algorithm.

\sphinxstyleemphasis{Removing household structure}

We consider the risk emanating from the household structure in the
dataset to be very high. We can remove the hierarchical household
structure completely and treat all variables at the individual level.
This entails, besides removing the household id (“IDH”), also treating
variables that could be used for reconstructing households. These are,
for instance, “REL” (relation to household head), “HHSIZE” (household
size), and any of the household level variables, such as income and
expenditure. However, not all household level variables need to be
treated. For example, “REGION” is a household level variable, but the
probability that this variable leads to the reconstruction of a
household is low. Also, we need to reorder the records in the file, as
they are sorted by households. Note that by removing the household
structure, we interpret all variables as individual level variables for
measuring disclosure risk. This leads to a lower need for recoding and
suppression, since the hierarchical risk disappears. The reason why we
did not opt for this approach is the loss of utility for the user. The
household structure is an important feature of the data, and should be
kept in the PUF file.

\sphinxstyleemphasis{Using different options for local suppression}

The long running time is mainly due to the local suppression algorithm.
In the Section \sphinxhref{anon\_methods.html\#Localsuppression}{Local suppression}
we discuss options to reduce the running time of the
local suppression in case of many key variables. The all-\(m\)
approach reduces the running time by first considering subsets of the
complete set of key variables. This reduces the complexity of the
problem and leads to lower computation times. However, the total number
of suppressions made is likely to be higher. Also, if not explicitly
specified, it is not guaranteed that the required level for
\(k\)-anonymity is automatically achieved on the complete set of key
variables. It is therefore important to check the results.


\subsection{Step 9b: Re-measure risk}
\label{\detokenize{casestudies:step-9b-re-measure-risk}}
We re-evaluate the risk measures selected in Step 6. \hyperref[\detokenize{casestudies:tab925}]{Table \ref{\detokenize{casestudies:tab925}}} shows
that local suppression, not surprisingly, has reduced the number of
individuals violating 5-anonymity to 0. The global hierarchical risk was
reduced to 0.02\%, which corresponds to approximately 2 correct
re-identifications. The highest individual hierarchical
re-identification risk is 0.2\%. These risk levels are acceptable for a
PUF release. Furthermore, the recoding has removed any unusual
combinations in the data.

\begin{sphinxadmonition}{note}{Note:}
The risk may be underestimated by excluding the household level variables.
\end{sphinxadmonition}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{k-anonymity violations}\label{\detokenize{casestudies:tab925}}\label{\detokenize{casestudies:id46}}
\sphinxaftercaption
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
k-anonymity
&\sphinxstyletheadfamily 
Number of records violating
&\sphinxstyletheadfamily 
Percentage
\\
\hline
2
&
0
&
0.0 \%
\\
\hline
3
&
0
&
0.0 \%
\\
\hline
5
&
0
&
0.0 \%
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsection{Step 10b: Re-measure utility}
\label{\detokenize{casestudies:step-10b-re-measure-utility}}
We compare (cross-)tabulations before and after anonymization, which are
illustrated in the \sphinxstyleemphasis{R} code to this case study. We note that due to the
recoding in Step 8b, the detail in the variables is reduced. This
reduces the number of necessary suppressions and is acceptable for a
public use file.


\subsection{Step 11: Audit and reporting}
\label{\detokenize{casestudies:id15}}
In the audit step, we check whether the data allow for reproduction of
published figures from the original dataset and relationships between
variables and other data characteristics are preserved in the
anonymization process. In short, we check whether the dataset is valid
for analytical purposes. There are no figures available that were
published from the dataset and need to be reproducible from the
anonymized data.

In Step 2, we explored the data characteristics and relationships
between variables. These data characteristics and relationships have
been mainly preserved, since we took them into account when choosing the
appropriate anonymization methods. Since values of the variable “AGEYRS”
were not perturbed, but only recoded and suppressed, we did not
introduce unlikely combinations, such as a 60-year-old individual
enrolled in primary education. Also, by separating the anonymization
process into two parts, one for household-level variables and one for
individual-level variables, the values of variables measured at the
household level agree for all members of each household.

Furthermore, we drafted two reports, internal and external, on the
anonymization of the case study dataset. The internal report includes
the methods used, the risk before and after anonymization as well as the
reasons for the selected methods and their parameters. The external
report focuses on the changes in the data and the loss in utility. Focus
here should be on the number of suppressions as well as the perturbative
methods (PRAM). This is described in the previous steps.

\begin{sphinxadmonition}{note}{Note:}
When creating a PUF, it is inevitable that there will be a loss of
information and it is very important for the users to be aware of these
changes and release them in a report that accompanies the data.
\end{sphinxadmonition}

\sphinxhref{appendices.html\#AppendixC:InternalandExternalReportsforCaseStudies}{Appendix C}
provides examples of an internal and external report of the
anonymization process of this dataset. Depending on the users and
readers of the reports, the content may differ.

\begin{sphinxadmonition}{note}{Note:}
The report() function in sdcMicro is at this point not useful, since this will
only report on the SDC measures in the second case study.
\end{sphinxadmonition}

However, the report should contain the entire process, including the measures applied
in case study 1.


\subsection{Step 12: Data release}
\label{\detokenize{casestudies:id16}}
The final step is the release of the anonymized dataset together with
the external report. \hyperref[\detokenize{casestudies:code946}]{Listing \ref{\detokenize{casestudies:code946}}} shows how to export the anonymized
dataset as \sphinxstyleemphasis{STATA} file. The Section \sphinxhref{sdcMicro.html\#ReadfunctionsinR}{Read functions in R}
presents functions for exporting files in other data formats.

\def\sphinxLiteralBlockLabel{\label{\detokenize{casestudies:code946}}}
\sphinxSetupCaptionForVerbatim{Exporting the anonymized PUF file}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\},numbers=left,firstnumber=1,stepnumber=1]
\PYG{c+c1}{\PYGZsh{} Create STATA file}
write.dta\PYG{p}{(}dataframe \PYG{o}{=} dataAnon\PYG{p}{,} file\PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Case2DataAnon.dta\PYGZsq{}}\PYG{p}{,} convert.dates\PYG{o}{=}\PYG{k+kc}{TRUE}\PYG{p}{)}
\end{sphinxVerbatim}



\renewcommand{\indexname}{Index}
\printindex
\end{document}